data/test.lmdb
Start training
=> 2021-11-01 16:47:58.488561: step 100, loss = 7.821150, learning_rate = 0.100000 (2290.5 examples/sec)
=> 2021-11-01 16:48:43.666231: step 200, loss = 7.897614, learning_rate = 0.100000 (2284.5 examples/sec)
=> 2021-11-01 16:49:30.083858: step 300, loss = 7.818493, learning_rate = 0.100000 (2293.1 examples/sec)
=> 2021-11-01 16:50:15.438407: step 400, loss = 7.806008, learning_rate = 0.100000 (2276.1 examples/sec)
=> 2021-11-01 16:51:02.383038: step 500, loss = 7.821648, learning_rate = 0.100000 (2284.2 examples/sec)
=> 2021-11-01 16:51:47.870291: step 600, loss = 7.811975, learning_rate = 0.100000 (2269.1 examples/sec)
=> 2021-11-01 16:52:34.556187: step 700, loss = 7.864832, learning_rate = 0.100000 (2283.2 examples/sec)
=> 2021-11-01 16:53:20.091155: step 800, loss = 7.786717, learning_rate = 0.090000 (2266.6 examples/sec)
=> 2021-11-01 16:54:06.938361: step 900, loss = 7.849339, learning_rate = 0.090000 (2278.9 examples/sec)
=> 2021-11-01 16:54:52.568350: step 1000, loss = 7.795635, learning_rate = 0.090000 (2261.9 examples/sec)
=> Model saved to file: ./logs/model-1000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.022880, best accuracy 0.000000
=> Model saved to file: ./logs/model-1000.pth
=> patience = 100
=> 2021-11-01 16:55:52.190329: step 1100, loss = 7.744515, learning_rate = 0.090000 (2282.0 examples/sec)
=> 2021-11-01 16:56:37.767885: step 1200, loss = 7.802325, learning_rate = 0.090000 (2264.6 examples/sec)
=> 2021-11-01 16:57:24.595721: step 1300, loss = 7.685174, learning_rate = 0.090000 (2278.5 examples/sec)
=> 2021-11-01 16:58:10.152807: step 1400, loss = 7.846143, learning_rate = 0.090000 (2265.6 examples/sec)
=> 2021-11-01 16:58:57.030914: step 1500, loss = 7.720503, learning_rate = 0.090000 (2278.0 examples/sec)
=> 2021-11-01 16:59:42.649959: step 1600, loss = 7.794642, learning_rate = 0.081000 (2262.6 examples/sec)
=> 2021-11-01 17:00:29.643063: step 1700, loss = 7.840711, learning_rate = 0.081000 (2272.6 examples/sec)
=> 2021-11-01 17:01:15.346208: step 1800, loss = 7.850569, learning_rate = 0.081000 (2258.4 examples/sec)
=> 2021-11-01 17:02:02.379093: step 1900, loss = 7.752630, learning_rate = 0.081000 (2273.0 examples/sec)
=> 2021-11-01 17:02:48.087709: step 2000, loss = 7.773015, learning_rate = 0.081000 (2258.1 examples/sec)
=> Model saved to file: ./logs/model-2000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.022498, best accuracy 0.022880
=> patience = 99
=> 2021-11-01 17:03:46.851788: step 2100, loss = 7.817018, learning_rate = 0.081000 (2283.6 examples/sec)
=> 2021-11-01 17:04:32.294405: step 2200, loss = 7.856433, learning_rate = 0.081000 (2271.3 examples/sec)
=> 2021-11-01 17:05:19.264019: step 2300, loss = 7.786819, learning_rate = 0.081000 (2277.9 examples/sec)
=> 2021-11-01 17:06:04.862257: step 2400, loss = 7.814641, learning_rate = 0.072900 (2263.6 examples/sec)
=> 2021-11-01 17:06:51.884883: step 2500, loss = 7.779377, learning_rate = 0.072900 (2277.8 examples/sec)
=> 2021-11-01 17:07:37.502231: step 2600, loss = 7.844913, learning_rate = 0.072900 (2262.6 examples/sec)
=> 2021-11-01 17:08:24.482130: step 2700, loss = 7.778597, learning_rate = 0.072900 (2276.4 examples/sec)
=> 2021-11-01 17:09:10.087251: step 2800, loss = 7.824199, learning_rate = 0.072900 (2263.3 examples/sec)
=> 2021-11-01 17:09:57.139289: step 2900, loss = 7.816479, learning_rate = 0.072900 (2275.0 examples/sec)
=> 2021-11-01 17:10:42.776625: step 3000, loss = 7.769086, learning_rate = 0.072900 (2261.6 examples/sec)
=> Model saved to file: ./logs/model-3000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.022651, best accuracy 0.022880
=> patience = 99
=> 2021-11-01 17:11:40.339716: step 3100, loss = 7.735267, learning_rate = 0.072900 (2271.0 examples/sec)
=> 2021-11-01 17:12:27.198870: step 3200, loss = 7.895893, learning_rate = 0.065610 (2282.3 examples/sec)
=> 2021-11-01 17:13:12.770077: step 3300, loss = 7.811214, learning_rate = 0.065610 (2264.9 examples/sec)
=> 2021-11-01 17:13:59.808654: step 3400, loss = 7.826725, learning_rate = 0.065610 (2278.3 examples/sec)
=> 2021-11-01 17:14:45.409852: step 3500, loss = 7.862177, learning_rate = 0.065610 (2263.5 examples/sec)
=> 2021-11-01 17:15:32.405180: step 3600, loss = 7.724472, learning_rate = 0.065610 (2275.1 examples/sec)
=> 2021-11-01 17:16:17.987933: step 3700, loss = 7.927605, learning_rate = 0.065610 (2265.0 examples/sec)
=> 2021-11-01 17:17:04.790141: step 3800, loss = 7.844069, learning_rate = 0.065610 (2276.6 examples/sec)
=> 2021-11-01 17:17:50.240412: step 3900, loss = 7.716094, learning_rate = 0.065610 (2270.7 examples/sec)
=> 2021-11-01 17:18:37.114862: step 4000, loss = 7.902982, learning_rate = 0.059049 (2283.2 examples/sec)
=> Model saved to file: ./logs/model-4000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.022574, best accuracy 0.022880
=> patience = 99
=> 2021-11-01 17:19:34.430803: step 4100, loss = 7.719050, learning_rate = 0.059049 (2273.2 examples/sec)
=> 2021-11-01 17:20:21.189914: step 4200, loss = 7.848173, learning_rate = 0.059049 (2287.1 examples/sec)
=> 2021-11-01 17:21:06.643556: step 4300, loss = 7.888413, learning_rate = 0.059049 (2270.6 examples/sec)
=> 2021-11-01 17:21:53.619396: step 4400, loss = 7.797214, learning_rate = 0.059049 (2282.3 examples/sec)
=> 2021-11-01 17:22:39.006895: step 4500, loss = 7.788669, learning_rate = 0.059049 (2273.9 examples/sec)
=> 2021-11-01 17:23:25.702993: step 4600, loss = 7.845305, learning_rate = 0.059049 (2284.2 examples/sec)
=> 2021-11-01 17:24:11.283334: step 4700, loss = 7.810982, learning_rate = 0.059049 (2264.3 examples/sec)
=> 2021-11-01 17:24:58.022059: step 4800, loss = 7.842662, learning_rate = 0.053144 (2280.8 examples/sec)
=> 2021-11-01 17:25:43.587855: step 4900, loss = 7.805429, learning_rate = 0.053144 (2265.1 examples/sec)
=> 2021-11-01 17:26:30.360048: step 5000, loss = 7.834579, learning_rate = 0.053144 (2280.1 examples/sec)
=> Model saved to file: ./logs/model-5000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.023416, best accuracy 0.022880
=> Model saved to file: ./logs/model-5000.pth
=> patience = 100
=> 2021-11-01 17:27:28.169541: step 5100, loss = 7.822241, learning_rate = 0.053144 (2272.0 examples/sec)
=> 2021-11-01 17:28:15.066916: step 5200, loss = 7.885982, learning_rate = 0.053144 (2283.2 examples/sec)
=> 2021-11-01 17:29:00.610106: step 5300, loss = 7.900549, learning_rate = 0.053144 (2266.1 examples/sec)
=> 2021-11-01 17:29:47.435814: step 5400, loss = 7.734255, learning_rate = 0.053144 (2277.6 examples/sec)
=> 2021-11-01 17:30:32.987638: step 5500, loss = 7.845977, learning_rate = 0.053144 (2265.7 examples/sec)
=> 2021-11-01 17:31:19.746691: step 5600, loss = 7.780208, learning_rate = 0.047830 (2280.0 examples/sec)
=> 2021-11-01 17:32:05.255782: step 5700, loss = 7.778939, learning_rate = 0.047830 (2268.0 examples/sec)
=> 2021-11-01 17:32:52.117322: step 5800, loss = 7.791467, learning_rate = 0.047830 (2280.7 examples/sec)
=> 2021-11-01 17:33:37.685463: step 5900, loss = 7.849933, learning_rate = 0.047830 (2264.9 examples/sec)
=> 2021-11-01 17:34:23.270002: step 6000, loss = 7.833821, learning_rate = 0.047830 (2264.6 examples/sec)
=> Model saved to file: ./logs/model-6000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.023493, best accuracy 0.023416
=> Model saved to file: ./logs/model-6000.pth
=> patience = 100
=> 2021-11-01 17:35:22.436616: step 6100, loss = 7.802909, learning_rate = 0.047830 (2284.3 examples/sec)
=> 2021-11-01 17:36:07.915913: step 6200, loss = 7.749878, learning_rate = 0.047830 (2269.3 examples/sec)
=> 2021-11-01 17:36:54.829124: step 6300, loss = 7.768449, learning_rate = 0.047830 (2280.8 examples/sec)
=> 2021-11-01 17:37:40.442903: step 6400, loss = 7.750368, learning_rate = 0.043047 (2262.6 examples/sec)
=> 2021-11-01 17:38:27.299450: step 6500, loss = 7.447651, learning_rate = 0.043047 (2276.5 examples/sec)
=> 2021-11-01 17:39:12.915916: step 6600, loss = 7.544141, learning_rate = 0.043047 (2262.5 examples/sec)
=> 2021-11-01 17:39:59.829057: step 6700, loss = 7.121899, learning_rate = 0.043047 (2275.8 examples/sec)
=> 2021-11-01 17:40:45.467048: step 6800, loss = 6.970373, learning_rate = 0.043047 (2261.5 examples/sec)
=> 2021-11-01 17:41:32.333784: step 6900, loss = 7.126705, learning_rate = 0.043047 (2276.5 examples/sec)
=> 2021-11-01 17:42:17.952242: step 7000, loss = 6.944979, learning_rate = 0.043047 (2262.4 examples/sec)
=> Model saved to file: ./logs/model-7000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.021809, best accuracy 0.023493
=> patience = 99
=> 2021-11-01 17:43:16.439678: step 7100, loss = 6.865174, learning_rate = 0.043047 (2282.3 examples/sec)
=> 2021-11-01 17:44:01.989967: step 7200, loss = 6.718895, learning_rate = 0.038742 (2265.8 examples/sec)
=> 2021-11-01 17:44:48.960051: step 7300, loss = 6.593429, learning_rate = 0.038742 (2278.4 examples/sec)
=> 2021-11-01 17:45:34.606352: step 7400, loss = 6.615695, learning_rate = 0.038742 (2261.1 examples/sec)
=> 2021-11-01 17:46:21.450793: step 7500, loss = 6.443171, learning_rate = 0.038742 (2276.5 examples/sec)
=> 2021-11-01 17:47:07.040888: step 7600, loss = 6.801111, learning_rate = 0.038742 (2263.9 examples/sec)
=> 2021-11-01 17:47:53.934690: step 7700, loss = 6.451483, learning_rate = 0.038742 (2276.5 examples/sec)
=> 2021-11-01 17:48:39.583905: step 7800, loss = 6.521729, learning_rate = 0.038742 (2261.0 examples/sec)
=> 2021-11-01 17:49:26.494198: step 7900, loss = 6.502312, learning_rate = 0.038742 (2274.0 examples/sec)
=> 2021-11-01 17:50:12.128954: step 8000, loss = 6.383989, learning_rate = 0.034868 (2261.6 examples/sec)
=> Model saved to file: ./logs/model-8000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.054025, best accuracy 0.023493
=> Model saved to file: ./logs/model-8000.pth
=> patience = 100
=> 2021-11-01 17:51:11.406479: step 8100, loss = 6.242405, learning_rate = 0.034868 (2283.0 examples/sec)
=> 2021-11-01 17:51:56.939850: step 8200, loss = 6.236711, learning_rate = 0.034868 (2266.8 examples/sec)
=> 2021-11-01 17:52:43.967260: step 8300, loss = 6.268790, learning_rate = 0.034868 (2276.7 examples/sec)
=> 2021-11-01 17:53:29.569489: step 8400, loss = 5.996117, learning_rate = 0.034868 (2263.2 examples/sec)
=> 2021-11-01 17:54:16.409915: step 8500, loss = 5.992180, learning_rate = 0.034868 (2278.0 examples/sec)
=> 2021-11-01 17:55:02.020999: step 8600, loss = 6.087382, learning_rate = 0.034868 (2262.7 examples/sec)
=> 2021-11-01 17:55:48.868908: step 8700, loss = 5.931044, learning_rate = 0.034868 (2276.9 examples/sec)
=> 2021-11-01 17:56:34.442953: step 8800, loss = 6.032645, learning_rate = 0.031381 (2264.6 examples/sec)
=> 2021-11-01 17:57:20.019900: step 8900, loss = 5.612399, learning_rate = 0.031381 (2264.9 examples/sec)
=> 2021-11-01 17:58:06.823125: step 9000, loss = 5.574809, learning_rate = 0.031381 (2277.4 examples/sec)
=> Model saved to file: ./logs/model-9000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.083257, best accuracy 0.054025
=> Model saved to file: ./logs/model-9000.pth
=> patience = 100
=> 2021-11-01 17:59:04.759309: step 9100, loss = 5.424298, learning_rate = 0.031381 (2272.0 examples/sec)
=> 2021-11-01 17:59:51.444336: step 9200, loss = 5.385968, learning_rate = 0.031381 (2283.9 examples/sec)
=> 2021-11-01 18:00:36.970286: step 9300, loss = 5.234467, learning_rate = 0.031381 (2267.1 examples/sec)
=> 2021-11-01 18:01:23.803996: step 9400, loss = 5.301151, learning_rate = 0.031381 (2277.8 examples/sec)
=> 2021-11-01 18:02:09.404111: step 9500, loss = 4.956414, learning_rate = 0.031381 (2263.4 examples/sec)
=> 2021-11-01 18:02:56.189809: step 9600, loss = 4.791008, learning_rate = 0.028243 (2279.0 examples/sec)
=> 2021-11-01 18:03:41.787190: step 9700, loss = 4.845113, learning_rate = 0.028243 (2263.5 examples/sec)
data/test.lmdb
Start training
data/test.lmdb
Start training
=> 2021-11-01 18:05:20.903099: step 100, loss = 7.517565, learning_rate = 0.010000 (2608.1 examples/sec)
=> 2021-11-01 18:05:40.705435: step 200, loss = 7.225544, learning_rate = 0.010000 (2606.1 examples/sec)
=> 2021-11-01 18:06:00.541174: step 300, loss = 6.984157, learning_rate = 0.010000 (2601.7 examples/sec)
=> 2021-11-01 18:06:20.402885: step 400, loss = 7.059826, learning_rate = 0.010000 (2598.3 examples/sec)
=> 2021-11-01 18:06:41.182661: step 500, loss = 6.987317, learning_rate = 0.010000 (2613.2 examples/sec)
=> 2021-11-01 18:07:01.123258: step 600, loss = 6.758150, learning_rate = 0.010000 (2589.4 examples/sec)
=> 2021-11-01 18:07:20.936383: step 700, loss = 6.280335, learning_rate = 0.010000 (2605.9 examples/sec)
=> 2021-11-01 18:07:40.805916: step 800, loss = 6.244110, learning_rate = 0.009000 (2598.6 examples/sec)
=> 2021-11-01 18:08:01.621473: step 900, loss = 5.963598, learning_rate = 0.009000 (2606.5 examples/sec)
=> 2021-11-01 18:08:21.498789: step 1000, loss = 5.763544, learning_rate = 0.009000 (2597.6 examples/sec)
=> Model saved to file: ./logs/model-1000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.070784, best accuracy 0.000000
=> Model saved to file: ./logs/model-1000.pth
=> patience = 100
=> 2021-11-01 18:08:53.762737: step 1100, loss = 5.637382, learning_rate = 0.009000 (2603.9 examples/sec)
=> 2021-11-01 18:09:13.593336: step 1200, loss = 5.427406, learning_rate = 0.009000 (2603.9 examples/sec)
=> 2021-11-01 18:09:34.319482: step 1300, loss = 4.837288, learning_rate = 0.009000 (2619.0 examples/sec)
=> 2021-11-01 18:09:54.174668: step 1400, loss = 4.693120, learning_rate = 0.009000 (2600.4 examples/sec)
=> 2021-11-01 18:10:14.070936: step 1500, loss = 4.364788, learning_rate = 0.009000 (2595.0 examples/sec)
=> 2021-11-01 18:10:33.962122: step 1600, loss = 4.271708, learning_rate = 0.008100 (2595.6 examples/sec)
=> 2021-11-01 18:10:54.866569: step 1700, loss = 3.571277, learning_rate = 0.008100 (2612.3 examples/sec)
=> 2021-11-01 18:11:14.789666: step 1800, loss = 4.012917, learning_rate = 0.008100 (2591.8 examples/sec)
=> 2021-11-01 18:11:34.709186: step 1900, loss = 3.451399, learning_rate = 0.008100 (2592.2 examples/sec)
=> 2021-11-01 18:11:54.650332: step 2000, loss = 3.349813, learning_rate = 0.008100 (2589.3 examples/sec)
=> Model saved to file: ./logs/model-2000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.315886, best accuracy 0.070784
=> Model saved to file: ./logs/model-2000.pth
=> patience = 100
=> 2021-11-01 18:12:27.728531: step 2100, loss = 3.371717, learning_rate = 0.008100 (2612.0 examples/sec)
=> 2021-11-01 18:12:47.614164: step 2200, loss = 3.088894, learning_rate = 0.008100 (2596.7 examples/sec)
=> 2021-11-01 18:13:07.486878: step 2300, loss = 2.900866, learning_rate = 0.008100 (2598.3 examples/sec)
=> 2021-11-01 18:13:27.392769: step 2400, loss = 2.802920, learning_rate = 0.007290 (2594.0 examples/sec)
=> 2021-11-01 18:13:48.187833: step 2500, loss = 2.815040, learning_rate = 0.007290 (2609.9 examples/sec)
=> 2021-11-01 18:14:08.096974: step 2600, loss = 2.660616, learning_rate = 0.007290 (2593.5 examples/sec)
=> 2021-11-01 18:14:28.009200: step 2700, loss = 2.407538, learning_rate = 0.007290 (2593.3 examples/sec)
=> 2021-11-01 18:14:47.916788: step 2800, loss = 2.360518, learning_rate = 0.007290 (2593.7 examples/sec)
=> 2021-11-01 18:15:08.800429: step 2900, loss = 2.466270, learning_rate = 0.007290 (2609.7 examples/sec)
=> 2021-11-01 18:15:28.759691: step 3000, loss = 2.127678, learning_rate = 0.007290 (2588.2 examples/sec)
=> Model saved to file: ./logs/model-3000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.569712, best accuracy 0.315886
=> Model saved to file: ./logs/model-3000.pth
=> patience = 100
=> 2021-11-01 18:16:00.737557: step 3100, loss = 2.220346, learning_rate = 0.007290 (2603.0 examples/sec)
=> 2021-11-01 18:16:20.586114: step 3200, loss = 2.228938, learning_rate = 0.006561 (2601.5 examples/sec)
=> 2021-11-01 18:16:40.435366: step 3300, loss = 1.892331, learning_rate = 0.006561 (2601.5 examples/sec)
=> 2021-11-01 18:17:01.274370: step 3400, loss = 1.928327, learning_rate = 0.006561 (2616.8 examples/sec)
=> 2021-11-01 18:17:21.138847: step 3500, loss = 1.866440, learning_rate = 0.006561 (2599.2 examples/sec)
=> 2021-11-01 18:17:41.027565: step 3600, loss = 1.873161, learning_rate = 0.006561 (2596.1 examples/sec)
=> 2021-11-01 18:18:00.933790: step 3700, loss = 1.667427, learning_rate = 0.006561 (2593.8 examples/sec)
=> 2021-11-01 18:18:21.826361: step 3800, loss = 1.616265, learning_rate = 0.006561 (2606.6 examples/sec)
=> 2021-11-01 18:18:41.727550: step 3900, loss = 1.748544, learning_rate = 0.006561 (2594.6 examples/sec)
=> 2021-11-01 18:19:01.609218: step 4000, loss = 1.793129, learning_rate = 0.005905 (2597.1 examples/sec)
=> Model saved to file: ./logs/model-4000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.710285, best accuracy 0.569712
=> Model saved to file: ./logs/model-4000.pth
=> patience = 100
=> 2021-11-01 18:19:33.801117: step 4100, loss = 1.587036, learning_rate = 0.005905 (2602.8 examples/sec)
=> 2021-11-01 18:19:54.569006: step 4200, loss = 1.695407, learning_rate = 0.005905 (2618.8 examples/sec)
=> 2021-11-01 18:20:14.389173: step 4300, loss = 1.510943, learning_rate = 0.005905 (2605.1 examples/sec)
=> 2021-11-01 18:20:34.238504: step 4400, loss = 1.643593, learning_rate = 0.005905 (2601.4 examples/sec)
=> 2021-11-01 18:20:54.112084: step 4500, loss = 1.474502, learning_rate = 0.005905 (2598.4 examples/sec)
=> 2021-11-01 18:21:15.116844: step 4600, loss = 1.515243, learning_rate = 0.005905 (2610.7 examples/sec)
=> 2021-11-01 18:21:35.001488: step 4700, loss = 1.372556, learning_rate = 0.005905 (2596.6 examples/sec)
=> 2021-11-01 18:21:54.909732: step 4800, loss = 1.276274, learning_rate = 0.005314 (2593.3 examples/sec)
=> 2021-11-01 18:22:14.813660: step 4900, loss = 1.305532, learning_rate = 0.005314 (2593.9 examples/sec)
=> 2021-11-01 18:22:35.784689: step 5000, loss = 1.191093, learning_rate = 0.005314 (2612.0 examples/sec)
=> Model saved to file: ./logs/model-5000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.763621, best accuracy 0.710285
=> Model saved to file: ./logs/model-5000.pth
=> patience = 100
=> 2021-11-01 18:23:07.863186: step 5100, loss = 1.356045, learning_rate = 0.005314 (2607.3 examples/sec)
=> 2021-11-01 18:23:27.652578: step 5200, loss = 1.575040, learning_rate = 0.005314 (2608.9 examples/sec)
=> 2021-11-01 18:23:47.466864: step 5300, loss = 1.198078, learning_rate = 0.005314 (2605.8 examples/sec)
=> 2021-11-01 18:24:08.246339: step 5400, loss = 1.211315, learning_rate = 0.005314 (2616.4 examples/sec)
=> 2021-11-01 18:24:28.111087: step 5500, loss = 1.504180, learning_rate = 0.005314 (2599.3 examples/sec)
=> 2021-11-01 18:24:47.987146: step 5600, loss = 1.273611, learning_rate = 0.004783 (2597.6 examples/sec)
=> 2021-11-01 18:25:07.875687: step 5700, loss = 1.284349, learning_rate = 0.004783 (2596.3 examples/sec)
=> 2021-11-01 18:25:28.698212: step 5800, loss = 1.141439, learning_rate = 0.004783 (2609.6 examples/sec)
=> 2021-11-01 18:25:48.572904: step 5900, loss = 1.239781, learning_rate = 0.004783 (2598.1 examples/sec)
=> 2021-11-01 18:26:08.472182: step 6000, loss = 1.190736, learning_rate = 0.004783 (2594.7 examples/sec)
=> Model saved to file: ./logs/model-6000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.780150, best accuracy 0.763621
=> Model saved to file: ./logs/model-6000.pth
=> patience = 100
=> 2021-11-01 18:26:40.652969: step 6100, loss = 1.085144, learning_rate = 0.004783 (2607.1 examples/sec)
=> 2021-11-01 18:27:00.487033: step 6200, loss = 1.031541, learning_rate = 0.004783 (2603.3 examples/sec)
=> 2021-11-01 18:27:21.270816: step 6300, loss = 1.180228, learning_rate = 0.004783 (2616.7 examples/sec)
=> 2021-11-01 18:27:41.132258: step 6400, loss = 1.101890, learning_rate = 0.004305 (2599.6 examples/sec)
=> 2021-11-01 18:28:01.022683: step 6500, loss = 1.127433, learning_rate = 0.004305 (2595.8 examples/sec)
=> 2021-11-01 18:28:20.920821: step 6600, loss = 1.208381, learning_rate = 0.004305 (2594.8 examples/sec)
=> 2021-11-01 18:28:41.733876: step 6700, loss = 1.015714, learning_rate = 0.004305 (2608.7 examples/sec)
=> 2021-11-01 18:29:01.644298: step 6800, loss = 1.221151, learning_rate = 0.004305 (2593.2 examples/sec)
=> 2021-11-01 18:29:21.577157: step 6900, loss = 1.097221, learning_rate = 0.004305 (2590.5 examples/sec)
=> 2021-11-01 18:29:41.491293: step 7000, loss = 0.930918, learning_rate = 0.004305 (2592.7 examples/sec)
=> Model saved to file: ./logs/model-7000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.827135, best accuracy 0.780150
=> Model saved to file: ./logs/model-7000.pth
=> patience = 100
=> 2021-11-01 18:30:14.499395: step 7100, loss = 1.018054, learning_rate = 0.004305 (2621.2 examples/sec)
=> 2021-11-01 18:30:34.294703: step 7200, loss = 1.263155, learning_rate = 0.003874 (2608.5 examples/sec)
=> 2021-11-01 18:30:54.123231: step 7300, loss = 1.076122, learning_rate = 0.003874 (2604.0 examples/sec)
=> 2021-11-01 18:31:14.001601: step 7400, loss = 0.920936, learning_rate = 0.003874 (2597.5 examples/sec)
=> 2021-11-01 18:31:34.901746: step 7500, loss = 0.929962, learning_rate = 0.003874 (2612.5 examples/sec)
=> 2021-11-01 18:31:54.754322: step 7600, loss = 0.871236, learning_rate = 0.003874 (2600.7 examples/sec)
=> 2021-11-01 18:32:14.564446: step 7700, loss = 0.976697, learning_rate = 0.003874 (2606.3 examples/sec)
=> 2021-11-01 18:32:34.417476: step 7800, loss = 0.865565, learning_rate = 0.003874 (2600.7 examples/sec)
=> 2021-11-01 18:32:55.223595: step 7900, loss = 1.139110, learning_rate = 0.003874 (2614.4 examples/sec)
=> 2021-11-01 18:33:15.093404: step 8000, loss = 0.967888, learning_rate = 0.003487 (2598.6 examples/sec)
=> Model saved to file: ./logs/model-8000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.843281, best accuracy 0.827135
=> Model saved to file: ./logs/model-8000.pth
=> patience = 100
=> 2021-11-01 18:33:47.085329: step 8100, loss = 0.904235, learning_rate = 0.003487 (2613.3 examples/sec)
=> 2021-11-01 18:34:06.876573: step 8200, loss = 0.883881, learning_rate = 0.003487 (2609.0 examples/sec)
=> 2021-11-01 18:34:27.738097: step 8300, loss = 1.080196, learning_rate = 0.003487 (2606.1 examples/sec)
=> 2021-11-01 18:34:47.574304: step 8400, loss = 0.955234, learning_rate = 0.003487 (2603.1 examples/sec)
=> 2021-11-01 18:35:07.411373: step 8500, loss = 1.107916, learning_rate = 0.003487 (2603.0 examples/sec)
=> 2021-11-01 18:35:27.258134: step 8600, loss = 1.258288, learning_rate = 0.003487 (2601.4 examples/sec)
=> 2021-11-01 18:35:47.998684: step 8700, loss = 0.806884, learning_rate = 0.003487 (2617.9 examples/sec)
=> 2021-11-01 18:36:07.865227: step 8800, loss = 0.900591, learning_rate = 0.003138 (2598.8 examples/sec)
=> 2021-11-01 18:36:27.746715: step 8900, loss = 0.928831, learning_rate = 0.003138 (2597.1 examples/sec)
=> 2021-11-01 18:36:47.668466: step 9000, loss = 0.968288, learning_rate = 0.003138 (2591.7 examples/sec)
=> Model saved to file: ./logs/model-9000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.854760, best accuracy 0.843281
=> Model saved to file: ./logs/model-9000.pth
=> patience = 100
=> 2021-11-01 18:37:19.871183: step 9100, loss = 1.080455, learning_rate = 0.003138 (2601.8 examples/sec)
=> 2021-11-01 18:37:40.616695: step 9200, loss = 1.031348, learning_rate = 0.003138 (2624.2 examples/sec)
=> 2021-11-01 18:38:00.455800: step 9300, loss = 1.039321, learning_rate = 0.003138 (2602.6 examples/sec)
=> 2021-11-01 18:38:20.306261: step 9400, loss = 0.889107, learning_rate = 0.003138 (2601.0 examples/sec)
=> 2021-11-01 18:38:40.175113: step 9500, loss = 0.849141, learning_rate = 0.003138 (2598.8 examples/sec)
=> 2021-11-01 18:39:01.103640: step 9600, loss = 0.903568, learning_rate = 0.002824 (2612.9 examples/sec)
=> 2021-11-01 18:39:20.951578: step 9700, loss = 0.814242, learning_rate = 0.002824 (2601.5 examples/sec)
=> 2021-11-01 18:39:40.791770: step 9800, loss = 0.794339, learning_rate = 0.002824 (2602.4 examples/sec)
=> 2021-11-01 18:40:00.662523: step 9900, loss = 0.743991, learning_rate = 0.002824 (2598.5 examples/sec)
=> 2021-11-01 18:40:21.512005: step 10000, loss = 0.730329, learning_rate = 0.002824 (2613.0 examples/sec)
=> Model saved to file: ./logs/model-10000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.863101, best accuracy 0.854760
=> Model saved to file: ./logs/model-10000.pth
=> patience = 100
=> 2021-11-01 18:40:53.670431: step 10100, loss = 0.732458, learning_rate = 0.002824 (2611.6 examples/sec)
=> 2021-11-01 18:41:13.480402: step 10200, loss = 0.841984, learning_rate = 0.002824 (2606.5 examples/sec)
=> 2021-11-01 18:41:33.294164: step 10300, loss = 0.795988, learning_rate = 0.002824 (2606.0 examples/sec)
=> 2021-11-01 18:41:54.048296: step 10400, loss = 0.807650, learning_rate = 0.002542 (2617.5 examples/sec)
=> 2021-11-01 18:42:13.909868: step 10500, loss = 0.935765, learning_rate = 0.002542 (2599.9 examples/sec)
=> 2021-11-01 18:42:33.746323: step 10600, loss = 0.770511, learning_rate = 0.002542 (2603.0 examples/sec)
=> 2021-11-01 18:42:53.597907: step 10700, loss = 0.831155, learning_rate = 0.002542 (2601.0 examples/sec)
=> 2021-11-01 18:43:14.452050: step 10800, loss = 0.711298, learning_rate = 0.002542 (2611.7 examples/sec)
=> 2021-11-01 18:43:34.302517: step 10900, loss = 0.961540, learning_rate = 0.002542 (2601.4 examples/sec)
=> 2021-11-01 18:43:54.174969: step 11000, loss = 0.791363, learning_rate = 0.002542 (2598.3 examples/sec)
=> Model saved to file: ./logs/model-11000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.877410, best accuracy 0.863101
=> Model saved to file: ./logs/model-11000.pth
=> patience = 100
=> 2021-11-01 18:44:26.493499: step 11100, loss = 0.596098, learning_rate = 0.002542 (2606.4 examples/sec)
=> 2021-11-01 18:44:47.232940: step 11200, loss = 0.595734, learning_rate = 0.002288 (2619.8 examples/sec)
=> 2021-11-01 18:45:07.062246: step 11300, loss = 0.760384, learning_rate = 0.002288 (2605.3 examples/sec)
=> 2021-11-01 18:45:26.865361: step 11400, loss = 0.909277, learning_rate = 0.002288 (2607.6 examples/sec)
=> 2021-11-01 18:45:46.670537: step 11500, loss = 0.633544, learning_rate = 0.002288 (2607.0 examples/sec)
=> 2021-11-01 18:46:07.461837: step 11600, loss = 0.844680, learning_rate = 0.002288 (2618.0 examples/sec)
=> 2021-11-01 18:46:27.310438: step 11700, loss = 0.885163, learning_rate = 0.002288 (2601.8 examples/sec)
=> 2021-11-01 18:46:47.092409: step 11800, loss = 0.780710, learning_rate = 0.002288 (2610.1 examples/sec)
=> 2021-11-01 18:47:06.909434: step 11900, loss = 1.008643, learning_rate = 0.002288 (2605.6 examples/sec)
=> 2021-11-01 18:47:26.736892: step 12000, loss = 0.823463, learning_rate = 0.002059 (2605.4 examples/sec)
=> Model saved to file: ./logs/model-12000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.874426, best accuracy 0.877410
=> patience = 99
=> 2021-11-01 18:47:59.074068: step 12100, loss = 0.788576, learning_rate = 0.002059 (2625.7 examples/sec)
=> 2021-11-01 18:48:18.867553: step 12200, loss = 0.812583, learning_rate = 0.002059 (2608.6 examples/sec)
=> 2021-11-01 18:48:38.694161: step 12300, loss = 0.777242, learning_rate = 0.002059 (2604.4 examples/sec)
=> 2021-11-01 18:48:58.517927: step 12400, loss = 0.704864, learning_rate = 0.002059 (2604.7 examples/sec)
=> 2021-11-01 18:49:19.285172: step 12500, loss = 0.557691, learning_rate = 0.002059 (2616.7 examples/sec)
=> 2021-11-01 18:49:39.140026: step 12600, loss = 0.703792, learning_rate = 0.002059 (2600.6 examples/sec)
=> 2021-11-01 18:49:59.005984: step 12700, loss = 0.757900, learning_rate = 0.002059 (2599.1 examples/sec)
=> 2021-11-01 18:50:18.888299: step 12800, loss = 0.794470, learning_rate = 0.001853 (2597.1 examples/sec)
=> 2021-11-01 18:50:39.655291: step 12900, loss = 0.578602, learning_rate = 0.001853 (2614.7 examples/sec)
=> 2021-11-01 18:50:59.535504: step 13000, loss = 0.703006, learning_rate = 0.001853 (2597.1 examples/sec)
=> Model saved to file: ./logs/model-13000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.887588, best accuracy 0.877410
=> Model saved to file: ./logs/model-13000.pth
=> patience = 100
=> 2021-11-01 18:51:31.659933: step 13100, loss = 0.951834, learning_rate = 0.001853 (2610.0 examples/sec)
=> 2021-11-01 18:51:51.468281: step 13200, loss = 0.598898, learning_rate = 0.001853 (2606.8 examples/sec)
=> 2021-11-01 18:52:12.177406: step 13300, loss = 0.738341, learning_rate = 0.001853 (2627.2 examples/sec)
=> 2021-11-01 18:52:32.011906: step 13400, loss = 0.594753, learning_rate = 0.001853 (2603.0 examples/sec)
=> 2021-11-01 18:52:51.872334: step 13500, loss = 0.627030, learning_rate = 0.001853 (2599.9 examples/sec)
=> 2021-11-01 18:53:11.740075: step 13600, loss = 0.742633, learning_rate = 0.001668 (2598.5 examples/sec)
=> 2021-11-01 18:53:32.519221: step 13700, loss = 0.523204, learning_rate = 0.001668 (2614.1 examples/sec)
=> 2021-11-01 18:53:52.395247: step 13800, loss = 0.663685, learning_rate = 0.001668 (2597.8 examples/sec)
=> 2021-11-01 18:54:12.266068: step 13900, loss = 0.849807, learning_rate = 0.001668 (2598.4 examples/sec)
=> 2021-11-01 18:54:32.170721: step 14000, loss = 0.679788, learning_rate = 0.001668 (2594.3 examples/sec)
=> Model saved to file: ./logs/model-14000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.894016, best accuracy 0.887588
=> Model saved to file: ./logs/model-14000.pth
=> patience = 100
=> 2021-11-01 18:55:05.259240: step 14100, loss = 0.587573, learning_rate = 0.001668 (2623.2 examples/sec)
=> 2021-11-01 18:55:25.042102: step 14200, loss = 0.569913, learning_rate = 0.001668 (2610.0 examples/sec)
=> 2021-11-01 18:55:44.847505: step 14300, loss = 0.756877, learning_rate = 0.001668 (2607.2 examples/sec)
=> 2021-11-01 18:56:04.697130: step 14400, loss = 0.799104, learning_rate = 0.001501 (2601.4 examples/sec)
=> 2021-11-01 18:56:25.494984: step 14500, loss = 0.707413, learning_rate = 0.001501 (2615.4 examples/sec)
=> 2021-11-01 18:56:45.351029: step 14600, loss = 0.731390, learning_rate = 0.001501 (2600.2 examples/sec)
=> 2021-11-01 18:57:05.208487: step 14700, loss = 0.664922, learning_rate = 0.001501 (2600.2 examples/sec)
=> 2021-11-01 18:57:25.074850: step 14800, loss = 0.571907, learning_rate = 0.001501 (2598.9 examples/sec)
=> 2021-11-01 18:57:44.937906: step 14900, loss = 0.606440, learning_rate = 0.001501 (2600.0 examples/sec)
=> 2021-11-01 18:58:05.847186: step 15000, loss = 0.564427, learning_rate = 0.001501 (2611.5 examples/sec)
=> Model saved to file: ./logs/model-15000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.896312, best accuracy 0.894016
=> Model saved to file: ./logs/model-15000.pth
=> patience = 100
=> 2021-11-01 18:58:37.943745: step 15100, loss = 0.638908, learning_rate = 0.001501 (2607.5 examples/sec)
=> 2021-11-01 18:58:57.746272: step 15200, loss = 0.674889, learning_rate = 0.001351 (2608.0 examples/sec)
=> 2021-11-01 18:59:17.578668: step 15300, loss = 0.727852, learning_rate = 0.001351 (2603.8 examples/sec)
=> 2021-11-01 18:59:38.275922: step 15400, loss = 0.938720, learning_rate = 0.001351 (2622.8 examples/sec)
=> 2021-11-01 18:59:58.114736: step 15500, loss = 0.471594, learning_rate = 0.001351 (2602.6 examples/sec)
=> 2021-11-01 19:00:17.974020: step 15600, loss = 0.519754, learning_rate = 0.001351 (2600.0 examples/sec)
=> 2021-11-01 19:00:37.834741: step 15700, loss = 0.613625, learning_rate = 0.001351 (2599.7 examples/sec)
=> 2021-11-01 19:00:58.810374: step 15800, loss = 0.594025, learning_rate = 0.001351 (2614.9 examples/sec)
=> 2021-11-01 19:01:18.674618: step 15900, loss = 0.583688, learning_rate = 0.001351 (2599.4 examples/sec)
=> 2021-11-01 19:01:38.538982: step 16000, loss = 0.630651, learning_rate = 0.001216 (2599.3 examples/sec)
=> Model saved to file: ./logs/model-16000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.903275, best accuracy 0.896312
=> Model saved to file: ./logs/model-16000.pth
=> patience = 100
=> 2021-11-01 19:02:10.695275: step 16100, loss = 0.697199, learning_rate = 0.001216 (2608.8 examples/sec)
=> 2021-11-01 19:02:31.390661: step 16200, loss = 0.587758, learning_rate = 0.001216 (2628.5 examples/sec)
=> 2021-11-01 19:02:51.158569: step 16300, loss = 0.636152, learning_rate = 0.001216 (2611.9 examples/sec)
=> 2021-11-01 19:03:10.981447: step 16400, loss = 0.597307, learning_rate = 0.001216 (2604.8 examples/sec)
=> 2021-11-01 19:03:30.803236: step 16500, loss = 0.626004, learning_rate = 0.001216 (2604.8 examples/sec)
=> 2021-11-01 19:03:51.554366: step 16600, loss = 0.591468, learning_rate = 0.001216 (2619.6 examples/sec)
=> 2021-11-01 19:04:11.423196: step 16700, loss = 0.711229, learning_rate = 0.001216 (2598.9 examples/sec)
=> 2021-11-01 19:04:31.310649: step 16800, loss = 0.646567, learning_rate = 0.001094 (2596.1 examples/sec)
=> 2021-11-01 19:04:51.178291: step 16900, loss = 0.575371, learning_rate = 0.001094 (2598.8 examples/sec)
=> 2021-11-01 19:05:12.001899: step 17000, loss = 0.557137, learning_rate = 0.001094 (2615.1 examples/sec)
=> Model saved to file: ./logs/model-17000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.905112, best accuracy 0.903275
=> Model saved to file: ./logs/model-17000.pth
=> patience = 100
=> 2021-11-01 19:05:44.067952: step 17100, loss = 0.759857, learning_rate = 0.001094 (2610.3 examples/sec)
=> 2021-11-01 19:06:03.840921: step 17200, loss = 0.624071, learning_rate = 0.001094 (2611.6 examples/sec)
=> 2021-11-01 19:06:23.692824: step 17300, loss = 0.729995, learning_rate = 0.001094 (2600.9 examples/sec)
=> 2021-11-01 19:06:44.651589: step 17400, loss = 0.551091, learning_rate = 0.001094 (2615.7 examples/sec)
=> 2021-11-01 19:07:04.485460: step 17500, loss = 0.690931, learning_rate = 0.001094 (2603.7 examples/sec)
=> 2021-11-01 19:07:24.263697: step 17600, loss = 0.669923, learning_rate = 0.000985 (2610.5 examples/sec)
=> 2021-11-01 19:07:44.081055: step 17700, loss = 0.658723, learning_rate = 0.000985 (2605.7 examples/sec)
=> 2021-11-01 19:08:03.918203: step 17800, loss = 0.528990, learning_rate = 0.000985 (2603.6 examples/sec)
=> 2021-11-01 19:08:24.659783: step 17900, loss = 0.557972, learning_rate = 0.000985 (2620.4 examples/sec)
=> 2021-11-01 19:08:44.513926: step 18000, loss = 0.638805, learning_rate = 0.000985 (2600.6 examples/sec)
=> Model saved to file: ./logs/model-18000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.905265, best accuracy 0.905112
=> Model saved to file: ./logs/model-18000.pth
=> patience = 100
=> 2021-11-01 19:09:16.598812: step 18100, loss = 0.564972, learning_rate = 0.000985 (2609.8 examples/sec)
=> 2021-11-01 19:09:36.388216: step 18200, loss = 0.598229, learning_rate = 0.000985 (2608.9 examples/sec)
=> 2021-11-01 19:09:57.265724: step 18300, loss = 0.521366, learning_rate = 0.000985 (2620.8 examples/sec)
=> 2021-11-01 19:10:17.076720: step 18400, loss = 0.649719, learning_rate = 0.000886 (2606.2 examples/sec)
=> 2021-11-01 19:10:36.924557: step 18500, loss = 0.498195, learning_rate = 0.000886 (2601.6 examples/sec)
=> 2021-11-01 19:10:56.802788: step 18600, loss = 0.563072, learning_rate = 0.000886 (2597.6 examples/sec)
=> 2021-11-01 19:11:17.618476: step 18700, loss = 0.502463, learning_rate = 0.000886 (2611.9 examples/sec)
=> 2021-11-01 19:11:37.483446: step 18800, loss = 0.588003, learning_rate = 0.000886 (2599.1 examples/sec)
=> 2021-11-01 19:11:57.367947: step 18900, loss = 0.644221, learning_rate = 0.000886 (2596.9 examples/sec)
=> 2021-11-01 19:12:17.248625: step 19000, loss = 0.439711, learning_rate = 0.000886 (2597.3 examples/sec)
=> Model saved to file: ./logs/model-19000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.906336, best accuracy 0.905265
=> Model saved to file: ./logs/model-19000.pth
=> patience = 100
=> 2021-11-01 19:12:50.222625: step 19100, loss = 0.600071, learning_rate = 0.000886 (2623.5 examples/sec)
=> 2021-11-01 19:13:10.008040: step 19200, loss = 0.703003, learning_rate = 0.000798 (2609.6 examples/sec)
=> 2021-11-01 19:13:29.787123: step 19300, loss = 0.521326, learning_rate = 0.000798 (2610.4 examples/sec)
=> 2021-11-01 19:13:49.612731: step 19400, loss = 0.474985, learning_rate = 0.000798 (2604.4 examples/sec)
=> 2021-11-01 19:14:10.414763: step 19500, loss = 0.568328, learning_rate = 0.000798 (2613.1 examples/sec)
=> 2021-11-01 19:14:30.273640: step 19600, loss = 0.640833, learning_rate = 0.000798 (2599.8 examples/sec)
=> 2021-11-01 19:14:50.138490: step 19700, loss = 0.443893, learning_rate = 0.000798 (2599.1 examples/sec)
=> 2021-11-01 19:15:09.998247: step 19800, loss = 0.508329, learning_rate = 0.000798 (2600.0 examples/sec)
=> 2021-11-01 19:15:30.858620: step 19900, loss = 0.578628, learning_rate = 0.000798 (2614.0 examples/sec)
=> 2021-11-01 19:15:50.718498: step 20000, loss = 0.517492, learning_rate = 0.000718 (2599.8 examples/sec)
=> Model saved to file: ./logs/model-20000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.911999, best accuracy 0.906336
=> Model saved to file: ./logs/model-20000.pth
=> patience = 100
=> 2021-11-01 19:16:22.886201: step 20100, loss = 0.629880, learning_rate = 0.000718 (2608.6 examples/sec)
=> 2021-11-01 19:16:42.689521: step 20200, loss = 0.461476, learning_rate = 0.000718 (2607.1 examples/sec)
=> 2021-11-01 19:17:03.451768: step 20300, loss = 0.497619, learning_rate = 0.000718 (2616.2 examples/sec)
=> 2021-11-01 19:17:23.318143: step 20400, loss = 0.491792, learning_rate = 0.000718 (2599.1 examples/sec)
=> 2021-11-01 19:17:43.138314: step 20500, loss = 0.430944, learning_rate = 0.000718 (2605.0 examples/sec)
=> 2021-11-01 19:18:02.983879: step 20600, loss = 0.623916, learning_rate = 0.000718 (2601.7 examples/sec)
=> 2021-11-01 19:18:22.842452: step 20700, loss = 0.482229, learning_rate = 0.000718 (2600.7 examples/sec)
=> 2021-11-01 19:18:43.747084: step 20800, loss = 0.526075, learning_rate = 0.000646 (2598.1 examples/sec)
=> 2021-11-01 19:19:03.617807: step 20900, loss = 0.589590, learning_rate = 0.000646 (2598.3 examples/sec)
=> 2021-11-01 19:19:23.477962: step 21000, loss = 0.540196, learning_rate = 0.000646 (2599.8 examples/sec)
=> Model saved to file: ./logs/model-21000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.913912, best accuracy 0.911999
=> Model saved to file: ./logs/model-21000.pth
=> patience = 100
=> 2021-11-01 19:19:55.512467: step 21100, loss = 0.535271, learning_rate = 0.000646 (2604.2 examples/sec)
=> 2021-11-01 19:20:16.196547: step 21200, loss = 0.541632, learning_rate = 0.000646 (2624.0 examples/sec)
=> 2021-11-01 19:20:36.028337: step 21300, loss = 0.568424, learning_rate = 0.000646 (2603.5 examples/sec)
=> 2021-11-01 19:20:55.857904: step 21400, loss = 0.451776, learning_rate = 0.000646 (2603.8 examples/sec)
=> 2021-11-01 19:21:15.703678: step 21500, loss = 0.435826, learning_rate = 0.000646 (2601.7 examples/sec)
=> 2021-11-01 19:21:36.545707: step 21600, loss = 0.429496, learning_rate = 0.000581 (2606.4 examples/sec)
=> 2021-11-01 19:21:56.399622: step 21700, loss = 0.482946, learning_rate = 0.000581 (2600.4 examples/sec)
=> 2021-11-01 19:22:16.276250: step 21800, loss = 0.478426, learning_rate = 0.000581 (2597.5 examples/sec)
=> 2021-11-01 19:22:36.138513: step 21900, loss = 0.424396, learning_rate = 0.000581 (2599.5 examples/sec)
=> 2021-11-01 19:22:56.928590: step 22000, loss = 0.580273, learning_rate = 0.000581 (2614.7 examples/sec)
=> Model saved to file: ./logs/model-22000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.912075, best accuracy 0.913912
=> patience = 99
=> 2021-11-01 19:23:28.535999: step 22100, loss = 0.472922, learning_rate = 0.000581 (2607.0 examples/sec)
=> 2021-11-01 19:23:48.347999: step 22200, loss = 0.639359, learning_rate = 0.000581 (2605.9 examples/sec)
=> 2021-11-01 19:24:08.168197: step 22300, loss = 0.514976, learning_rate = 0.000581 (2605.1 examples/sec)
=> 2021-11-01 19:24:29.149193: step 22400, loss = 0.638447, learning_rate = 0.000523 (2612.2 examples/sec)
=> 2021-11-01 19:24:48.992770: step 22500, loss = 0.437728, learning_rate = 0.000523 (2602.1 examples/sec)
=> 2021-11-01 19:25:08.837927: step 22600, loss = 0.422504, learning_rate = 0.000523 (2601.7 examples/sec)
=> 2021-11-01 19:25:28.691900: step 22700, loss = 0.541939, learning_rate = 0.000523 (2600.5 examples/sec)
=> 2021-11-01 19:25:49.470747: step 22800, loss = 0.430708, learning_rate = 0.000523 (2614.2 examples/sec)
=> 2021-11-01 19:26:09.324716: step 22900, loss = 0.421870, learning_rate = 0.000523 (2600.6 examples/sec)
=> 2021-11-01 19:26:29.213679: step 23000, loss = 0.493338, learning_rate = 0.000523 (2595.9 examples/sec)
=> Model saved to file: ./logs/model-23000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.915748, best accuracy 0.913912
=> Model saved to file: ./logs/model-23000.pth
=> patience = 100
=> 2021-11-01 19:27:01.275870: step 23100, loss = 0.431779, learning_rate = 0.000523 (2606.8 examples/sec)
=> 2021-11-01 19:27:21.979371: step 23200, loss = 0.418241, learning_rate = 0.000471 (2626.0 examples/sec)
=> 2021-11-01 19:27:41.772256: step 23300, loss = 0.493557, learning_rate = 0.000471 (2608.7 examples/sec)
=> 2021-11-01 19:28:01.567849: step 23400, loss = 0.524351, learning_rate = 0.000471 (2608.3 examples/sec)
=> 2021-11-01 19:28:21.374908: step 23500, loss = 0.681147, learning_rate = 0.000471 (2606.7 examples/sec)
=> 2021-11-01 19:28:42.123554: step 23600, loss = 0.534136, learning_rate = 0.000471 (2619.6 examples/sec)
=> 2021-11-01 19:29:01.948544: step 23700, loss = 0.390596, learning_rate = 0.000471 (2604.4 examples/sec)
=> 2021-11-01 19:29:21.788629: step 23800, loss = 0.542528, learning_rate = 0.000471 (2602.5 examples/sec)
=> 2021-11-01 19:29:41.642246: step 23900, loss = 0.398665, learning_rate = 0.000471 (2600.7 examples/sec)
=> 2021-11-01 19:30:01.517505: step 24000, loss = 0.523782, learning_rate = 0.000424 (2597.8 examples/sec)
=> Model saved to file: ./logs/model-24000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.915595, best accuracy 0.915748
=> patience = 99
=> 2021-11-01 19:30:34.105463: step 24100, loss = 0.499309, learning_rate = 0.000424 (2627.1 examples/sec)
=> 2021-11-01 19:30:53.874222: step 24200, loss = 0.544909, learning_rate = 0.000424 (2611.8 examples/sec)
=> 2021-11-01 19:31:13.676928: step 24300, loss = 0.381154, learning_rate = 0.000424 (2607.5 examples/sec)
=> 2021-11-01 19:31:33.492940: step 24400, loss = 0.464261, learning_rate = 0.000424 (2605.7 examples/sec)
=> 2021-11-01 19:31:54.195056: step 24500, loss = 0.410294, learning_rate = 0.000424 (2621.8 examples/sec)
=> 2021-11-01 19:32:14.032155: step 24600, loss = 0.600507, learning_rate = 0.000424 (2602.7 examples/sec)
=> 2021-11-01 19:32:33.877089: step 24700, loss = 0.390116, learning_rate = 0.000424 (2601.7 examples/sec)
=> 2021-11-01 19:32:53.745268: step 24800, loss = 0.514295, learning_rate = 0.000382 (2598.8 examples/sec)
=> 2021-11-01 19:33:14.636444: step 24900, loss = 0.466495, learning_rate = 0.000382 (2618.4 examples/sec)
=> 2021-11-01 19:33:34.487740: step 25000, loss = 0.432622, learning_rate = 0.000382 (2600.8 examples/sec)
=> Model saved to file: ./logs/model-25000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.921335, best accuracy 0.915748
=> Model saved to file: ./logs/model-25000.pth
=> patience = 100
=> 2021-11-01 19:34:06.583721: step 25100, loss = 0.393169, learning_rate = 0.000382 (2610.3 examples/sec)
=> 2021-11-01 19:34:26.380778: step 25200, loss = 0.464246, learning_rate = 0.000382 (2608.3 examples/sec)
=> 2021-11-01 19:34:47.085895: step 25300, loss = 0.291475, learning_rate = 0.000382 (2622.9 examples/sec)
=> 2021-11-01 19:35:06.915174: step 25400, loss = 0.566408, learning_rate = 0.000382 (2603.9 examples/sec)
=> 2021-11-01 19:35:26.761792: step 25500, loss = 0.477250, learning_rate = 0.000382 (2601.6 examples/sec)
=> 2021-11-01 19:35:46.610049: step 25600, loss = 0.395725, learning_rate = 0.000343 (2601.4 examples/sec)
=> 2021-11-01 19:36:07.458978: step 25700, loss = 0.485465, learning_rate = 0.000343 (2616.5 examples/sec)
=> 2021-11-01 19:36:27.311389: step 25800, loss = 0.417673, learning_rate = 0.000343 (2601.0 examples/sec)
=> 2021-11-01 19:36:47.161660: step 25900, loss = 0.491828, learning_rate = 0.000343 (2601.2 examples/sec)
=> 2021-11-01 19:37:07.019539: step 26000, loss = 0.486940, learning_rate = 0.000343 (2600.2 examples/sec)
=> Model saved to file: ./logs/model-26000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.919651, best accuracy 0.921335
=> patience = 99
=> 2021-11-01 19:37:39.529113: step 26100, loss = 0.394557, learning_rate = 0.000343 (2625.2 examples/sec)
=> 2021-11-01 19:37:59.293945: step 26200, loss = 0.487473, learning_rate = 0.000343 (2612.4 examples/sec)
=> 2021-11-01 19:38:19.078975: step 26300, loss = 0.430571, learning_rate = 0.000343 (2609.7 examples/sec)
=> 2021-11-01 19:38:38.899643: step 26400, loss = 0.559559, learning_rate = 0.000309 (2605.0 examples/sec)
=> 2021-11-01 19:38:59.660798: step 26500, loss = 0.534308, learning_rate = 0.000309 (2620.8 examples/sec)
=> 2021-11-01 19:39:19.496241: step 26600, loss = 0.485277, learning_rate = 0.000309 (2607.0 examples/sec)
=> 2021-11-01 19:39:39.296184: step 26700, loss = 0.440485, learning_rate = 0.000309 (2607.6 examples/sec)
=> 2021-11-01 19:39:59.120945: step 26800, loss = 0.582521, learning_rate = 0.000309 (2604.4 examples/sec)
=> 2021-11-01 19:40:18.962691: step 26900, loss = 0.640374, learning_rate = 0.000309 (2602.2 examples/sec)
=> 2021-11-01 19:40:39.729263: step 27000, loss = 0.427190, learning_rate = 0.000309 (2614.4 examples/sec)
=> Model saved to file: ./logs/model-27000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.920722, best accuracy 0.921335
=> patience = 99
=> 2021-11-01 19:41:11.461036: step 27100, loss = 0.466991, learning_rate = 0.000309 (2610.5 examples/sec)
=> 2021-11-01 19:41:31.244501: step 27200, loss = 0.596100, learning_rate = 0.000278 (2609.8 examples/sec)
=> 2021-11-01 19:41:51.064372: step 27300, loss = 0.295567, learning_rate = 0.000278 (2605.2 examples/sec)
=> 2021-11-01 19:42:11.785137: step 27400, loss = 0.414966, learning_rate = 0.000278 (2621.9 examples/sec)
=> 2021-11-01 19:42:31.604531: step 27500, loss = 0.563614, learning_rate = 0.000278 (2605.1 examples/sec)
=> 2021-11-01 19:42:51.433860: step 27600, loss = 0.465375, learning_rate = 0.000278 (2603.8 examples/sec)
=> 2021-11-01 19:43:11.282822: step 27700, loss = 0.426785, learning_rate = 0.000278 (2601.5 examples/sec)
=> 2021-11-01 19:43:32.129358: step 27800, loss = 0.353667, learning_rate = 0.000278 (2620.0 examples/sec)
=> 2021-11-01 19:43:51.971281: step 27900, loss = 0.467132, learning_rate = 0.000278 (2602.2 examples/sec)
=> 2021-11-01 19:44:11.838179: step 28000, loss = 0.540526, learning_rate = 0.000250 (2599.0 examples/sec)
=> Model saved to file: ./logs/model-28000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.924931, best accuracy 0.921335
=> Model saved to file: ./logs/model-28000.pth
=> patience = 100
=> 2021-11-01 19:44:44.156877: step 28100, loss = 0.477664, learning_rate = 0.000250 (2609.4 examples/sec)
=> 2021-11-01 19:45:04.914656: step 28200, loss = 0.350514, learning_rate = 0.000250 (2625.4 examples/sec)
=> 2021-11-01 19:45:24.709343: step 28300, loss = 0.546294, learning_rate = 0.000250 (2608.4 examples/sec)
=> 2021-11-01 19:45:44.519481: step 28400, loss = 0.416556, learning_rate = 0.000250 (2606.3 examples/sec)
=> 2021-11-01 19:46:04.363102: step 28500, loss = 0.398120, learning_rate = 0.000250 (2602.1 examples/sec)
=> 2021-11-01 19:46:25.158150: step 28600, loss = 0.383956, learning_rate = 0.000250 (2620.0 examples/sec)
=> 2021-11-01 19:46:44.986615: step 28700, loss = 0.413923, learning_rate = 0.000250 (2604.2 examples/sec)
=> 2021-11-01 19:47:04.834279: step 28800, loss = 0.464232, learning_rate = 0.000225 (2601.4 examples/sec)
=> 2021-11-01 19:47:24.698421: step 28900, loss = 0.398516, learning_rate = 0.000225 (2599.4 examples/sec)
=> 2021-11-01 19:47:45.479765: step 29000, loss = 0.461692, learning_rate = 0.000225 (2630.7 examples/sec)
=> Model saved to file: ./logs/model-29000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.924855, best accuracy 0.924931
=> patience = 99
=> 2021-11-01 19:48:17.028895: step 29100, loss = 0.506723, learning_rate = 0.000225 (2609.0 examples/sec)
=> 2021-11-01 19:48:36.797215: step 29200, loss = 0.468989, learning_rate = 0.000225 (2611.9 examples/sec)
=> 2021-11-01 19:48:56.578665: step 29300, loss = 0.384080, learning_rate = 0.000225 (2610.3 examples/sec)
=> 2021-11-01 19:49:17.400828: step 29400, loss = 0.365123, learning_rate = 0.000225 (2622.2 examples/sec)
=> 2021-11-01 19:49:37.223059: step 29500, loss = 0.469315, learning_rate = 0.000225 (2604.7 examples/sec)
=> 2021-11-01 19:49:57.053852: step 29600, loss = 0.397242, learning_rate = 0.000203 (2603.6 examples/sec)
=> 2021-11-01 19:50:16.889422: step 29700, loss = 0.431045, learning_rate = 0.000203 (2603.0 examples/sec)
=> 2021-11-01 19:50:36.738871: step 29800, loss = 0.383492, learning_rate = 0.000203 (2602.0 examples/sec)
=> 2021-11-01 19:50:57.469963: step 29900, loss = 0.287792, learning_rate = 0.000203 (2618.3 examples/sec)
=> 2021-11-01 19:51:17.315225: step 30000, loss = 0.565343, learning_rate = 0.000203 (2601.8 examples/sec)
=> Model saved to file: ./logs/model-30000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.925314, best accuracy 0.924931
=> Model saved to file: ./logs/model-30000.pth
=> patience = 100
=> 2021-11-01 19:51:49.495314: step 30100, loss = 0.519574, learning_rate = 0.000203 (2614.1 examples/sec)
=> 2021-11-01 19:52:09.288978: step 30200, loss = 0.348545, learning_rate = 0.000203 (2610.0 examples/sec)
=> 2021-11-01 19:52:29.983733: step 30300, loss = 0.705827, learning_rate = 0.000203 (2624.2 examples/sec)
=> 2021-11-01 19:52:49.832840: step 30400, loss = 0.353036, learning_rate = 0.000182 (2601.3 examples/sec)
=> 2021-11-01 19:53:09.668208: step 30500, loss = 0.512035, learning_rate = 0.000182 (2603.1 examples/sec)
=> 2021-11-01 19:53:29.516940: step 30600, loss = 0.493251, learning_rate = 0.000182 (2601.1 examples/sec)
=> 2021-11-01 19:53:50.297763: step 30700, loss = 0.498605, learning_rate = 0.000182 (2618.2 examples/sec)
=> 2021-11-01 19:54:10.167607: step 30800, loss = 0.412399, learning_rate = 0.000182 (2599.0 examples/sec)
=> 2021-11-01 19:54:30.005853: step 30900, loss = 0.302044, learning_rate = 0.000182 (2603.0 examples/sec)
=> 2021-11-01 19:54:49.858239: step 31000, loss = 0.425925, learning_rate = 0.000182 (2600.7 examples/sec)
=> Model saved to file: ./logs/model-31000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.923401, best accuracy 0.925314
=> patience = 99
=> 2021-11-01 19:55:22.390631: step 31100, loss = 0.506714, learning_rate = 0.000182 (2623.7 examples/sec)
=> 2021-11-01 19:55:42.163699: step 31200, loss = 0.402742, learning_rate = 0.000164 (2611.3 examples/sec)
=> 2021-11-01 19:56:02.052687: step 31300, loss = 0.392474, learning_rate = 0.000164 (2596.1 examples/sec)
=> 2021-11-01 19:56:21.921526: step 31400, loss = 0.291092, learning_rate = 0.000164 (2599.2 examples/sec)
=> 2021-11-01 19:56:42.775235: step 31500, loss = 0.401017, learning_rate = 0.000164 (2619.5 examples/sec)
=> 2021-11-01 19:57:02.605314: step 31600, loss = 0.326195, learning_rate = 0.000164 (2604.0 examples/sec)
=> 2021-11-01 19:57:22.381361: step 31700, loss = 0.474641, learning_rate = 0.000164 (2611.0 examples/sec)
=> 2021-11-01 19:57:42.175257: step 31800, loss = 0.454409, learning_rate = 0.000164 (2608.6 examples/sec)
=> 2021-11-01 19:58:02.934545: step 31900, loss = 0.380553, learning_rate = 0.000164 (2619.5 examples/sec)
=> 2021-11-01 19:58:22.767479: step 32000, loss = 0.422427, learning_rate = 0.000148 (2603.6 examples/sec)
=> Model saved to file: ./logs/model-32000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.928757, best accuracy 0.925314
=> Model saved to file: ./logs/model-32000.pth
=> patience = 100
=> 2021-11-01 19:58:54.927467: step 32100, loss = 0.404512, learning_rate = 0.000148 (2612.3 examples/sec)
=> 2021-11-01 19:59:14.695727: step 32200, loss = 0.468212, learning_rate = 0.000148 (2612.0 examples/sec)
=> 2021-11-01 19:59:35.399390: step 32300, loss = 0.368411, learning_rate = 0.000148 (2624.0 examples/sec)
=> 2021-11-01 19:59:55.213120: step 32400, loss = 0.392036, learning_rate = 0.000148 (2606.2 examples/sec)
=> 2021-11-01 20:00:15.055517: step 32500, loss = 0.345353, learning_rate = 0.000148 (2602.2 examples/sec)
=> 2021-11-01 20:00:34.883536: step 32600, loss = 0.498543, learning_rate = 0.000148 (2603.4 examples/sec)
=> 2021-11-01 20:00:54.728049: step 32700, loss = 0.297174, learning_rate = 0.000148 (2602.8 examples/sec)
=> 2021-11-01 20:01:15.563960: step 32800, loss = 0.362547, learning_rate = 0.000133 (2617.1 examples/sec)
=> 2021-11-01 20:01:35.420195: step 32900, loss = 0.491759, learning_rate = 0.000133 (2600.3 examples/sec)
=> 2021-11-01 20:01:55.276253: step 33000, loss = 0.302751, learning_rate = 0.000133 (2600.1 examples/sec)
=> Model saved to file: ./logs/model-33000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.928681, best accuracy 0.928757
=> patience = 99
=> 2021-11-01 20:02:26.963107: step 33100, loss = 0.383813, learning_rate = 0.000133 (2610.5 examples/sec)
=> 2021-11-01 20:02:47.739961: step 33200, loss = 0.384001, learning_rate = 0.000133 (2626.7 examples/sec)
=> 2021-11-01 20:03:07.556506: step 33300, loss = 0.295217, learning_rate = 0.000133 (2605.7 examples/sec)
=> 2021-11-01 20:03:27.370333: step 33400, loss = 0.507428, learning_rate = 0.000133 (2605.9 examples/sec)
=> 2021-11-01 20:03:47.194148: step 33500, loss = 0.522821, learning_rate = 0.000133 (2604.7 examples/sec)
=> 2021-11-01 20:04:07.926592: step 33600, loss = 0.433182, learning_rate = 0.000120 (2619.1 examples/sec)
=> 2021-11-01 20:04:27.777752: step 33700, loss = 0.349611, learning_rate = 0.000120 (2601.1 examples/sec)
=> 2021-11-01 20:04:47.635454: step 33800, loss = 0.338362, learning_rate = 0.000120 (2600.1 examples/sec)
=> 2021-11-01 20:05:07.505557: step 33900, loss = 0.409992, learning_rate = 0.000120 (2598.8 examples/sec)
=> 2021-11-01 20:05:28.287044: step 34000, loss = 0.353838, learning_rate = 0.000120 (2611.9 examples/sec)
=> Model saved to file: ./logs/model-34000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.930441, best accuracy 0.928757
=> Model saved to file: ./logs/model-34000.pth
=> patience = 100
=> 2021-11-01 20:06:00.339267: step 34100, loss = 0.400427, learning_rate = 0.000120 (2610.6 examples/sec)
=> 2021-11-01 20:06:20.113438: step 34200, loss = 0.400504, learning_rate = 0.000120 (2611.2 examples/sec)
=> 2021-11-01 20:06:39.912740: step 34300, loss = 0.425256, learning_rate = 0.000120 (2607.7 examples/sec)
=> 2021-11-01 20:07:00.639087: step 34400, loss = 0.324092, learning_rate = 0.000108 (2619.0 examples/sec)
=> 2021-11-01 20:07:20.452354: step 34500, loss = 0.383286, learning_rate = 0.000108 (2605.8 examples/sec)
=> 2021-11-01 20:07:40.270425: step 34600, loss = 0.321278, learning_rate = 0.000108 (2605.4 examples/sec)
=> 2021-11-01 20:08:00.113709: step 34700, loss = 0.434793, learning_rate = 0.000108 (2602.0 examples/sec)
=> 2021-11-01 20:08:20.861729: step 34800, loss = 0.208901, learning_rate = 0.000108 (2618.8 examples/sec)
=> 2021-11-01 20:08:40.696874: step 34900, loss = 0.358002, learning_rate = 0.000108 (2603.1 examples/sec)
=> 2021-11-01 20:09:00.530875: step 35000, loss = 0.409520, learning_rate = 0.000108 (2603.1 examples/sec)
=> Model saved to file: ./logs/model-35000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.932201, best accuracy 0.930441
=> Model saved to file: ./logs/model-35000.pth
=> patience = 100
=> 2021-11-01 20:09:32.465173: step 35100, loss = 0.429575, learning_rate = 0.000108 (2612.1 examples/sec)
=> 2021-11-01 20:09:53.285830: step 35200, loss = 0.395702, learning_rate = 0.000097 (2624.8 examples/sec)
=> 2021-11-01 20:10:13.067068: step 35300, loss = 0.360416, learning_rate = 0.000097 (2609.9 examples/sec)
=> 2021-11-01 20:10:32.866212: step 35400, loss = 0.328387, learning_rate = 0.000097 (2607.8 examples/sec)
=> 2021-11-01 20:10:52.691108: step 35500, loss = 0.372991, learning_rate = 0.000097 (2604.6 examples/sec)
=> 2021-11-01 20:11:12.524360: step 35600, loss = 0.271763, learning_rate = 0.000097 (2604.4 examples/sec)
=> 2021-11-01 20:11:33.246429: step 35700, loss = 0.325865, learning_rate = 0.000097 (2621.7 examples/sec)
=> 2021-11-01 20:11:53.084091: step 35800, loss = 0.278232, learning_rate = 0.000097 (2602.8 examples/sec)
=> 2021-11-01 20:12:12.918937: step 35900, loss = 0.315276, learning_rate = 0.000097 (2602.8 examples/sec)
=> 2021-11-01 20:12:32.766877: step 36000, loss = 0.439073, learning_rate = 0.000087 (2601.4 examples/sec)
=> Model saved to file: ./logs/model-36000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.927456, best accuracy 0.932201
=> patience = 99
=> 2021-11-01 20:13:05.304034: step 36100, loss = 0.274632, learning_rate = 0.000087 (2626.9 examples/sec)
=> 2021-11-01 20:13:25.067242: step 36200, loss = 0.382750, learning_rate = 0.000087 (2612.7 examples/sec)
=> 2021-11-01 20:13:44.844876: step 36300, loss = 0.400055, learning_rate = 0.000087 (2610.8 examples/sec)
=> 2021-11-01 20:14:04.637322: step 36400, loss = 0.319106, learning_rate = 0.000087 (2608.7 examples/sec)
=> 2021-11-01 20:14:25.370037: step 36500, loss = 0.311050, learning_rate = 0.000087 (2623.3 examples/sec)
=> 2021-11-01 20:14:45.188111: step 36600, loss = 0.417458, learning_rate = 0.000087 (2605.3 examples/sec)
=> 2021-11-01 20:15:05.042394: step 36700, loss = 0.344059, learning_rate = 0.000087 (2600.6 examples/sec)
=> 2021-11-01 20:15:24.896736: step 36800, loss = 0.318523, learning_rate = 0.000079 (2600.5 examples/sec)
=> 2021-11-01 20:15:45.617015: step 36900, loss = 0.381647, learning_rate = 0.000079 (2623.7 examples/sec)
=> 2021-11-01 20:16:05.446941: step 37000, loss = 0.398956, learning_rate = 0.000079 (2604.4 examples/sec)
=> Model saved to file: ./logs/model-37000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.930364, best accuracy 0.932201
=> patience = 99
=> 2021-11-01 20:16:36.931810: step 37100, loss = 0.354955, learning_rate = 0.000079 (2611.8 examples/sec)
=> 2021-11-01 20:16:56.697390: step 37200, loss = 0.301203, learning_rate = 0.000079 (2612.1 examples/sec)
=> 2021-11-01 20:17:17.447922: step 37300, loss = 0.443022, learning_rate = 0.000079 (2628.0 examples/sec)
=> 2021-11-01 20:17:37.233762: step 37400, loss = 0.428144, learning_rate = 0.000079 (2609.4 examples/sec)
=> 2021-11-01 20:17:57.041529: step 37500, loss = 0.307029, learning_rate = 0.000079 (2606.8 examples/sec)
=> 2021-11-01 20:18:16.874472: step 37600, loss = 0.331792, learning_rate = 0.000071 (2603.4 examples/sec)
=> 2021-11-01 20:18:37.664348: step 37700, loss = 0.294547, learning_rate = 0.000071 (2617.7 examples/sec)
=> 2021-11-01 20:18:57.488845: step 37800, loss = 0.438054, learning_rate = 0.000071 (2604.6 examples/sec)
=> 2021-11-01 20:19:17.333486: step 37900, loss = 0.236366, learning_rate = 0.000071 (2602.1 examples/sec)
=> 2021-11-01 20:19:37.180510: step 38000, loss = 0.382322, learning_rate = 0.000071 (2601.5 examples/sec)
=> Model saved to file: ./logs/model-38000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.929752, best accuracy 0.932201
=> patience = 99
=> 2021-11-01 20:20:09.590075: step 38100, loss = 0.269921, learning_rate = 0.000071 (2626.4 examples/sec)
=> 2021-11-01 20:20:29.357067: step 38200, loss = 0.446659, learning_rate = 0.000071 (2612.0 examples/sec)
=> 2021-11-01 20:20:49.145270: step 38300, loss = 0.530797, learning_rate = 0.000071 (2609.1 examples/sec)
=> 2021-11-01 20:21:08.957309: step 38400, loss = 0.408431, learning_rate = 0.000064 (2606.1 examples/sec)
=> 2021-11-01 20:21:28.777656: step 38500, loss = 0.379279, learning_rate = 0.000064 (2605.6 examples/sec)
=> 2021-11-01 20:21:49.611840: step 38600, loss = 0.415842, learning_rate = 0.000064 (2621.1 examples/sec)
=> 2021-11-01 20:22:09.393984: step 38700, loss = 0.346077, learning_rate = 0.000064 (2610.2 examples/sec)
=> 2021-11-01 20:22:29.176566: step 38800, loss = 0.305365, learning_rate = 0.000064 (2610.1 examples/sec)
=> 2021-11-01 20:22:48.977970: step 38900, loss = 0.416287, learning_rate = 0.000064 (2607.7 examples/sec)
=> 2021-11-01 20:23:09.689841: step 39000, loss = 0.280562, learning_rate = 0.000064 (2621.5 examples/sec)
=> Model saved to file: ./logs/model-39000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.929216, best accuracy 0.932201
=> patience = 99
=> 2021-11-01 20:23:41.178600: step 39100, loss = 0.365647, learning_rate = 0.000064 (2620.3 examples/sec)
=> 2021-11-01 20:24:00.910112: step 39200, loss = 0.426467, learning_rate = 0.000057 (2616.9 examples/sec)
=> 2021-11-01 20:24:20.672800: step 39300, loss = 0.275238, learning_rate = 0.000057 (2612.9 examples/sec)
=> 2021-11-01 20:24:41.358939: step 39400, loss = 0.378831, learning_rate = 0.000057 (2626.8 examples/sec)
=> 2021-11-01 20:25:01.152642: step 39500, loss = 0.315645, learning_rate = 0.000057 (2608.4 examples/sec)
=> 2021-11-01 20:25:20.948096: step 39600, loss = 0.354037, learning_rate = 0.000057 (2608.2 examples/sec)
=> 2021-11-01 20:25:40.760729: step 39700, loss = 0.344153, learning_rate = 0.000057 (2606.2 examples/sec)
=> 2021-11-01 20:26:01.661216: step 39800, loss = 0.318702, learning_rate = 0.000057 (2619.5 examples/sec)
=> 2021-11-01 20:26:21.483396: step 39900, loss = 0.298896, learning_rate = 0.000057 (2604.7 examples/sec)
=> 2021-11-01 20:26:41.307186: step 40000, loss = 0.366870, learning_rate = 0.000052 (2604.6 examples/sec)
=> Model saved to file: ./logs/model-40000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.935109, best accuracy 0.932201
=> Model saved to file: ./logs/model-40000.pth
=> patience = 100
=> 2021-11-01 20:27:13.409350: step 40100, loss = 0.346848, learning_rate = 0.000052 (2611.4 examples/sec)
=> 2021-11-01 20:27:34.081903: step 40200, loss = 0.442070, learning_rate = 0.000052 (2627.0 examples/sec)
=> 2021-11-01 20:27:53.868850: step 40300, loss = 0.386130, learning_rate = 0.000052 (2609.5 examples/sec)
=> 2021-11-01 20:28:13.673617: step 40400, loss = 0.350036, learning_rate = 0.000052 (2607.1 examples/sec)
=> 2021-11-01 20:28:33.484488: step 40500, loss = 0.326078, learning_rate = 0.000052 (2606.4 examples/sec)
=> 2021-11-01 20:28:54.189455: step 40600, loss = 0.260244, learning_rate = 0.000052 (2622.5 examples/sec)
=> 2021-11-01 20:29:13.989687: step 40700, loss = 0.389071, learning_rate = 0.000052 (2607.8 examples/sec)
=> 2021-11-01 20:29:33.729120: step 40800, loss = 0.499705, learning_rate = 0.000046 (2615.8 examples/sec)
=> 2021-11-01 20:29:53.490629: step 40900, loss = 0.298776, learning_rate = 0.000046 (2612.9 examples/sec)
=> 2021-11-01 20:30:14.185167: step 41000, loss = 0.348853, learning_rate = 0.000046 (2625.5 examples/sec)
=> Model saved to file: ./logs/model-41000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.932583, best accuracy 0.935109
=> patience = 99
=> 2021-11-01 20:30:45.639132: step 41100, loss = 0.260144, learning_rate = 0.000046 (2618.7 examples/sec)
=> 2021-11-01 20:31:05.376897: step 41200, loss = 0.461898, learning_rate = 0.000046 (2616.0 examples/sec)
=> 2021-11-01 20:31:25.141947: step 41300, loss = 0.268394, learning_rate = 0.000046 (2612.3 examples/sec)
=> 2021-11-01 20:31:44.925568: step 41400, loss = 0.280620, learning_rate = 0.000046 (2610.1 examples/sec)
=> 2021-11-01 20:32:05.908122: step 41500, loss = 0.354535, learning_rate = 0.000046 (2599.4 examples/sec)
=> 2021-11-01 20:32:25.704897: step 41600, loss = 0.338371, learning_rate = 0.000042 (2608.1 examples/sec)
=> 2021-11-01 20:32:45.514420: step 41700, loss = 0.395279, learning_rate = 0.000042 (2606.5 examples/sec)
=> 2021-11-01 20:33:05.356153: step 41800, loss = 0.302581, learning_rate = 0.000042 (2602.3 examples/sec)
=> 2021-11-01 20:33:26.062113: step 41900, loss = 0.331048, learning_rate = 0.000042 (2624.2 examples/sec)
=> 2021-11-01 20:33:45.884241: step 42000, loss = 0.227241, learning_rate = 0.000042 (2604.9 examples/sec)
=> Model saved to file: ./logs/model-42000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.933808, best accuracy 0.935109
=> patience = 99
=> 2021-11-01 20:34:17.565756: step 42100, loss = 0.291956, learning_rate = 0.000042 (2613.3 examples/sec)
=> 2021-11-01 20:34:37.304227: step 42200, loss = 0.312255, learning_rate = 0.000042 (2615.8 examples/sec)
=> 2021-11-01 20:34:58.011576: step 42300, loss = 0.263741, learning_rate = 0.000042 (2627.4 examples/sec)
=> 2021-11-01 20:35:17.801006: step 42400, loss = 0.515008, learning_rate = 0.000038 (2609.2 examples/sec)
=> 2021-11-01 20:35:37.603823: step 42500, loss = 0.473607, learning_rate = 0.000038 (2607.3 examples/sec)
=> 2021-11-01 20:35:57.421855: step 42600, loss = 0.376490, learning_rate = 0.000038 (2605.4 examples/sec)
=> 2021-11-01 20:36:18.167149: step 42700, loss = 0.230341, learning_rate = 0.000038 (2619.9 examples/sec)
=> 2021-11-01 20:36:37.993308: step 42800, loss = 0.348428, learning_rate = 0.000038 (2604.2 examples/sec)
=> 2021-11-01 20:36:57.815889: step 42900, loss = 0.399400, learning_rate = 0.000038 (2604.7 examples/sec)
=> 2021-11-01 20:37:17.649776: step 43000, loss = 0.474410, learning_rate = 0.000038 (2603.2 examples/sec)
=> Model saved to file: ./logs/model-43000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.936792, best accuracy 0.935109
=> Model saved to file: ./logs/model-43000.pth
=> patience = 100
=> 2021-11-01 20:37:50.710332: step 43100, loss = 0.300885, learning_rate = 0.000038 (2625.9 examples/sec)
=> 2021-11-01 20:38:10.467226: step 43200, loss = 0.250031, learning_rate = 0.000034 (2613.5 examples/sec)
=> 2021-11-01 20:38:30.207461: step 43300, loss = 0.510097, learning_rate = 0.000034 (2615.4 examples/sec)
=> 2021-11-01 20:38:49.981733: step 43400, loss = 0.429387, learning_rate = 0.000034 (2610.8 examples/sec)
=> 2021-11-01 20:39:10.750331: step 43500, loss = 0.260012, learning_rate = 0.000034 (2620.8 examples/sec)
=> 2021-11-01 20:39:30.530946: step 43600, loss = 0.252458, learning_rate = 0.000034 (2610.1 examples/sec)
=> 2021-11-01 20:39:50.340403: step 43700, loss = 0.353749, learning_rate = 0.000034 (2606.5 examples/sec)
=> 2021-11-01 20:40:10.150044: step 43800, loss = 0.199440, learning_rate = 0.000034 (2606.5 examples/sec)
=> 2021-11-01 20:40:30.974799: step 43900, loss = 0.224780, learning_rate = 0.000034 (2616.1 examples/sec)
=> 2021-11-01 20:40:50.802047: step 44000, loss = 0.256224, learning_rate = 0.000030 (2604.2 examples/sec)
=> Model saved to file: ./logs/model-44000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.935797, best accuracy 0.936792
=> patience = 99
=> 2021-11-01 20:41:22.358376: step 44100, loss = 0.343548, learning_rate = 0.000030 (2611.8 examples/sec)
=> 2021-11-01 20:41:42.099851: step 44200, loss = 0.324759, learning_rate = 0.000030 (2615.3 examples/sec)
=> 2021-11-01 20:42:02.863967: step 44300, loss = 0.327466, learning_rate = 0.000030 (2625.8 examples/sec)
=> 2021-11-01 20:42:22.711477: step 44400, loss = 0.298897, learning_rate = 0.000030 (2601.8 examples/sec)
=> 2021-11-01 20:42:42.501938: step 44500, loss = 0.312002, learning_rate = 0.000030 (2608.8 examples/sec)
=> 2021-11-01 20:43:02.294265: step 44600, loss = 0.379007, learning_rate = 0.000030 (2608.8 examples/sec)
=> 2021-11-01 20:43:22.100880: step 44700, loss = 0.326825, learning_rate = 0.000030 (2606.9 examples/sec)
=> 2021-11-01 20:43:42.937432: step 44800, loss = 0.331918, learning_rate = 0.000027 (2620.7 examples/sec)
=> 2021-11-01 20:44:02.759105: step 44900, loss = 0.235798, learning_rate = 0.000027 (2604.9 examples/sec)
=> 2021-11-01 20:44:22.579772: step 45000, loss = 0.393029, learning_rate = 0.000027 (2605.1 examples/sec)
=> Model saved to file: ./logs/model-45000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.937404, best accuracy 0.936792
=> Model saved to file: ./logs/model-45000.pth
=> patience = 100
=> 2021-11-01 20:44:54.903695: step 45100, loss = 0.297503, learning_rate = 0.000027 (2614.3 examples/sec)
=> 2021-11-01 20:45:15.531641: step 45200, loss = 0.370390, learning_rate = 0.000027 (2632.7 examples/sec)
=> 2021-11-01 20:45:35.261032: step 45300, loss = 0.351979, learning_rate = 0.000027 (2616.9 examples/sec)
=> 2021-11-01 20:45:55.021537: step 45400, loss = 0.231206, learning_rate = 0.000027 (2612.9 examples/sec)
=> 2021-11-01 20:46:14.799483: step 45500, loss = 0.248494, learning_rate = 0.000027 (2610.6 examples/sec)
=> 2021-11-01 20:46:35.570627: step 45600, loss = 0.333378, learning_rate = 0.000025 (2628.2 examples/sec)
=> 2021-11-01 20:46:55.338895: step 45700, loss = 0.331626, learning_rate = 0.000025 (2611.8 examples/sec)
=> 2021-11-01 20:47:15.090771: step 45800, loss = 0.381330, learning_rate = 0.000025 (2614.1 examples/sec)
=> 2021-11-01 20:47:34.868135: step 45900, loss = 0.256001, learning_rate = 0.000025 (2610.7 examples/sec)
=> 2021-11-01 20:47:55.718557: step 46000, loss = 0.348245, learning_rate = 0.000025 (2621.0 examples/sec)
=> Model saved to file: ./logs/model-46000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.937098, best accuracy 0.937404
=> patience = 99
=> 2021-11-01 20:48:27.252828: step 46100, loss = 0.264466, learning_rate = 0.000025 (2617.3 examples/sec)
=> 2021-11-01 20:48:46.980065: step 46200, loss = 0.278221, learning_rate = 0.000025 (2617.4 examples/sec)
=> 2021-11-01 20:49:06.746324: step 46300, loss = 0.307475, learning_rate = 0.000025 (2612.2 examples/sec)
=> 2021-11-01 20:49:27.453454: step 46400, loss = 0.350019, learning_rate = 0.000022 (2628.9 examples/sec)
=> 2021-11-01 20:49:47.215710: step 46500, loss = 0.351652, learning_rate = 0.000022 (2612.7 examples/sec)
=> 2021-11-01 20:50:06.985652: step 46600, loss = 0.278074, learning_rate = 0.000022 (2612.0 examples/sec)
=> 2021-11-01 20:50:26.772850: step 46700, loss = 0.349802, learning_rate = 0.000022 (2609.3 examples/sec)
=> 2021-11-01 20:50:47.671506: step 46800, loss = 0.348376, learning_rate = 0.000022 (2624.8 examples/sec)
=> 2021-11-01 20:51:07.490496: step 46900, loss = 0.376431, learning_rate = 0.000022 (2605.3 examples/sec)
=> 2021-11-01 20:51:27.278279: step 47000, loss = 0.270868, learning_rate = 0.000022 (2609.4 examples/sec)
=> Model saved to file: ./logs/model-47000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.939777, best accuracy 0.937404
=> Model saved to file: ./logs/model-47000.pth
=> patience = 100
=> 2021-11-01 20:51:59.542410: step 47100, loss = 0.312890, learning_rate = 0.000022 (2613.7 examples/sec)
=> 2021-11-01 20:52:20.298030: step 47200, loss = 0.344957, learning_rate = 0.000020 (2629.2 examples/sec)
=> 2021-11-01 20:52:40.071322: step 47300, loss = 0.325638, learning_rate = 0.000020 (2611.2 examples/sec)
=> 2021-11-01 20:52:59.842800: step 47400, loss = 0.307297, learning_rate = 0.000020 (2611.6 examples/sec)
=> 2021-11-01 20:53:19.696513: step 47500, loss = 0.236039, learning_rate = 0.000020 (2600.9 examples/sec)
=> 2021-11-01 20:53:39.498436: step 47600, loss = 0.323289, learning_rate = 0.000020 (2607.5 examples/sec)
=> 2021-11-01 20:54:00.224839: step 47700, loss = 0.327724, learning_rate = 0.000020 (2621.1 examples/sec)
=> 2021-11-01 20:54:20.036192: step 47800, loss = 0.394258, learning_rate = 0.000020 (2606.3 examples/sec)
=> 2021-11-01 20:54:39.842058: step 47900, loss = 0.284122, learning_rate = 0.000020 (2607.1 examples/sec)
=> 2021-11-01 20:54:59.650315: step 48000, loss = 0.323207, learning_rate = 0.000018 (2606.8 examples/sec)
=> Model saved to file: ./logs/model-48000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.937787, best accuracy 0.939777
=> patience = 99
=> 2021-11-01 20:55:32.174051: step 48100, loss = 0.335787, learning_rate = 0.000018 (2626.9 examples/sec)
=> 2021-11-01 20:55:51.907690: step 48200, loss = 0.356583, learning_rate = 0.000018 (2616.4 examples/sec)
=> 2021-11-01 20:56:11.677585: step 48300, loss = 0.339154, learning_rate = 0.000018 (2611.9 examples/sec)
=> 2021-11-01 20:56:31.445899: step 48400, loss = 0.251412, learning_rate = 0.000018 (2611.8 examples/sec)
=> 2021-11-01 20:56:52.172438: step 48500, loss = 0.258172, learning_rate = 0.000018 (2626.0 examples/sec)
=> 2021-11-01 20:57:11.955202: step 48600, loss = 0.415198, learning_rate = 0.000018 (2610.1 examples/sec)
=> 2021-11-01 20:57:31.781624: step 48700, loss = 0.391826, learning_rate = 0.000018 (2604.2 examples/sec)
=> 2021-11-01 20:57:51.584170: step 48800, loss = 0.273922, learning_rate = 0.000016 (2607.5 examples/sec)
=> 2021-11-01 20:58:12.332443: step 48900, loss = 0.340836, learning_rate = 0.000016 (2624.3 examples/sec)
=> 2021-11-01 20:58:32.153509: step 49000, loss = 0.228733, learning_rate = 0.000016 (2605.2 examples/sec)
=> Model saved to file: ./logs/model-49000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.939700, best accuracy 0.939777
=> patience = 99
=> 2021-11-01 20:59:04.143484: step 49100, loss = 0.275816, learning_rate = 0.000016 (2614.2 examples/sec)
=> 2021-11-01 20:59:23.887049: step 49200, loss = 0.285576, learning_rate = 0.000016 (2615.4 examples/sec)
=> 2021-11-01 20:59:44.745840: step 49300, loss = 0.362573, learning_rate = 0.000016 (2630.0 examples/sec)
=> 2021-11-01 21:00:04.508304: step 49400, loss = 0.286582, learning_rate = 0.000016 (2612.4 examples/sec)
=> 2021-11-01 21:00:24.287440: step 49500, loss = 0.254184, learning_rate = 0.000016 (2610.5 examples/sec)
=> 2021-11-01 21:00:44.080210: step 49600, loss = 0.339797, learning_rate = 0.000015 (2608.7 examples/sec)
=> 2021-11-01 21:01:04.866139: step 49700, loss = 0.183424, learning_rate = 0.000015 (2620.7 examples/sec)
=> 2021-11-01 21:01:24.672209: step 49800, loss = 0.304680, learning_rate = 0.000015 (2606.9 examples/sec)
=> 2021-11-01 21:01:44.482104: step 49900, loss = 0.355707, learning_rate = 0.000015 (2606.5 examples/sec)
=> 2021-11-01 21:02:04.299969: step 50000, loss = 0.372495, learning_rate = 0.000015 (2605.4 examples/sec)
=> Model saved to file: ./logs/model-50000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.937940, best accuracy 0.939777
=> patience = 99
=> 2021-11-01 21:02:36.817362: step 50100, loss = 0.259057, learning_rate = 0.000015 (2631.9 examples/sec)
=> 2021-11-01 21:02:56.547814: step 50200, loss = 0.369020, learning_rate = 0.000015 (2616.9 examples/sec)
=> 2021-11-01 21:03:16.293602: step 50300, loss = 0.325859, learning_rate = 0.000015 (2615.0 examples/sec)
=> 2021-11-01 21:03:36.063673: step 50400, loss = 0.340047, learning_rate = 0.000013 (2611.6 examples/sec)
=> 2021-11-01 21:03:55.840076: step 50500, loss = 0.390633, learning_rate = 0.000013 (2611.4 examples/sec)
=> 2021-11-01 21:04:16.523570: step 50600, loss = 0.248404, learning_rate = 0.000013 (2626.9 examples/sec)
=> 2021-11-01 21:04:36.307622: step 50700, loss = 0.248489, learning_rate = 0.000013 (2609.8 examples/sec)
=> 2021-11-01 21:04:56.117404: step 50800, loss = 0.293412, learning_rate = 0.000013 (2606.5 examples/sec)
=> 2021-11-01 21:05:15.926976: step 50900, loss = 0.353845, learning_rate = 0.000013 (2606.5 examples/sec)
=> 2021-11-01 21:05:36.820528: step 51000, loss = 0.353133, learning_rate = 0.000013 (2622.0 examples/sec)
=> Model saved to file: ./logs/model-51000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.940083, best accuracy 0.939777
=> Model saved to file: ./logs/model-51000.pth
=> patience = 100
=> 2021-11-01 21:06:08.763311: step 51100, loss = 0.230519, learning_rate = 0.000013 (2614.8 examples/sec)
=> 2021-11-01 21:06:28.466391: step 51200, loss = 0.230604, learning_rate = 0.000012 (2620.6 examples/sec)
=> 2021-11-01 21:06:48.191717: step 51300, loss = 0.300469, learning_rate = 0.000012 (2617.7 examples/sec)
=> 2021-11-01 21:07:08.961782: step 51400, loss = 0.303946, learning_rate = 0.000012 (2631.1 examples/sec)
=> 2021-11-01 21:07:28.719109: step 51500, loss = 0.249533, learning_rate = 0.000012 (2613.4 examples/sec)
=> 2021-11-01 21:07:48.491398: step 51600, loss = 0.302431, learning_rate = 0.000012 (2611.4 examples/sec)
=> 2021-11-01 21:08:08.347319: step 51700, loss = 0.290042, learning_rate = 0.000012 (2600.5 examples/sec)
=> 2021-11-01 21:08:29.013630: step 51800, loss = 0.223364, learning_rate = 0.000012 (2626.7 examples/sec)
=> 2021-11-01 21:08:48.818594: step 51900, loss = 0.161327, learning_rate = 0.000012 (2606.8 examples/sec)
=> 2021-11-01 21:09:08.617052: step 52000, loss = 0.294530, learning_rate = 0.000011 (2608.0 examples/sec)
=> Model saved to file: ./logs/model-52000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.942149, best accuracy 0.940083
=> Model saved to file: ./logs/model-52000.pth
=> patience = 100
=> 2021-11-01 21:09:40.892050: step 52100, loss = 0.365597, learning_rate = 0.000011 (2614.3 examples/sec)
=> 2021-11-01 21:10:01.527012: step 52200, loss = 0.191674, learning_rate = 0.000011 (2634.7 examples/sec)
=> 2021-11-01 21:10:21.278829: step 52300, loss = 0.227516, learning_rate = 0.000011 (2614.1 examples/sec)
=> 2021-11-01 21:10:41.029597: step 52400, loss = 0.451304, learning_rate = 0.000011 (2614.4 examples/sec)
=> 2021-11-01 21:11:00.809693: step 52500, loss = 0.292459, learning_rate = 0.000011 (2610.4 examples/sec)
=> 2021-11-01 21:11:21.670502: step 52600, loss = 0.197813, learning_rate = 0.000011 (2620.3 examples/sec)
=> 2021-11-01 21:11:41.470209: step 52700, loss = 0.261055, learning_rate = 0.000011 (2607.8 examples/sec)
=> 2021-11-01 21:12:01.270922: step 52800, loss = 0.225224, learning_rate = 0.000010 (2607.7 examples/sec)
=> 2021-11-01 21:12:21.081340: step 52900, loss = 0.209039, learning_rate = 0.000010 (2606.5 examples/sec)
=> 2021-11-01 21:12:41.794673: step 53000, loss = 0.267664, learning_rate = 0.000010 (2622.7 examples/sec)
=> Model saved to file: ./logs/model-53000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.936869, best accuracy 0.942149
=> patience = 99
=> 2021-11-01 21:13:13.259475: step 53100, loss = 0.161064, learning_rate = 0.000010 (2615.0 examples/sec)
=> 2021-11-01 21:13:32.990955: step 53200, loss = 0.306336, learning_rate = 0.000010 (2616.8 examples/sec)
=> 2021-11-01 21:13:52.753458: step 53300, loss = 0.499785, learning_rate = 0.000010 (2612.6 examples/sec)
=> 2021-11-01 21:14:12.532091: step 53400, loss = 0.263916, learning_rate = 0.000010 (2611.3 examples/sec)
=> 2021-11-01 21:14:33.272331: step 53500, loss = 0.269358, learning_rate = 0.000010 (2622.0 examples/sec)
=> 2021-11-01 21:14:53.066976: step 53600, loss = 0.347385, learning_rate = 0.000009 (2608.3 examples/sec)
=> 2021-11-01 21:15:12.860594: step 53700, loss = 0.364078, learning_rate = 0.000009 (2608.7 examples/sec)
=> 2021-11-01 21:15:32.644511: step 53800, loss = 0.294167, learning_rate = 0.000009 (2609.8 examples/sec)
=> 2021-11-01 21:15:53.374193: step 53900, loss = 0.204878, learning_rate = 0.000009 (2624.5 examples/sec)
=> 2021-11-01 21:16:13.176217: step 54000, loss = 0.292820, learning_rate = 0.000009 (2607.5 examples/sec)
=> Model saved to file: ./logs/model-54000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.942378, best accuracy 0.942149
=> Model saved to file: ./logs/model-54000.pth
=> patience = 100
=> 2021-11-01 21:16:45.362776: step 54100, loss = 0.347949, learning_rate = 0.000009 (2606.6 examples/sec)
=> 2021-11-01 21:17:05.091419: step 54200, loss = 0.306323, learning_rate = 0.000009 (2617.3 examples/sec)
=> 2021-11-01 21:17:25.735335: step 54300, loss = 0.273048, learning_rate = 0.000009 (2635.1 examples/sec)
=> 2021-11-01 21:17:45.492059: step 54400, loss = 0.298670, learning_rate = 0.000008 (2613.7 examples/sec)
=> 2021-11-01 21:18:05.257333: step 54500, loss = 0.274276, learning_rate = 0.000008 (2612.3 examples/sec)
=> 2021-11-01 21:18:25.036291: step 54600, loss = 0.323973, learning_rate = 0.000008 (2610.4 examples/sec)
=> 2021-11-01 21:18:45.794787: step 54700, loss = 0.248275, learning_rate = 0.000008 (2623.2 examples/sec)
=> 2021-11-01 21:19:05.598897: step 54800, loss = 0.269161, learning_rate = 0.000008 (2607.2 examples/sec)
=> 2021-11-01 21:19:25.405376: step 54900, loss = 0.213857, learning_rate = 0.000008 (2607.1 examples/sec)
=> 2021-11-01 21:19:45.203797: step 55000, loss = 0.304117, learning_rate = 0.000008 (2608.0 examples/sec)
=> Model saved to file: ./logs/model-55000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.941766, best accuracy 0.942378
=> patience = 99
=> 2021-11-01 21:20:17.730512: step 55100, loss = 0.204793, learning_rate = 0.000008 (2633.0 examples/sec)
=> 2021-11-01 21:20:37.458617: step 55200, loss = 0.365721, learning_rate = 0.000007 (2617.6 examples/sec)
=> 2021-11-01 21:20:57.211133: step 55300, loss = 0.291540, learning_rate = 0.000007 (2614.1 examples/sec)
=> 2021-11-01 21:21:16.980200: step 55400, loss = 0.417744, learning_rate = 0.000007 (2611.7 examples/sec)
=> 2021-11-01 21:21:37.670279: step 55500, loss = 0.235904, learning_rate = 0.000007 (2629.0 examples/sec)
=> 2021-11-01 21:21:57.459140: step 55600, loss = 0.199662, learning_rate = 0.000007 (2609.4 examples/sec)
=> 2021-11-01 21:22:17.264454: step 55700, loss = 0.337095, learning_rate = 0.000007 (2607.3 examples/sec)
=> 2021-11-01 21:22:37.060744: step 55800, loss = 0.303367, learning_rate = 0.000007 (2608.5 examples/sec)
=> 2021-11-01 21:22:57.792916: step 55900, loss = 0.311235, learning_rate = 0.000007 (2620.5 examples/sec)
=> 2021-11-01 21:23:17.603080: step 56000, loss = 0.305327, learning_rate = 0.000006 (2606.5 examples/sec)
=> Model saved to file: ./logs/model-56000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.941996, best accuracy 0.942378
=> patience = 99
=> 2021-11-01 21:23:49.162170: step 56100, loss = 0.197278, learning_rate = 0.000006 (2615.5 examples/sec)
=> 2021-11-01 21:24:08.897480: step 56200, loss = 0.270622, learning_rate = 0.000006 (2616.5 examples/sec)
=> 2021-11-01 21:24:28.648751: step 56300, loss = 0.271379, learning_rate = 0.000006 (2614.9 examples/sec)
=> 2021-11-01 21:24:49.364552: step 56400, loss = 0.385790, learning_rate = 0.000006 (2628.4 examples/sec)
=> 2021-11-01 21:25:09.089967: step 56500, loss = 0.278289, learning_rate = 0.000006 (2617.9 examples/sec)
=> 2021-11-01 21:25:28.819264: step 56600, loss = 0.339382, learning_rate = 0.000006 (2617.3 examples/sec)
=> 2021-11-01 21:25:48.579185: step 56700, loss = 0.158454, learning_rate = 0.000006 (2613.1 examples/sec)
=> 2021-11-01 21:26:09.293407: step 56800, loss = 0.272555, learning_rate = 0.000006 (2624.1 examples/sec)
=> 2021-11-01 21:26:29.087397: step 56900, loss = 0.313580, learning_rate = 0.000006 (2608.6 examples/sec)
=> 2021-11-01 21:26:48.869141: step 57000, loss = 0.327586, learning_rate = 0.000006 (2610.0 examples/sec)
=> Model saved to file: ./logs/model-57000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.941690, best accuracy 0.942378
=> patience = 99
=> 2021-11-01 21:27:20.274393: step 57100, loss = 0.237262, learning_rate = 0.000006 (2617.5 examples/sec)
=> 2021-11-01 21:27:41.021247: step 57200, loss = 0.167568, learning_rate = 0.000006 (2632.9 examples/sec)
=> 2021-11-01 21:28:00.743550: step 57300, loss = 0.314459, learning_rate = 0.000006 (2618.2 examples/sec)
=> 2021-11-01 21:28:20.490692: step 57400, loss = 0.276688, learning_rate = 0.000006 (2614.9 examples/sec)
=> 2021-11-01 21:28:40.353833: step 57500, loss = 0.193845, learning_rate = 0.000006 (2599.6 examples/sec)
=> 2021-11-01 21:29:01.050885: step 57600, loss = 0.298868, learning_rate = 0.000005 (2624.8 examples/sec)
=> 2021-11-01 21:29:20.843991: step 57700, loss = 0.347025, learning_rate = 0.000005 (2608.7 examples/sec)
=> 2021-11-01 21:29:40.641896: step 57800, loss = 0.218966, learning_rate = 0.000005 (2608.1 examples/sec)
=> 2021-11-01 21:30:00.435028: step 57900, loss = 0.319346, learning_rate = 0.000005 (2608.7 examples/sec)
=> 2021-11-01 21:30:21.196855: step 58000, loss = 0.218928, learning_rate = 0.000005 (2620.4 examples/sec)
=> Model saved to file: ./logs/model-58000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.941843, best accuracy 0.942378
=> patience = 99
=> 2021-11-01 21:30:52.569191: step 58100, loss = 0.210902, learning_rate = 0.000005 (2617.6 examples/sec)
=> 2021-11-01 21:31:12.293786: step 58200, loss = 0.312306, learning_rate = 0.000005 (2617.7 examples/sec)
=> 2021-11-01 21:31:32.021818: step 58300, loss = 0.218982, learning_rate = 0.000005 (2617.2 examples/sec)
=> 2021-11-01 21:31:52.817065: step 58400, loss = 0.339050, learning_rate = 0.000005 (2630.4 examples/sec)
=> 2021-11-01 21:32:12.576485: step 58500, loss = 0.367794, learning_rate = 0.000005 (2613.3 examples/sec)
=> 2021-11-01 21:32:32.340211: step 58600, loss = 0.198437, learning_rate = 0.000005 (2612.6 examples/sec)
=> 2021-11-01 21:32:52.132904: step 58700, loss = 0.280852, learning_rate = 0.000005 (2608.8 examples/sec)
=> 2021-11-01 21:33:12.856066: step 58800, loss = 0.287384, learning_rate = 0.000005 (2620.6 examples/sec)
=> 2021-11-01 21:33:32.639687: step 58900, loss = 0.299174, learning_rate = 0.000005 (2609.9 examples/sec)
=> 2021-11-01 21:33:52.436717: step 59000, loss = 0.349931, learning_rate = 0.000005 (2607.9 examples/sec)
=> Model saved to file: ./logs/model-59000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.941919, best accuracy 0.942378
=> patience = 99
=> 2021-11-01 21:34:23.804335: step 59100, loss = 0.241506, learning_rate = 0.000005 (2616.8 examples/sec)
=> 2021-11-01 21:34:43.526764: step 59200, loss = 0.383884, learning_rate = 0.000004 (2618.5 examples/sec)
=> 2021-11-01 21:35:04.270066: step 59300, loss = 0.266621, learning_rate = 0.000004 (2624.8 examples/sec)
=> 2021-11-01 21:35:24.020964: step 59400, loss = 0.249832, learning_rate = 0.000004 (2614.1 examples/sec)
=> 2021-11-01 21:35:43.785775: step 59500, loss = 0.459102, learning_rate = 0.000004 (2612.5 examples/sec)
=> 2021-11-01 21:36:03.559266: step 59600, loss = 0.185435, learning_rate = 0.000004 (2611.3 examples/sec)
=> 2021-11-01 21:36:24.281456: step 59700, loss = 0.232926, learning_rate = 0.000004 (2624.7 examples/sec)
=> 2021-11-01 21:36:44.048081: step 59800, loss = 0.234847, learning_rate = 0.000004 (2612.0 examples/sec)
=> 2021-11-01 21:37:03.854120: step 59900, loss = 0.388154, learning_rate = 0.000004 (2607.2 examples/sec)
=> 2021-11-01 21:37:23.658199: step 60000, loss = 0.276579, learning_rate = 0.000004 (2607.2 examples/sec)
=> Model saved to file: ./logs/model-60000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.942455, best accuracy 0.942378
=> Model saved to file: ./logs/model-60000.pth
=> patience = 100
=> 2021-11-01 21:37:56.806083: step 60100, loss = 0.241267, learning_rate = 0.000004 (2634.5 examples/sec)
=> 2021-11-01 21:38:16.537393: step 60200, loss = 0.223732, learning_rate = 0.000004 (2617.3 examples/sec)
=> 2021-11-01 21:38:36.287232: step 60300, loss = 0.313876, learning_rate = 0.000004 (2614.6 examples/sec)
=> 2021-11-01 21:38:56.028376: step 60400, loss = 0.219010, learning_rate = 0.000004 (2615.7 examples/sec)
=> 2021-11-01 21:39:16.896953: step 60500, loss = 0.325351, learning_rate = 0.000004 (2625.4 examples/sec)
=> 2021-11-01 21:39:36.652201: step 60600, loss = 0.295191, learning_rate = 0.000004 (2613.8 examples/sec)
=> 2021-11-01 21:39:56.407908: step 60700, loss = 0.225627, learning_rate = 0.000004 (2613.5 examples/sec)
=> 2021-11-01 21:40:16.184748: step 60800, loss = 0.271129, learning_rate = 0.000003 (2610.8 examples/sec)
=> 2021-11-01 21:40:36.911480: step 60900, loss = 0.264416, learning_rate = 0.000003 (2622.9 examples/sec)
=> 2021-11-01 21:40:56.674209: step 61000, loss = 0.251398, learning_rate = 0.000003 (2612.6 examples/sec)
=> Model saved to file: ./logs/model-61000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.944368, best accuracy 0.942455
=> Model saved to file: ./logs/model-61000.pth
=> patience = 100
=> 2021-11-01 21:41:28.863236: step 61100, loss = 0.213333, learning_rate = 0.000003 (2619.6 examples/sec)
=> 2021-11-01 21:41:48.568870: step 61200, loss = 0.242965, learning_rate = 0.000003 (2620.2 examples/sec)
=> 2021-11-01 21:42:09.244135: step 61300, loss = 0.204851, learning_rate = 0.000003 (2629.3 examples/sec)
=> 2021-11-01 21:42:29.058359: step 61400, loss = 0.185111, learning_rate = 0.000003 (2606.5 examples/sec)
=> 2021-11-01 21:42:48.828745: step 61500, loss = 0.206959, learning_rate = 0.000003 (2613.1 examples/sec)
=> 2021-11-01 21:43:08.605724: step 61600, loss = 0.297775, learning_rate = 0.000003 (2611.1 examples/sec)
=> 2021-11-01 21:43:29.384951: step 61700, loss = 0.224666, learning_rate = 0.000003 (2623.8 examples/sec)
=> 2021-11-01 21:43:49.167660: step 61800, loss = 0.183570, learning_rate = 0.000003 (2610.8 examples/sec)
=> 2021-11-01 21:44:08.932964: step 61900, loss = 0.336620, learning_rate = 0.000003 (2613.0 examples/sec)
=> 2021-11-01 21:44:28.743913: step 62000, loss = 0.218442, learning_rate = 0.000003 (2606.9 examples/sec)
=> Model saved to file: ./logs/model-62000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.945898, best accuracy 0.944368
=> Model saved to file: ./logs/model-62000.pth
=> patience = 100
=> 2021-11-01 21:45:00.966291: step 62100, loss = 0.248007, learning_rate = 0.000003 (2616.8 examples/sec)
=> 2021-11-01 21:45:21.734122: step 62200, loss = 0.259180, learning_rate = 0.000003 (2613.4 examples/sec)
=> 2021-11-01 21:45:41.460009: step 62300, loss = 0.256142, learning_rate = 0.000003 (2617.6 examples/sec)
=> 2021-11-01 21:46:01.211584: step 62400, loss = 0.221242, learning_rate = 0.000003 (2614.1 examples/sec)
=> 2021-11-01 21:46:20.985191: step 62500, loss = 0.213158, learning_rate = 0.000003 (2611.4 examples/sec)
=> 2021-11-01 21:46:41.673401: step 62600, loss = 0.262513, learning_rate = 0.000003 (2626.9 examples/sec)
=> 2021-11-01 21:47:01.412461: step 62700, loss = 0.205584, learning_rate = 0.000003 (2615.8 examples/sec)
=> 2021-11-01 21:47:21.167615: step 62800, loss = 0.185868, learning_rate = 0.000003 (2613.7 examples/sec)
=> 2021-11-01 21:47:40.924407: step 62900, loss = 0.256726, learning_rate = 0.000003 (2613.5 examples/sec)
=> 2021-11-01 21:48:01.613914: step 63000, loss = 0.344168, learning_rate = 0.000003 (2624.9 examples/sec)
=> Model saved to file: ./logs/model-63000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.943909, best accuracy 0.945898
=> patience = 99
=> 2021-11-01 21:48:33.134220: step 63100, loss = 0.211190, learning_rate = 0.000003 (2617.8 examples/sec)
=> 2021-11-01 21:48:52.861097: step 63200, loss = 0.141772, learning_rate = 0.000002 (2617.6 examples/sec)
=> 2021-11-01 21:49:12.613395: step 63300, loss = 0.295988, learning_rate = 0.000002 (2614.0 examples/sec)
=> 2021-11-01 21:49:33.332057: step 63400, loss = 0.345459, learning_rate = 0.000002 (2629.2 examples/sec)
=> 2021-11-01 21:49:53.110353: step 63500, loss = 0.223577, learning_rate = 0.000002 (2610.6 examples/sec)
=> 2021-11-01 21:50:12.887114: step 63600, loss = 0.260979, learning_rate = 0.000002 (2610.8 examples/sec)
=> 2021-11-01 21:50:32.668214: step 63700, loss = 0.182232, learning_rate = 0.000002 (2610.2 examples/sec)
=> 2021-11-01 21:50:53.381804: step 63800, loss = 0.212651, learning_rate = 0.000002 (2625.9 examples/sec)
=> 2021-11-01 21:51:13.270760: step 63900, loss = 0.300215, learning_rate = 0.000002 (2596.2 examples/sec)
=> 2021-11-01 21:51:33.048558: step 64000, loss = 0.245861, learning_rate = 0.000002 (2610.7 examples/sec)
=> Model saved to file: ./logs/model-64000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.941996, best accuracy 0.945898
=> patience = 99
=> 2021-11-01 21:52:04.567661: step 64100, loss = 0.183337, learning_rate = 0.000002 (2617.4 examples/sec)
=> 2021-11-01 21:52:25.240554: step 64200, loss = 0.220370, learning_rate = 0.000002 (2633.2 examples/sec)
=> 2021-11-01 21:52:44.976071: step 64300, loss = 0.224936, learning_rate = 0.000002 (2616.3 examples/sec)
=> 2021-11-01 21:53:04.739811: step 64400, loss = 0.360478, learning_rate = 0.000002 (2613.0 examples/sec)
=> 2021-11-01 21:53:24.535232: step 64500, loss = 0.245202, learning_rate = 0.000002 (2608.5 examples/sec)
=> 2021-11-01 21:53:45.245927: step 64600, loss = 0.250234, learning_rate = 0.000002 (2639.9 examples/sec)
=> 2021-11-01 21:54:05.018545: step 64700, loss = 0.348420, learning_rate = 0.000002 (2611.5 examples/sec)
=> 2021-11-01 21:54:24.843289: step 64800, loss = 0.186826, learning_rate = 0.000002 (2604.6 examples/sec)
=> 2021-11-01 21:54:44.612126: step 64900, loss = 0.229312, learning_rate = 0.000002 (2611.8 examples/sec)
=> 2021-11-01 21:55:05.323326: step 65000, loss = 0.175730, learning_rate = 0.000002 (2626.1 examples/sec)
=> Model saved to file: ./logs/model-65000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.943220, best accuracy 0.945898
=> patience = 99
=> 2021-11-01 21:55:37.123374: step 65100, loss = 0.235537, learning_rate = 0.000002 (2619.2 examples/sec)
=> 2021-11-01 21:55:56.836955: step 65200, loss = 0.230728, learning_rate = 0.000002 (2619.3 examples/sec)
=> 2021-11-01 21:56:16.578883: step 65300, loss = 0.186136, learning_rate = 0.000002 (2615.5 examples/sec)
=> 2021-11-01 21:56:36.340705: step 65400, loss = 0.355435, learning_rate = 0.000002 (2612.8 examples/sec)
=> 2021-11-01 21:56:57.010277: step 65500, loss = 0.195604, learning_rate = 0.000002 (2629.0 examples/sec)
=> 2021-11-01 21:57:16.797955: step 65600, loss = 0.206876, learning_rate = 0.000002 (2609.6 examples/sec)
=> 2021-11-01 21:57:36.580802: step 65700, loss = 0.237785, learning_rate = 0.000002 (2610.3 examples/sec)
=> 2021-11-01 21:57:56.371468: step 65800, loss = 0.279750, learning_rate = 0.000002 (2609.1 examples/sec)
=> 2021-11-01 21:58:17.067080: step 65900, loss = 0.216038, learning_rate = 0.000002 (2624.3 examples/sec)
=> 2021-11-01 21:58:36.889379: step 66000, loss = 0.276260, learning_rate = 0.000002 (2604.9 examples/sec)
=> Model saved to file: ./logs/model-66000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.945363, best accuracy 0.945898
=> patience = 99
=> 2021-11-01 21:59:08.412749: step 66100, loss = 0.395908, learning_rate = 0.000002 (2614.1 examples/sec)
=> 2021-11-01 21:59:28.132554: step 66200, loss = 0.164534, learning_rate = 0.000002 (2618.6 examples/sec)
=> 2021-11-01 21:59:48.948589: step 66300, loss = 0.159194, learning_rate = 0.000002 (2630.5 examples/sec)
=> 2021-11-01 22:00:08.667701: step 66400, loss = 0.208373, learning_rate = 0.000002 (2618.6 examples/sec)
=> 2021-11-01 22:00:28.370330: step 66500, loss = 0.239845, learning_rate = 0.000002 (2620.6 examples/sec)
=> 2021-11-01 22:00:48.107998: step 66600, loss = 0.286743, learning_rate = 0.000002 (2615.9 examples/sec)
=> 2021-11-01 22:01:08.892247: step 66700, loss = 0.166868, learning_rate = 0.000002 (2633.0 examples/sec)
=> 2021-11-01 22:01:28.622120: step 66800, loss = 0.235067, learning_rate = 0.000002 (2617.2 examples/sec)
=> 2021-11-01 22:01:48.365271: step 66900, loss = 0.210894, learning_rate = 0.000002 (2615.5 examples/sec)
=> 2021-11-01 22:02:08.113105: step 67000, loss = 0.224238, learning_rate = 0.000002 (2614.8 examples/sec)
=> Model saved to file: ./logs/model-67000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.939700, best accuracy 0.945898
=> patience = 99
=> 2021-11-01 22:02:40.530191: step 67100, loss = 0.294568, learning_rate = 0.000002 (2628.4 examples/sec)
=> 2021-11-01 22:03:00.256866: step 67200, loss = 0.189935, learning_rate = 0.000001 (2617.5 examples/sec)
=> 2021-11-01 22:03:19.989793: step 67300, loss = 0.216791, learning_rate = 0.000001 (2616.6 examples/sec)
=> 2021-11-01 22:03:39.742169: step 67400, loss = 0.170443, learning_rate = 0.000001 (2613.9 examples/sec)
=> 2021-11-01 22:04:00.468419: step 67500, loss = 0.124056, learning_rate = 0.000001 (2624.4 examples/sec)
=> 2021-11-01 22:04:20.251745: step 67600, loss = 0.240527, learning_rate = 0.000001 (2610.1 examples/sec)
=> 2021-11-01 22:04:40.034267: step 67700, loss = 0.358587, learning_rate = 0.000001 (2609.9 examples/sec)
=> 2021-11-01 22:04:59.828505: step 67800, loss = 0.316210, learning_rate = 0.000001 (2608.5 examples/sec)
=> 2021-11-01 22:05:20.660611: step 67900, loss = 0.284861, learning_rate = 0.000001 (2624.5 examples/sec)
=> 2021-11-01 22:05:40.447429: step 68000, loss = 0.216383, learning_rate = 0.000001 (2610.1 examples/sec)
=> Model saved to file: ./logs/model-68000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.945745, best accuracy 0.945898
=> patience = 99
=> 2021-11-01 22:06:12.111373: step 68100, loss = 0.260523, learning_rate = 0.000001 (2616.0 examples/sec)
=> 2021-11-01 22:06:31.839978: step 68200, loss = 0.163170, learning_rate = 0.000001 (2617.3 examples/sec)
=> 2021-11-01 22:06:51.572414: step 68300, loss = 0.231359, learning_rate = 0.000001 (2616.6 examples/sec)
=> 2021-11-01 22:07:12.299472: step 68400, loss = 0.253307, learning_rate = 0.000001 (2623.7 examples/sec)
=> 2021-11-01 22:07:32.055165: step 68500, loss = 0.205976, learning_rate = 0.000001 (2613.7 examples/sec)
=> 2021-11-01 22:07:51.827925: step 68600, loss = 0.257738, learning_rate = 0.000001 (2611.5 examples/sec)
=> 2021-11-01 22:08:11.718044: step 68700, loss = 0.251199, learning_rate = 0.000001 (2595.8 examples/sec)
=> 2021-11-01 22:08:32.464141: step 68800, loss = 0.301541, learning_rate = 0.000001 (2628.3 examples/sec)
=> 2021-11-01 22:08:52.246561: step 68900, loss = 0.175261, learning_rate = 0.000001 (2610.1 examples/sec)
=> 2021-11-01 22:09:12.034854: step 69000, loss = 0.279560, learning_rate = 0.000001 (2609.4 examples/sec)
=> Model saved to file: ./logs/model-69000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.945363, best accuracy 0.945898
=> patience = 99
=> 2021-11-01 22:09:43.703843: step 69100, loss = 0.257709, learning_rate = 0.000001 (2613.9 examples/sec)
=> 2021-11-01 22:10:04.349598: step 69200, loss = 0.224480, learning_rate = 0.000001 (2633.5 examples/sec)
=> 2021-11-01 22:10:24.109585: step 69300, loss = 0.210933, learning_rate = 0.000001 (2613.6 examples/sec)
=> 2021-11-01 22:10:43.857148: step 69400, loss = 0.370108, learning_rate = 0.000001 (2615.2 examples/sec)
=> 2021-11-01 22:11:03.627123: step 69500, loss = 0.326678, learning_rate = 0.000001 (2611.6 examples/sec)
=> 2021-11-01 22:11:24.298586: step 69600, loss = 0.235393, learning_rate = 0.000001 (2631.0 examples/sec)
=> 2021-11-01 22:11:44.054792: step 69700, loss = 0.240059, learning_rate = 0.000001 (2613.4 examples/sec)
=> 2021-11-01 22:12:03.827778: step 69800, loss = 0.177200, learning_rate = 0.000001 (2611.3 examples/sec)
=> 2021-11-01 22:12:23.603178: step 69900, loss = 0.302017, learning_rate = 0.000001 (2610.9 examples/sec)
=> 2021-11-01 22:12:44.296163: step 70000, loss = 0.172744, learning_rate = 0.000001 (2624.6 examples/sec)
=> Model saved to file: ./logs/model-70000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947888, best accuracy 0.945898
=> Model saved to file: ./logs/model-70000.pth
=> patience = 100
=> 2021-11-01 22:13:16.492021: step 70100, loss = 0.234122, learning_rate = 0.000001 (2620.1 examples/sec)
=> 2021-11-01 22:13:36.213066: step 70200, loss = 0.210672, learning_rate = 0.000001 (2618.3 examples/sec)
=> 2021-11-01 22:13:55.936921: step 70300, loss = 0.207477, learning_rate = 0.000001 (2617.9 examples/sec)
=> 2021-11-01 22:14:16.662664: step 70400, loss = 0.181981, learning_rate = 0.000001 (2625.3 examples/sec)
=> 2021-11-01 22:14:36.446870: step 70500, loss = 0.174402, learning_rate = 0.000001 (2610.0 examples/sec)
=> 2021-11-01 22:14:56.217103: step 70600, loss = 0.169965, learning_rate = 0.000001 (2612.2 examples/sec)
=> 2021-11-01 22:15:16.000933: step 70700, loss = 0.214501, learning_rate = 0.000001 (2610.4 examples/sec)
=> 2021-11-01 22:15:36.702710: step 70800, loss = 0.323739, learning_rate = 0.000001 (2626.7 examples/sec)
=> 2021-11-01 22:15:56.499299: step 70900, loss = 0.190688, learning_rate = 0.000001 (2608.4 examples/sec)
=> 2021-11-01 22:16:16.285676: step 71000, loss = 0.208286, learning_rate = 0.000001 (2609.5 examples/sec)
=> Model saved to file: ./logs/model-71000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947505, best accuracy 0.947888
=> patience = 99
=> 2021-11-01 22:16:47.805271: step 71100, loss = 0.149967, learning_rate = 0.000001 (2615.4 examples/sec)
=> 2021-11-01 22:17:07.543069: step 71200, loss = 0.164629, learning_rate = 0.000001 (2616.5 examples/sec)
=> 2021-11-01 22:17:28.288007: step 71300, loss = 0.219608, learning_rate = 0.000001 (2628.0 examples/sec)
=> 2021-11-01 22:17:48.041151: step 71400, loss = 0.210559, learning_rate = 0.000001 (2613.9 examples/sec)
=> 2021-11-01 22:18:07.805505: step 71500, loss = 0.193837, learning_rate = 0.000001 (2612.5 examples/sec)
=> 2021-11-01 22:18:27.572768: step 71600, loss = 0.155984, learning_rate = 0.000001 (2612.1 examples/sec)
=> 2021-11-01 22:18:48.340154: step 71700, loss = 0.160953, learning_rate = 0.000001 (2623.3 examples/sec)
=> 2021-11-01 22:19:08.131951: step 71800, loss = 0.257519, learning_rate = 0.000001 (2608.8 examples/sec)
=> 2021-11-01 22:19:27.908281: step 71900, loss = 0.281992, learning_rate = 0.000001 (2611.0 examples/sec)
=> 2021-11-01 22:19:47.686705: step 72000, loss = 0.173776, learning_rate = 0.000001 (2610.5 examples/sec)
=> Model saved to file: ./logs/model-72000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.945822, best accuracy 0.947888
=> patience = 99
=> 2021-11-01 22:20:20.141797: step 72100, loss = 0.190005, learning_rate = 0.000001 (2631.0 examples/sec)
=> 2021-11-01 22:20:39.861017: step 72200, loss = 0.239429, learning_rate = 0.000001 (2618.2 examples/sec)
=> 2021-11-01 22:20:59.593661: step 72300, loss = 0.190442, learning_rate = 0.000001 (2616.8 examples/sec)
=> 2021-11-01 22:21:19.358231: step 72400, loss = 0.223817, learning_rate = 0.000001 (2612.5 examples/sec)
=> 2021-11-01 22:21:40.010363: step 72500, loss = 0.162779, learning_rate = 0.000001 (2630.0 examples/sec)
=> 2021-11-01 22:21:59.763001: step 72600, loss = 0.283990, learning_rate = 0.000001 (2614.0 examples/sec)
=> 2021-11-01 22:22:19.512555: step 72700, loss = 0.272758, learning_rate = 0.000001 (2614.7 examples/sec)
=> 2021-11-01 22:22:39.271743: step 72800, loss = 0.201914, learning_rate = 0.000001 (2613.2 examples/sec)
=> 2021-11-01 22:23:00.028744: step 72900, loss = 0.298291, learning_rate = 0.000001 (2625.3 examples/sec)
=> 2021-11-01 22:23:19.781402: step 73000, loss = 0.165199, learning_rate = 0.000001 (2614.1 examples/sec)
=> Model saved to file: ./logs/model-73000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947352, best accuracy 0.947888
=> patience = 99
=> 2021-11-01 22:23:51.347068: step 73100, loss = 0.182676, learning_rate = 0.000001 (2618.1 examples/sec)
=> 2021-11-01 22:24:11.085595: step 73200, loss = 0.135709, learning_rate = 0.000001 (2615.9 examples/sec)
=> 2021-11-01 22:24:31.834751: step 73300, loss = 0.193246, learning_rate = 0.000001 (2657.0 examples/sec)
=> 2021-11-01 22:24:51.594255: step 73400, loss = 0.285566, learning_rate = 0.000001 (2613.2 examples/sec)
=> 2021-11-01 22:25:11.358147: step 73500, loss = 0.173600, learning_rate = 0.000001 (2612.6 examples/sec)
=> 2021-11-01 22:25:31.133153: step 73600, loss = 0.192398, learning_rate = 0.000001 (2611.2 examples/sec)
=> 2021-11-01 22:25:51.813450: step 73700, loss = 0.223470, learning_rate = 0.000001 (2628.3 examples/sec)
=> 2021-11-01 22:26:11.590091: step 73800, loss = 0.225080, learning_rate = 0.000001 (2611.2 examples/sec)
=> 2021-11-01 22:26:31.389250: step 73900, loss = 0.166915, learning_rate = 0.000001 (2608.0 examples/sec)
=> 2021-11-01 22:26:51.187889: step 74000, loss = 0.221419, learning_rate = 0.000001 (2608.0 examples/sec)
=> Model saved to file: ./logs/model-74000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948347, best accuracy 0.947888
=> Model saved to file: ./logs/model-74000.pth
=> patience = 100
=> 2021-11-01 22:27:23.495421: step 74100, loss = 0.274432, learning_rate = 0.000001 (2618.1 examples/sec)
=> 2021-11-01 22:27:44.178325: step 74200, loss = 0.133658, learning_rate = 0.000001 (2627.1 examples/sec)
=> 2021-11-01 22:28:03.929261: step 74300, loss = 0.206806, learning_rate = 0.000001 (2614.2 examples/sec)
=> 2021-11-01 22:28:23.691937: step 74400, loss = 0.280539, learning_rate = 0.000001 (2612.7 examples/sec)
=> 2021-11-01 22:28:43.454653: step 74500, loss = 0.198888, learning_rate = 0.000001 (2612.9 examples/sec)
=> 2021-11-01 22:29:04.147229: step 74600, loss = 0.206338, learning_rate = 0.000001 (2634.5 examples/sec)
=> 2021-11-01 22:29:23.899754: step 74700, loss = 0.194734, learning_rate = 0.000001 (2614.1 examples/sec)
=> 2021-11-01 22:29:43.651363: step 74800, loss = 0.183256, learning_rate = 0.000001 (2614.1 examples/sec)
=> 2021-11-01 22:30:03.417785: step 74900, loss = 0.145984, learning_rate = 0.000001 (2612.1 examples/sec)
=> 2021-11-01 22:30:24.170520: step 75000, loss = 0.206528, learning_rate = 0.000001 (2629.2 examples/sec)
=> Model saved to file: ./logs/model-75000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.946051, best accuracy 0.948347
=> patience = 99
=> 2021-11-01 22:30:55.751713: step 75100, loss = 0.276218, learning_rate = 0.000001 (2619.6 examples/sec)
=> 2021-11-01 22:31:15.465086: step 75200, loss = 0.210714, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-01 22:31:35.203419: step 75300, loss = 0.264306, learning_rate = 0.000000 (2615.8 examples/sec)
=> 2021-11-01 22:31:55.901506: step 75400, loss = 0.198182, learning_rate = 0.000000 (2630.4 examples/sec)
=> 2021-11-01 22:32:15.650335: step 75500, loss = 0.176078, learning_rate = 0.000000 (2614.5 examples/sec)
=> 2021-11-01 22:32:35.397848: step 75600, loss = 0.177777, learning_rate = 0.000000 (2614.6 examples/sec)
=> 2021-11-01 22:32:55.224998: step 75700, loss = 0.163725, learning_rate = 0.000000 (2604.3 examples/sec)
=> 2021-11-01 22:33:15.926889: step 75800, loss = 0.201057, learning_rate = 0.000000 (2641.7 examples/sec)
=> 2021-11-01 22:33:35.693185: step 75900, loss = 0.202636, learning_rate = 0.000000 (2612.2 examples/sec)
=> 2021-11-01 22:33:55.476047: step 76000, loss = 0.216966, learning_rate = 0.000000 (2610.3 examples/sec)
=> Model saved to file: ./logs/model-76000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948500, best accuracy 0.948347
=> Model saved to file: ./logs/model-76000.pth
=> patience = 100
=> 2021-11-01 22:34:27.997612: step 76100, loss = 0.202841, learning_rate = 0.000000 (2617.6 examples/sec)
=> 2021-11-01 22:34:48.911923: step 76200, loss = 0.103439, learning_rate = 0.000000 (2623.4 examples/sec)
=> 2021-11-01 22:35:08.635564: step 76300, loss = 0.182791, learning_rate = 0.000000 (2617.9 examples/sec)
=> 2021-11-01 22:35:28.380609: step 76400, loss = 0.155323, learning_rate = 0.000000 (2614.8 examples/sec)
=> 2021-11-01 22:35:48.139198: step 76500, loss = 0.178083, learning_rate = 0.000000 (2613.2 examples/sec)
=> 2021-11-01 22:36:08.911224: step 76600, loss = 0.274215, learning_rate = 0.000000 (2632.0 examples/sec)
=> 2021-11-01 22:36:28.676613: step 76700, loss = 0.271287, learning_rate = 0.000000 (2612.5 examples/sec)
=> 2021-11-01 22:36:48.418879: step 76800, loss = 0.155155, learning_rate = 0.000000 (2615.2 examples/sec)
=> 2021-11-01 22:37:08.171679: step 76900, loss = 0.175564, learning_rate = 0.000000 (2614.1 examples/sec)
=> 2021-11-01 22:37:27.993282: step 77000, loss = 0.136709, learning_rate = 0.000000 (2605.7 examples/sec)
=> Model saved to file: ./logs/model-77000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948883, best accuracy 0.948500
=> Model saved to file: ./logs/model-77000.pth
=> patience = 100
=> 2021-11-01 22:38:01.118107: step 77100, loss = 0.209013, learning_rate = 0.000000 (2634.5 examples/sec)
=> 2021-11-01 22:38:20.910240: step 77200, loss = 0.329486, learning_rate = 0.000000 (2608.9 examples/sec)
=> 2021-11-01 22:38:40.648199: step 77300, loss = 0.144795, learning_rate = 0.000000 (2615.8 examples/sec)
=> 2021-11-01 22:39:00.388555: step 77400, loss = 0.249862, learning_rate = 0.000000 (2615.6 examples/sec)
=> 2021-11-01 22:39:21.079958: step 77500, loss = 0.206171, learning_rate = 0.000000 (2627.2 examples/sec)
=> 2021-11-01 22:39:40.832989: step 77600, loss = 0.125944, learning_rate = 0.000000 (2613.9 examples/sec)
=> 2021-11-01 22:40:00.575306: step 77700, loss = 0.171468, learning_rate = 0.000000 (2615.2 examples/sec)
=> 2021-11-01 22:40:20.332595: step 77800, loss = 0.219248, learning_rate = 0.000000 (2613.5 examples/sec)
=> 2021-11-01 22:40:41.044046: step 77900, loss = 0.301604, learning_rate = 0.000000 (2625.1 examples/sec)
=> 2021-11-01 22:41:00.810939: step 78000, loss = 0.176864, learning_rate = 0.000000 (2612.2 examples/sec)
=> Model saved to file: ./logs/model-78000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948653, best accuracy 0.948883
=> patience = 99
=> 2021-11-01 22:41:32.343752: step 78100, loss = 0.159167, learning_rate = 0.000000 (2616.7 examples/sec)
=> 2021-11-01 22:41:52.056916: step 78200, loss = 0.251341, learning_rate = 0.000000 (2619.3 examples/sec)
=> 2021-11-01 22:42:12.690313: step 78300, loss = 0.186855, learning_rate = 0.000000 (2634.0 examples/sec)
=> 2021-11-01 22:42:32.421120: step 78400, loss = 0.164648, learning_rate = 0.000000 (2616.9 examples/sec)
=> 2021-11-01 22:42:52.172166: step 78500, loss = 0.146955, learning_rate = 0.000000 (2614.4 examples/sec)
=> 2021-11-01 22:43:11.914430: step 78600, loss = 0.234326, learning_rate = 0.000000 (2615.3 examples/sec)
=> 2021-11-01 22:43:32.618706: step 78700, loss = 0.164305, learning_rate = 0.000000 (2627.2 examples/sec)
=> 2021-11-01 22:43:52.482037: step 78800, loss = 0.212693, learning_rate = 0.000000 (2599.4 examples/sec)
=> 2021-11-01 22:44:12.251342: step 78900, loss = 0.191853, learning_rate = 0.000000 (2612.0 examples/sec)
=> 2021-11-01 22:44:32.003314: step 79000, loss = 0.166255, learning_rate = 0.000000 (2614.2 examples/sec)
=> Model saved to file: ./logs/model-79000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947123, best accuracy 0.948883
=> patience = 99
=> 2021-11-01 22:45:04.738321: step 79100, loss = 0.185014, learning_rate = 0.000000 (2631.5 examples/sec)
=> 2021-11-01 22:45:24.424248: step 79200, loss = 0.245082, learning_rate = 0.000000 (2622.7 examples/sec)
=> 2021-11-01 22:45:44.089296: step 79300, loss = 0.144755, learning_rate = 0.000000 (2625.7 examples/sec)
=> 2021-11-01 22:46:03.785882: step 79400, loss = 0.190045, learning_rate = 0.000000 (2621.3 examples/sec)
=> 2021-11-01 22:46:24.447907: step 79500, loss = 0.214842, learning_rate = 0.000000 (2631.1 examples/sec)
=> 2021-11-01 22:46:44.171444: step 79600, loss = 0.153509, learning_rate = 0.000000 (2618.1 examples/sec)
=> 2021-11-01 22:47:03.920393: step 79700, loss = 0.270297, learning_rate = 0.000000 (2615.1 examples/sec)
=> 2021-11-01 22:47:23.668496: step 79800, loss = 0.192061, learning_rate = 0.000000 (2614.5 examples/sec)
=> 2021-11-01 22:47:43.416255: step 79900, loss = 0.281100, learning_rate = 0.000000 (2615.3 examples/sec)
=> 2021-11-01 22:48:04.164132: step 80000, loss = 0.233595, learning_rate = 0.000000 (2626.7 examples/sec)
=> Model saved to file: ./logs/model-80000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947658, best accuracy 0.948883
=> patience = 99
=> 2021-11-01 22:48:35.704944: step 80100, loss = 0.186093, learning_rate = 0.000000 (2619.0 examples/sec)
=> 2021-11-01 22:48:55.420927: step 80200, loss = 0.207304, learning_rate = 0.000000 (2618.9 examples/sec)
=> 2021-11-01 22:49:15.215090: step 80300, loss = 0.164157, learning_rate = 0.000000 (2608.4 examples/sec)
=> 2021-11-01 22:49:35.886756: step 80400, loss = 0.137366, learning_rate = 0.000000 (2631.4 examples/sec)
=> 2021-11-01 22:49:55.626586: step 80500, loss = 0.162334, learning_rate = 0.000000 (2615.7 examples/sec)
=> 2021-11-01 22:50:15.382265: step 80600, loss = 0.151419, learning_rate = 0.000000 (2613.8 examples/sec)
=> 2021-11-01 22:50:35.136778: step 80700, loss = 0.149131, learning_rate = 0.000000 (2613.8 examples/sec)
=> 2021-11-01 22:50:55.793049: step 80800, loss = 0.243662, learning_rate = 0.000000 (2629.4 examples/sec)
=> 2021-11-01 22:51:15.543981: step 80900, loss = 0.293437, learning_rate = 0.000000 (2614.4 examples/sec)
=> 2021-11-01 22:51:35.279958: step 81000, loss = 0.155419, learning_rate = 0.000000 (2616.3 examples/sec)
=> Model saved to file: ./logs/model-81000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.946817, best accuracy 0.948883
=> patience = 99
=> 2021-11-01 22:52:06.891043: step 81100, loss = 0.238563, learning_rate = 0.000000 (2618.7 examples/sec)
=> 2021-11-01 22:52:27.644786: step 81200, loss = 0.169240, learning_rate = 0.000000 (2632.5 examples/sec)
=> 2021-11-01 22:52:47.345169: step 81300, loss = 0.206286, learning_rate = 0.000000 (2621.1 examples/sec)
=> 2021-11-01 22:53:07.080620: step 81400, loss = 0.382646, learning_rate = 0.000000 (2616.3 examples/sec)
=> 2021-11-01 22:53:26.823092: step 81500, loss = 0.176788, learning_rate = 0.000000 (2615.6 examples/sec)
=> 2021-11-01 22:53:47.676014: step 81600, loss = 0.170431, learning_rate = 0.000000 (2629.8 examples/sec)
=> 2021-11-01 22:54:07.420749: step 81700, loss = 0.190095, learning_rate = 0.000000 (2615.3 examples/sec)
=> 2021-11-01 22:54:27.179872: step 81800, loss = 0.192986, learning_rate = 0.000000 (2613.3 examples/sec)
=> 2021-11-01 22:54:46.927836: step 81900, loss = 0.157285, learning_rate = 0.000000 (2614.7 examples/sec)
=> 2021-11-01 22:55:07.646808: step 82000, loss = 0.185977, learning_rate = 0.000000 (2645.3 examples/sec)
=> Model saved to file: ./logs/model-82000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947505, best accuracy 0.948883
=> patience = 99
=> 2021-11-01 22:55:39.082598: step 82100, loss = 0.208584, learning_rate = 0.000000 (2615.0 examples/sec)
=> 2021-11-01 22:55:58.797302: step 82200, loss = 0.219175, learning_rate = 0.000000 (2618.9 examples/sec)
=> 2021-11-01 22:56:18.522401: step 82300, loss = 0.232850, learning_rate = 0.000000 (2617.7 examples/sec)
=> 2021-11-01 22:56:39.274346: step 82400, loss = 0.166469, learning_rate = 0.000000 (2617.2 examples/sec)
=> 2021-11-01 22:56:58.983208: step 82500, loss = 0.237001, learning_rate = 0.000000 (2620.1 examples/sec)
=> 2021-11-01 22:57:18.672271: step 82600, loss = 0.179314, learning_rate = 0.000000 (2622.3 examples/sec)
=> 2021-11-01 22:57:38.369208: step 82700, loss = 0.217558, learning_rate = 0.000000 (2621.3 examples/sec)
=> 2021-11-01 22:57:58.092264: step 82800, loss = 0.257547, learning_rate = 0.000000 (2618.8 examples/sec)
=> 2021-11-01 22:58:18.841030: step 82900, loss = 0.192408, learning_rate = 0.000000 (2617.0 examples/sec)
=> 2021-11-01 22:58:38.583018: step 83000, loss = 0.242947, learning_rate = 0.000000 (2615.5 examples/sec)
=> Model saved to file: ./logs/model-83000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949418, best accuracy 0.948883
=> Model saved to file: ./logs/model-83000.pth
=> patience = 100
=> 2021-11-01 22:59:10.474591: step 83100, loss = 0.267688, learning_rate = 0.000000 (2621.0 examples/sec)
=> 2021-11-01 22:59:30.181272: step 83200, loss = 0.139262, learning_rate = 0.000000 (2620.2 examples/sec)
=> 2021-11-01 22:59:51.021006: step 83300, loss = 0.257207, learning_rate = 0.000000 (2633.4 examples/sec)
=> 2021-11-01 23:00:10.747113: step 83400, loss = 0.180462, learning_rate = 0.000000 (2617.7 examples/sec)
=> 2021-11-01 23:00:30.471091: step 83500, loss = 0.184045, learning_rate = 0.000000 (2617.9 examples/sec)
=> 2021-11-01 23:00:50.255547: step 83600, loss = 0.113457, learning_rate = 0.000000 (2609.7 examples/sec)
=> 2021-11-01 23:01:10.933310: step 83700, loss = 0.239362, learning_rate = 0.000000 (2628.5 examples/sec)
=> 2021-11-01 23:01:30.670328: step 83800, loss = 0.136231, learning_rate = 0.000000 (2616.0 examples/sec)
=> 2021-11-01 23:01:50.435301: step 83900, loss = 0.269310, learning_rate = 0.000000 (2612.3 examples/sec)
=> 2021-11-01 23:02:10.200497: step 84000, loss = 0.192753, learning_rate = 0.000000 (2612.5 examples/sec)
=> Model saved to file: ./logs/model-84000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.946893, best accuracy 0.949418
=> patience = 99
=> 2021-11-01 23:02:42.535588: step 84100, loss = 0.206741, learning_rate = 0.000000 (2635.9 examples/sec)
=> 2021-11-01 23:03:02.227707: step 84200, loss = 0.141248, learning_rate = 0.000000 (2622.3 examples/sec)
=> 2021-11-01 23:03:21.952452: step 84300, loss = 0.263942, learning_rate = 0.000000 (2617.8 examples/sec)
=> 2021-11-01 23:03:41.683451: step 84400, loss = 0.216036, learning_rate = 0.000000 (2616.9 examples/sec)
=> 2021-11-01 23:04:02.457522: step 84500, loss = 0.207396, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-01 23:04:22.199770: step 84600, loss = 0.193874, learning_rate = 0.000000 (2615.7 examples/sec)
=> 2021-11-01 23:04:41.934034: step 84700, loss = 0.192357, learning_rate = 0.000000 (2616.5 examples/sec)
=> 2021-11-01 23:05:01.689102: step 84800, loss = 0.159253, learning_rate = 0.000000 (2613.7 examples/sec)
=> 2021-11-01 23:05:22.342135: step 84900, loss = 0.218214, learning_rate = 0.000000 (2641.0 examples/sec)
=> 2021-11-01 23:05:42.090981: step 85000, loss = 0.174315, learning_rate = 0.000000 (2614.5 examples/sec)
=> Model saved to file: ./logs/model-85000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947276, best accuracy 0.949418
=> patience = 99
=> 2021-11-01 23:06:13.751960: step 85100, loss = 0.157065, learning_rate = 0.000000 (2619.9 examples/sec)
=> 2021-11-01 23:06:33.454227: step 85200, loss = 0.205770, learning_rate = 0.000000 (2620.8 examples/sec)
=> 2021-11-01 23:06:54.072949: step 85300, loss = 0.268416, learning_rate = 0.000000 (2634.9 examples/sec)
=> 2021-11-01 23:07:13.802780: step 85400, loss = 0.237228, learning_rate = 0.000000 (2617.1 examples/sec)
=> 2021-11-01 23:07:33.555078: step 85500, loss = 0.262632, learning_rate = 0.000000 (2614.4 examples/sec)
=> 2021-11-01 23:07:53.301616: step 85600, loss = 0.181893, learning_rate = 0.000000 (2614.9 examples/sec)
=> 2021-11-01 23:08:13.998719: step 85700, loss = 0.143035, learning_rate = 0.000000 (2626.8 examples/sec)
=> 2021-11-01 23:08:33.746864: step 85800, loss = 0.144448, learning_rate = 0.000000 (2614.8 examples/sec)
=> 2021-11-01 23:08:53.497092: step 85900, loss = 0.170166, learning_rate = 0.000000 (2614.5 examples/sec)
=> 2021-11-01 23:09:13.266461: step 86000, loss = 0.221537, learning_rate = 0.000000 (2612.0 examples/sec)
=> Model saved to file: ./logs/model-86000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.946970, best accuracy 0.949418
=> patience = 99
=> 2021-11-01 23:09:44.601568: step 86100, loss = 0.198374, learning_rate = 0.000000 (2620.6 examples/sec)
=> 2021-11-01 23:10:05.263590: step 86200, loss = 0.115461, learning_rate = 0.000000 (2633.7 examples/sec)
=> 2021-11-01 23:10:24.993164: step 86300, loss = 0.150699, learning_rate = 0.000000 (2617.1 examples/sec)
=> 2021-11-01 23:10:44.722703: step 86400, loss = 0.321484, learning_rate = 0.000000 (2617.2 examples/sec)
=> 2021-11-01 23:11:04.477496: step 86500, loss = 0.210342, learning_rate = 0.000000 (2613.8 examples/sec)
=> 2021-11-01 23:11:25.193217: step 86600, loss = 0.158610, learning_rate = 0.000000 (2631.4 examples/sec)
=> 2021-11-01 23:11:44.930801: step 86700, loss = 0.174528, learning_rate = 0.000000 (2615.9 examples/sec)
=> 2021-11-01 23:12:04.683276: step 86800, loss = 0.189350, learning_rate = 0.000000 (2613.8 examples/sec)
=> 2021-11-01 23:12:24.434742: step 86900, loss = 0.170619, learning_rate = 0.000000 (2614.2 examples/sec)
=> 2021-11-01 23:12:45.353238: step 87000, loss = 0.115595, learning_rate = 0.000000 (2625.3 examples/sec)
=> Model saved to file: ./logs/model-87000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948271, best accuracy 0.949418
=> patience = 99
=> 2021-11-01 23:13:16.904542: step 87100, loss = 0.148902, learning_rate = 0.000000 (2620.5 examples/sec)
=> 2021-11-01 23:13:36.707334: step 87200, loss = 0.178073, learning_rate = 0.000000 (2607.3 examples/sec)
=> 2021-11-01 23:13:56.465251: step 87300, loss = 0.193114, learning_rate = 0.000000 (2613.5 examples/sec)
=> 2021-11-01 23:14:17.223304: step 87400, loss = 0.167340, learning_rate = 0.000000 (2618.9 examples/sec)
=> 2021-11-01 23:14:37.132076: step 87500, loss = 0.140016, learning_rate = 0.000000 (2593.3 examples/sec)
=> 2021-11-01 23:14:56.929669: step 87600, loss = 0.141490, learning_rate = 0.000000 (2608.0 examples/sec)
=> 2021-11-01 23:15:16.724320: step 87700, loss = 0.160777, learning_rate = 0.000000 (2608.5 examples/sec)
=> 2021-11-01 23:15:37.662123: step 87800, loss = 0.335555, learning_rate = 0.000000 (2617.4 examples/sec)
=> 2021-11-01 23:15:57.469862: step 87900, loss = 0.180198, learning_rate = 0.000000 (2606.8 examples/sec)
=> 2021-11-01 23:16:17.277832: step 88000, loss = 0.202575, learning_rate = 0.000000 (2606.9 examples/sec)
=> Model saved to file: ./logs/model-88000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947046, best accuracy 0.949418
=> patience = 99
=> 2021-11-01 23:16:49.018369: step 88100, loss = 0.220137, learning_rate = 0.000000 (2614.0 examples/sec)
=> 2021-11-01 23:17:09.780433: step 88200, loss = 0.150532, learning_rate = 0.000000 (2641.7 examples/sec)
=> 2021-11-01 23:17:29.525975: step 88300, loss = 0.179685, learning_rate = 0.000000 (2615.1 examples/sec)
=> 2021-11-01 23:17:49.362010: step 88400, loss = 0.217606, learning_rate = 0.000000 (2603.0 examples/sec)
=> 2021-11-01 23:18:09.162478: step 88500, loss = 0.201021, learning_rate = 0.000000 (2607.5 examples/sec)
=> 2021-11-01 23:18:29.898481: step 88600, loss = 0.152964, learning_rate = 0.000000 (2621.1 examples/sec)
=> 2021-11-01 23:18:49.699724: step 88700, loss = 0.151811, learning_rate = 0.000000 (2607.9 examples/sec)
=> 2021-11-01 23:19:09.540549: step 88800, loss = 0.158736, learning_rate = 0.000000 (2602.7 examples/sec)
=> 2021-11-01 23:19:29.350857: step 88900, loss = 0.123409, learning_rate = 0.000000 (2606.4 examples/sec)
=> 2021-11-01 23:19:49.151672: step 89000, loss = 0.155963, learning_rate = 0.000000 (2607.8 examples/sec)
=> Model saved to file: ./logs/model-89000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948806, best accuracy 0.949418
=> patience = 99
=> 2021-11-01 23:20:21.827646: step 89100, loss = 0.116939, learning_rate = 0.000000 (2627.2 examples/sec)
=> 2021-11-01 23:20:41.571672: step 89200, loss = 0.195921, learning_rate = 0.000000 (2615.2 examples/sec)
=> 2021-11-01 23:21:01.354909: step 89300, loss = 0.224396, learning_rate = 0.000000 (2610.1 examples/sec)
=> 2021-11-01 23:21:21.113484: step 89400, loss = 0.298639, learning_rate = 0.000000 (2613.5 examples/sec)
=> 2021-11-01 23:21:41.835560: step 89500, loss = 0.202236, learning_rate = 0.000000 (2624.8 examples/sec)
=> 2021-11-01 23:22:01.638623: step 89600, loss = 0.254401, learning_rate = 0.000000 (2607.5 examples/sec)
=> 2021-11-01 23:22:21.450715: step 89700, loss = 0.100727, learning_rate = 0.000000 (2606.1 examples/sec)
=> 2021-11-01 23:22:41.240940: step 89800, loss = 0.138608, learning_rate = 0.000000 (2609.1 examples/sec)
=> 2021-11-01 23:23:02.002091: step 89900, loss = 0.188573, learning_rate = 0.000000 (2625.9 examples/sec)
=> 2021-11-01 23:23:21.820166: step 90000, loss = 0.154449, learning_rate = 0.000000 (2607.0 examples/sec)
=> Model saved to file: ./logs/model-90000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951178, best accuracy 0.949418
=> Model saved to file: ./logs/model-90000.pth
=> patience = 100
=> 2021-11-01 23:23:54.314141: step 90100, loss = 0.197046, learning_rate = 0.000000 (2614.8 examples/sec)
=> 2021-11-01 23:24:14.062493: step 90200, loss = 0.155169, learning_rate = 0.000000 (2614.7 examples/sec)
=> 2021-11-01 23:24:34.804323: step 90300, loss = 0.229967, learning_rate = 0.000000 (2623.2 examples/sec)
=> 2021-11-01 23:24:54.592959: step 90400, loss = 0.162408, learning_rate = 0.000000 (2609.3 examples/sec)
=> 2021-11-01 23:25:14.368034: step 90500, loss = 0.150380, learning_rate = 0.000000 (2611.2 examples/sec)
=> 2021-11-01 23:25:34.145864: step 90600, loss = 0.158679, learning_rate = 0.000000 (2610.8 examples/sec)
=> 2021-11-01 23:25:55.049672: step 90700, loss = 0.211393, learning_rate = 0.000000 (2624.2 examples/sec)
=> 2021-11-01 23:26:14.837571: step 90800, loss = 0.139089, learning_rate = 0.000000 (2609.8 examples/sec)
=> 2021-11-01 23:26:34.615409: step 90900, loss = 0.122211, learning_rate = 0.000000 (2610.8 examples/sec)
=> 2021-11-01 23:26:54.398608: step 91000, loss = 0.215112, learning_rate = 0.000000 (2610.2 examples/sec)
=> Model saved to file: ./logs/model-91000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947658, best accuracy 0.951178
=> patience = 99
=> 2021-11-01 23:27:27.026735: step 91100, loss = 0.277459, learning_rate = 0.000000 (2642.6 examples/sec)
=> 2021-11-01 23:27:46.793799: step 91200, loss = 0.187627, learning_rate = 0.000000 (2612.2 examples/sec)
=> 2021-11-01 23:28:06.576296: step 91300, loss = 0.168974, learning_rate = 0.000000 (2610.1 examples/sec)
=> 2021-11-01 23:28:26.374271: step 91400, loss = 0.212567, learning_rate = 0.000000 (2607.9 examples/sec)
=> 2021-11-01 23:28:47.299489: step 91500, loss = 0.149657, learning_rate = 0.000000 (2619.3 examples/sec)
=> 2021-11-01 23:29:07.119617: step 91600, loss = 0.121318, learning_rate = 0.000000 (2605.4 examples/sec)
=> 2021-11-01 23:29:26.936025: step 91700, loss = 0.219927, learning_rate = 0.000000 (2605.6 examples/sec)
=> 2021-11-01 23:29:46.754059: step 91800, loss = 0.175217, learning_rate = 0.000000 (2605.6 examples/sec)
=> 2021-11-01 23:30:06.569812: step 91900, loss = 0.209473, learning_rate = 0.000000 (2606.3 examples/sec)
=> 2021-11-01 23:30:27.325628: step 92000, loss = 0.175764, learning_rate = 0.000000 (2618.8 examples/sec)
=> Model saved to file: ./logs/model-92000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950184, best accuracy 0.951178
=> patience = 99
=> 2021-11-01 23:30:59.071972: step 92100, loss = 0.168174, learning_rate = 0.000000 (2616.2 examples/sec)
=> 2021-11-01 23:31:18.851805: step 92200, loss = 0.172849, learning_rate = 0.000000 (2610.9 examples/sec)
=> 2021-11-01 23:31:38.632935: step 92300, loss = 0.149576, learning_rate = 0.000000 (2610.4 examples/sec)
=> 2021-11-01 23:31:59.379692: step 92400, loss = 0.204568, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-01 23:32:19.187277: step 92500, loss = 0.220438, learning_rate = 0.000000 (2606.8 examples/sec)
=> 2021-11-01 23:32:38.967289: step 92600, loss = 0.138877, learning_rate = 0.000000 (2610.3 examples/sec)
=> 2021-11-01 23:32:58.766615: step 92700, loss = 0.155880, learning_rate = 0.000000 (2608.0 examples/sec)
=> 2021-11-01 23:33:19.580140: step 92800, loss = 0.203581, learning_rate = 0.000000 (2622.7 examples/sec)
=> 2021-11-01 23:33:39.368740: step 92900, loss = 0.236908, learning_rate = 0.000000 (2609.2 examples/sec)
=> 2021-11-01 23:33:59.117629: step 93000, loss = 0.232654, learning_rate = 0.000000 (2614.6 examples/sec)
=> Model saved to file: ./logs/model-93000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950184, best accuracy 0.951178
=> patience = 99
=> 2021-11-01 23:34:30.656212: step 93100, loss = 0.255401, learning_rate = 0.000000 (2617.2 examples/sec)
=> 2021-11-01 23:34:51.523848: step 93200, loss = 0.291620, learning_rate = 0.000000 (2623.9 examples/sec)
=> 2021-11-01 23:35:11.240206: step 93300, loss = 0.180664, learning_rate = 0.000000 (2618.7 examples/sec)
=> 2021-11-01 23:35:31.013145: step 93400, loss = 0.185392, learning_rate = 0.000000 (2611.2 examples/sec)
=> 2021-11-01 23:35:50.782871: step 93500, loss = 0.223583, learning_rate = 0.000000 (2611.9 examples/sec)
=> 2021-11-01 23:36:11.504288: step 93600, loss = 0.145693, learning_rate = 0.000000 (2624.2 examples/sec)
=> 2021-11-01 23:36:31.302766: step 93700, loss = 0.264424, learning_rate = 0.000000 (2607.9 examples/sec)
=> 2021-11-01 23:36:51.158101: step 93800, loss = 0.156128, learning_rate = 0.000000 (2600.5 examples/sec)
=> 2021-11-01 23:37:10.970772: step 93900, loss = 0.092362, learning_rate = 0.000000 (2606.1 examples/sec)
=> 2021-11-01 23:37:31.679591: step 94000, loss = 0.214608, learning_rate = 0.000000 (2625.3 examples/sec)
=> Model saved to file: ./logs/model-94000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948194, best accuracy 0.951178
=> patience = 99
=> 2021-11-01 23:38:03.267008: step 94100, loss = 0.144141, learning_rate = 0.000000 (2616.2 examples/sec)
=> 2021-11-01 23:38:22.950095: step 94200, loss = 0.122841, learning_rate = 0.000000 (2623.4 examples/sec)
=> 2021-11-01 23:38:42.670339: step 94300, loss = 0.145120, learning_rate = 0.000000 (2618.5 examples/sec)
=> 2021-11-01 23:39:03.499850: step 94400, loss = 0.159828, learning_rate = 0.000000 (2620.7 examples/sec)
=> 2021-11-01 23:39:23.259263: step 94500, loss = 0.159056, learning_rate = 0.000000 (2613.0 examples/sec)
=> 2021-11-01 23:39:43.038319: step 94600, loss = 0.139757, learning_rate = 0.000000 (2610.6 examples/sec)
=> 2021-11-01 23:40:02.846752: step 94700, loss = 0.102677, learning_rate = 0.000000 (2606.8 examples/sec)
=> 2021-11-01 23:40:22.640416: step 94800, loss = 0.206530, learning_rate = 0.000000 (2609.2 examples/sec)
=> 2021-11-01 23:40:43.375721: step 94900, loss = 0.140907, learning_rate = 0.000000 (2621.5 examples/sec)
=> 2021-11-01 23:41:03.161154: step 95000, loss = 0.204634, learning_rate = 0.000000 (2609.6 examples/sec)
=> Model saved to file: ./logs/model-95000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951025, best accuracy 0.951178
=> patience = 99
=> 2021-11-01 23:41:34.942638: step 95100, loss = 0.196939, learning_rate = 0.000000 (2615.7 examples/sec)
=> 2021-11-01 23:41:54.667516: step 95200, loss = 0.165766, learning_rate = 0.000000 (2617.8 examples/sec)
=> 2021-11-01 23:42:15.302250: step 95300, loss = 0.208349, learning_rate = 0.000000 (2634.1 examples/sec)
=> 2021-11-01 23:42:35.041007: step 95400, loss = 0.171396, learning_rate = 0.000000 (2615.9 examples/sec)
=> 2021-11-01 23:42:54.801305: step 95500, loss = 0.271757, learning_rate = 0.000000 (2613.0 examples/sec)
=> 2021-11-01 23:43:14.558175: step 95600, loss = 0.198662, learning_rate = 0.000000 (2613.6 examples/sec)
=> 2021-11-01 23:43:35.394735: step 95700, loss = 0.181788, learning_rate = 0.000000 (2623.4 examples/sec)
=> 2021-11-01 23:43:55.192323: step 95800, loss = 0.122124, learning_rate = 0.000000 (2608.0 examples/sec)
=> 2021-11-01 23:44:14.989132: step 95900, loss = 0.210308, learning_rate = 0.000000 (2608.2 examples/sec)
=> 2021-11-01 23:44:34.786550: step 96000, loss = 0.194790, learning_rate = 0.000000 (2608.1 examples/sec)
=> Model saved to file: ./logs/model-96000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949112, best accuracy 0.951178
=> patience = 99
=> 2021-11-01 23:45:07.390936: step 96100, loss = 0.143765, learning_rate = 0.000000 (2630.0 examples/sec)
=> 2021-11-01 23:45:27.134308: step 96200, loss = 0.151167, learning_rate = 0.000000 (2615.2 examples/sec)
=> 2021-11-01 23:45:46.897911: step 96300, loss = 0.165140, learning_rate = 0.000000 (2612.7 examples/sec)
=> 2021-11-01 23:46:06.670422: step 96400, loss = 0.249990, learning_rate = 0.000000 (2611.4 examples/sec)
=> 2021-11-01 23:46:27.443120: step 96500, loss = 0.178104, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-01 23:46:47.246665: step 96600, loss = 0.162542, learning_rate = 0.000000 (2607.4 examples/sec)
=> 2021-11-01 23:47:07.068121: step 96700, loss = 0.253833, learning_rate = 0.000000 (2605.1 examples/sec)
=> 2021-11-01 23:47:26.873339: step 96800, loss = 0.106531, learning_rate = 0.000000 (2607.1 examples/sec)
=> 2021-11-01 23:47:47.596857: step 96900, loss = 0.188145, learning_rate = 0.000000 (2623.3 examples/sec)
=> 2021-11-01 23:48:07.387612: step 97000, loss = 0.143741, learning_rate = 0.000000 (2609.1 examples/sec)
=> Model saved to file: ./logs/model-97000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950031, best accuracy 0.951178
=> patience = 99
=> 2021-11-01 23:48:39.115356: step 97100, loss = 0.231909, learning_rate = 0.000000 (2618.4 examples/sec)
=> 2021-11-01 23:48:58.851269: step 97200, loss = 0.162474, learning_rate = 0.000000 (2616.3 examples/sec)
=> 2021-11-01 23:49:19.686019: step 97300, loss = 0.167892, learning_rate = 0.000000 (2625.8 examples/sec)
=> 2021-11-01 23:49:39.449719: step 97400, loss = 0.166467, learning_rate = 0.000000 (2612.9 examples/sec)
=> 2021-11-01 23:49:59.211902: step 97500, loss = 0.111528, learning_rate = 0.000000 (2612.8 examples/sec)
=> 2021-11-01 23:50:18.987243: step 97600, loss = 0.230717, learning_rate = 0.000000 (2611.0 examples/sec)
=> 2021-11-01 23:50:38.747255: step 97700, loss = 0.122284, learning_rate = 0.000000 (2613.6 examples/sec)
=> 2021-11-01 23:50:59.582933: step 97800, loss = 0.205337, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-01 23:51:19.378152: step 97900, loss = 0.180800, learning_rate = 0.000000 (2608.4 examples/sec)
=> 2021-11-01 23:51:39.188344: step 98000, loss = 0.140109, learning_rate = 0.000000 (2606.3 examples/sec)
=> Model saved to file: ./logs/model-98000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951408, best accuracy 0.951178
=> Model saved to file: ./logs/model-98000.pth
=> patience = 100
=> 2021-11-01 23:52:11.614468: step 98100, loss = 0.186744, learning_rate = 0.000000 (2612.8 examples/sec)
=> 2021-11-01 23:52:32.301815: step 98200, loss = 0.252426, learning_rate = 0.000000 (2627.7 examples/sec)
=> 2021-11-01 23:52:52.087848: step 98300, loss = 0.178847, learning_rate = 0.000000 (2609.7 examples/sec)
=> 2021-11-01 23:53:11.866484: step 98400, loss = 0.145602, learning_rate = 0.000000 (2610.6 examples/sec)
=> 2021-11-01 23:53:31.667185: step 98500, loss = 0.111066, learning_rate = 0.000000 (2607.6 examples/sec)
=> 2021-11-01 23:53:52.445330: step 98600, loss = 0.151469, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-01 23:54:12.274057: step 98700, loss = 0.166063, learning_rate = 0.000000 (2604.2 examples/sec)
=> 2021-11-01 23:54:32.087109: step 98800, loss = 0.158047, learning_rate = 0.000000 (2606.2 examples/sec)
=> 2021-11-01 23:54:51.913701: step 98900, loss = 0.193126, learning_rate = 0.000000 (2604.4 examples/sec)
=> 2021-11-01 23:55:12.674174: step 99000, loss = 0.148253, learning_rate = 0.000000 (2616.8 examples/sec)
=> Model saved to file: ./logs/model-99000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950872, best accuracy 0.951408
=> patience = 99
=> 2021-11-01 23:55:44.355315: step 99100, loss = 0.105476, learning_rate = 0.000000 (2616.0 examples/sec)
=> 2021-11-01 23:56:04.098841: step 99200, loss = 0.131442, learning_rate = 0.000000 (2615.4 examples/sec)
=> 2021-11-01 23:56:23.857114: step 99300, loss = 0.181017, learning_rate = 0.000000 (2613.4 examples/sec)
=> 2021-11-01 23:56:44.613569: step 99400, loss = 0.199978, learning_rate = 0.000000 (2621.8 examples/sec)
=> 2021-11-01 23:57:04.394715: step 99500, loss = 0.189664, learning_rate = 0.000000 (2610.5 examples/sec)
=> 2021-11-01 23:57:24.166079: step 99600, loss = 0.264698, learning_rate = 0.000000 (2611.5 examples/sec)
=> 2021-11-01 23:57:43.948648: step 99700, loss = 0.167920, learning_rate = 0.000000 (2609.9 examples/sec)
=> 2021-11-01 23:58:04.668636: step 99800, loss = 0.165741, learning_rate = 0.000000 (2626.2 examples/sec)
=> 2021-11-01 23:58:24.459123: step 99900, loss = 0.146979, learning_rate = 0.000000 (2609.1 examples/sec)
=> 2021-11-01 23:58:44.246160: step 100000, loss = 0.127383, learning_rate = 0.000000 (2609.5 examples/sec)
=> Model saved to file: ./logs/model-100000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951102, best accuracy 0.951408
=> patience = 99
=> 2021-11-01 23:59:15.950030: step 100100, loss = 0.129516, learning_rate = 0.000000 (2616.3 examples/sec)
=> 2021-11-01 23:59:36.586642: step 100200, loss = 0.185093, learning_rate = 0.000000 (2634.5 examples/sec)
=> 2021-11-01 23:59:56.317951: step 100300, loss = 0.128241, learning_rate = 0.000000 (2617.0 examples/sec)
=> 2021-11-02 00:00:16.098138: step 100400, loss = 0.114297, learning_rate = 0.000000 (2610.6 examples/sec)
=> 2021-11-02 00:00:35.866291: step 100500, loss = 0.133888, learning_rate = 0.000000 (2612.3 examples/sec)
=> 2021-11-02 00:00:55.665181: step 100600, loss = 0.096106, learning_rate = 0.000000 (2608.6 examples/sec)
=> 2021-11-02 00:01:16.412129: step 100700, loss = 0.136608, learning_rate = 0.000000 (2619.1 examples/sec)
=> 2021-11-02 00:01:36.197366: step 100800, loss = 0.168004, learning_rate = 0.000000 (2609.8 examples/sec)
=> 2021-11-02 00:01:55.980573: step 100900, loss = 0.138456, learning_rate = 0.000000 (2610.1 examples/sec)
=> 2021-11-02 00:02:15.778662: step 101000, loss = 0.142895, learning_rate = 0.000000 (2608.1 examples/sec)
=> Model saved to file: ./logs/model-101000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951714, best accuracy 0.951408
=> Model saved to file: ./logs/model-101000.pth
=> patience = 100
=> 2021-11-02 00:02:48.953786: step 101100, loss = 0.139237, learning_rate = 0.000000 (2628.5 examples/sec)
=> 2021-11-02 00:03:08.695829: step 101200, loss = 0.203852, learning_rate = 0.000000 (2615.6 examples/sec)
=> 2021-11-02 00:03:28.441496: step 101300, loss = 0.241173, learning_rate = 0.000000 (2615.0 examples/sec)
=> 2021-11-02 00:03:48.219200: step 101400, loss = 0.165784, learning_rate = 0.000000 (2610.8 examples/sec)
=> 2021-11-02 00:04:08.980601: step 101500, loss = 0.187365, learning_rate = 0.000000 (2619.4 examples/sec)
=> 2021-11-02 00:04:28.758982: step 101600, loss = 0.135730, learning_rate = 0.000000 (2610.8 examples/sec)
=> 2021-11-02 00:04:48.539463: step 101700, loss = 0.094023, learning_rate = 0.000000 (2610.3 examples/sec)
=> 2021-11-02 00:05:08.333207: step 101800, loss = 0.150130, learning_rate = 0.000000 (2608.7 examples/sec)
=> 2021-11-02 00:05:28.974301: step 101900, loss = 0.086359, learning_rate = 0.000000 (2633.7 examples/sec)
=> 2021-11-02 00:05:48.749687: step 102000, loss = 0.146355, learning_rate = 0.000000 (2611.1 examples/sec)
=> Model saved to file: ./logs/model-102000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950796, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 00:06:20.386357: step 102100, loss = 0.142895, learning_rate = 0.000000 (2621.8 examples/sec)
=> 2021-11-02 00:06:40.107147: step 102200, loss = 0.114459, learning_rate = 0.000000 (2618.3 examples/sec)
=> 2021-11-02 00:07:00.815295: step 102300, loss = 0.181828, learning_rate = 0.000000 (2632.0 examples/sec)
=> 2021-11-02 00:07:20.603036: step 102400, loss = 0.146098, learning_rate = 0.000000 (2609.5 examples/sec)
=> 2021-11-02 00:07:40.390095: step 102500, loss = 0.144594, learning_rate = 0.000000 (2609.5 examples/sec)
=> 2021-11-02 00:08:00.188005: step 102600, loss = 0.131760, learning_rate = 0.000000 (2608.2 examples/sec)
=> 2021-11-02 00:08:20.915927: step 102700, loss = 0.173386, learning_rate = 0.000000 (2622.9 examples/sec)
=> 2021-11-02 00:08:40.726016: step 102800, loss = 0.156234, learning_rate = 0.000000 (2606.7 examples/sec)
=> 2021-11-02 00:09:00.534156: step 102900, loss = 0.155029, learning_rate = 0.000000 (2607.1 examples/sec)
=> 2021-11-02 00:09:20.331321: step 103000, loss = 0.163557, learning_rate = 0.000000 (2608.5 examples/sec)
=> Model saved to file: ./logs/model-103000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951485, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 00:09:52.982247: step 103100, loss = 0.146214, learning_rate = 0.000000 (2633.5 examples/sec)
=> 2021-11-02 00:10:12.745640: step 103200, loss = 0.212101, learning_rate = 0.000000 (2612.7 examples/sec)
=> 2021-11-02 00:10:32.508756: step 103300, loss = 0.147069, learning_rate = 0.000000 (2612.9 examples/sec)
=> 2021-11-02 00:10:52.294425: step 103400, loss = 0.163591, learning_rate = 0.000000 (2609.6 examples/sec)
=> 2021-11-02 00:11:12.086105: step 103500, loss = 0.180051, learning_rate = 0.000000 (2609.5 examples/sec)
=> 2021-11-02 00:11:33.001411: step 103600, loss = 0.113645, learning_rate = 0.000000 (2608.1 examples/sec)
=> 2021-11-02 00:11:52.943249: step 103700, loss = 0.168514, learning_rate = 0.000000 (2589.1 examples/sec)
=> 2021-11-02 00:12:12.681826: step 103800, loss = 0.132094, learning_rate = 0.000000 (2615.9 examples/sec)
=> 2021-11-02 00:12:32.440897: step 103900, loss = 0.153963, learning_rate = 0.000000 (2613.2 examples/sec)
=> 2021-11-02 00:12:53.180333: step 104000, loss = 0.094231, learning_rate = 0.000000 (2624.9 examples/sec)
=> Model saved to file: ./logs/model-104000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951102, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 00:13:24.906295: step 104100, loss = 0.181417, learning_rate = 0.000000 (2618.5 examples/sec)
=> 2021-11-02 00:13:44.622651: step 104200, loss = 0.237089, learning_rate = 0.000000 (2618.8 examples/sec)
=> 2021-11-02 00:14:04.373966: step 104300, loss = 0.156549, learning_rate = 0.000000 (2614.4 examples/sec)
=> 2021-11-02 00:14:25.108625: step 104400, loss = 0.139659, learning_rate = 0.000000 (2626.6 examples/sec)
=> 2021-11-02 00:14:44.859803: step 104500, loss = 0.200061, learning_rate = 0.000000 (2614.4 examples/sec)
=> 2021-11-02 00:15:04.636475: step 104600, loss = 0.152222, learning_rate = 0.000000 (2611.2 examples/sec)
=> 2021-11-02 00:15:24.392065: step 104700, loss = 0.119026, learning_rate = 0.000000 (2613.6 examples/sec)
=> 2021-11-02 00:15:45.282515: step 104800, loss = 0.123362, learning_rate = 0.000000 (2615.1 examples/sec)
=> 2021-11-02 00:16:05.071948: step 104900, loss = 0.176997, learning_rate = 0.000000 (2609.1 examples/sec)
=> 2021-11-02 00:16:24.855275: step 105000, loss = 0.160279, learning_rate = 0.000000 (2610.1 examples/sec)
=> Model saved to file: ./logs/model-105000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949954, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 00:16:56.328471: step 105100, loss = 0.154788, learning_rate = 0.000000 (2614.0 examples/sec)
=> 2021-11-02 00:17:17.048594: step 105200, loss = 0.163120, learning_rate = 0.000000 (2632.4 examples/sec)
=> 2021-11-02 00:17:36.747371: step 105300, loss = 0.132562, learning_rate = 0.000000 (2621.6 examples/sec)
=> 2021-11-02 00:17:56.467578: step 105400, loss = 0.174817, learning_rate = 0.000000 (2618.3 examples/sec)
=> 2021-11-02 00:18:16.220426: step 105500, loss = 0.128041, learning_rate = 0.000000 (2613.9 examples/sec)
=> 2021-11-02 00:18:36.942047: step 105600, loss = 0.144457, learning_rate = 0.000000 (2626.8 examples/sec)
=> 2021-11-02 00:18:56.715485: step 105700, loss = 0.137121, learning_rate = 0.000000 (2611.6 examples/sec)
=> 2021-11-02 00:19:16.493405: step 105800, loss = 0.080687, learning_rate = 0.000000 (2610.7 examples/sec)
=> 2021-11-02 00:19:36.286339: step 105900, loss = 0.100836, learning_rate = 0.000000 (2608.8 examples/sec)
=> 2021-11-02 00:19:56.980538: step 106000, loss = 0.192332, learning_rate = 0.000000 (2626.5 examples/sec)
=> Model saved to file: ./logs/model-106000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951102, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 00:20:28.708792: step 106100, loss = 0.173253, learning_rate = 0.000000 (2614.3 examples/sec)
=> 2021-11-02 00:20:48.428334: step 106200, loss = 0.124939, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 00:21:08.162910: step 106300, loss = 0.149083, learning_rate = 0.000000 (2616.5 examples/sec)
=> 2021-11-02 00:21:28.798849: step 106400, loss = 0.136840, learning_rate = 0.000000 (2631.6 examples/sec)
=> 2021-11-02 00:21:48.564302: step 106500, loss = 0.186529, learning_rate = 0.000000 (2612.8 examples/sec)
=> 2021-11-02 00:22:08.332492: step 106600, loss = 0.187886, learning_rate = 0.000000 (2612.1 examples/sec)
=> 2021-11-02 00:22:28.110494: step 106700, loss = 0.130701, learning_rate = 0.000000 (2610.9 examples/sec)
=> 2021-11-02 00:22:47.875934: step 106800, loss = 0.205429, learning_rate = 0.000000 (2612.6 examples/sec)
=> 2021-11-02 00:23:08.622275: step 106900, loss = 0.152539, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 00:23:28.414951: step 107000, loss = 0.121474, learning_rate = 0.000000 (2608.8 examples/sec)
=> Model saved to file: ./logs/model-107000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950337, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 00:23:59.915672: step 107100, loss = 0.149350, learning_rate = 0.000000 (2617.1 examples/sec)
=> 2021-11-02 00:24:19.651193: step 107200, loss = 0.072893, learning_rate = 0.000000 (2616.4 examples/sec)
=> 2021-11-02 00:24:40.355401: step 107300, loss = 0.155432, learning_rate = 0.000000 (2629.0 examples/sec)
=> 2021-11-02 00:25:00.113493: step 107400, loss = 0.229708, learning_rate = 0.000000 (2613.6 examples/sec)
=> 2021-11-02 00:25:19.877911: step 107500, loss = 0.115753, learning_rate = 0.000000 (2612.5 examples/sec)
=> 2021-11-02 00:25:39.642837: step 107600, loss = 0.158365, learning_rate = 0.000000 (2612.4 examples/sec)
=> 2021-11-02 00:26:00.428960: step 107700, loss = 0.206453, learning_rate = 0.000000 (2613.1 examples/sec)
=> 2021-11-02 00:26:20.204884: step 107800, loss = 0.142138, learning_rate = 0.000000 (2611.1 examples/sec)
=> 2021-11-02 00:26:39.987982: step 107900, loss = 0.110541, learning_rate = 0.000000 (2610.2 examples/sec)
=> 2021-11-02 00:26:59.767860: step 108000, loss = 0.175710, learning_rate = 0.000000 (2610.4 examples/sec)
=> Model saved to file: ./logs/model-108000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951714, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 00:27:32.748296: step 108100, loss = 0.184757, learning_rate = 0.000000 (2643.5 examples/sec)
=> 2021-11-02 00:27:52.399292: step 108200, loss = 0.110962, learning_rate = 0.000000 (2627.7 examples/sec)
=> 2021-11-02 00:28:12.091083: step 108300, loss = 0.133112, learning_rate = 0.000000 (2622.2 examples/sec)
=> 2021-11-02 00:28:31.804064: step 108400, loss = 0.220139, learning_rate = 0.000000 (2619.6 examples/sec)
=> 2021-11-02 00:28:52.485958: step 108500, loss = 0.167605, learning_rate = 0.000000 (2630.9 examples/sec)
=> 2021-11-02 00:29:12.204915: step 108600, loss = 0.151693, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 00:29:32.005482: step 108700, loss = 0.103733, learning_rate = 0.000000 (2608.0 examples/sec)
=> 2021-11-02 00:29:51.744427: step 108800, loss = 0.110357, learning_rate = 0.000000 (2616.0 examples/sec)
=> 2021-11-02 00:30:12.431964: step 108900, loss = 0.089711, learning_rate = 0.000000 (2632.3 examples/sec)
=> 2021-11-02 00:30:32.268930: step 109000, loss = 0.156093, learning_rate = 0.000000 (2602.7 examples/sec)
=> Model saved to file: ./logs/model-109000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950184, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 00:31:03.890384: step 109100, loss = 0.118033, learning_rate = 0.000000 (2622.3 examples/sec)
=> 2021-11-02 00:31:23.532982: step 109200, loss = 0.194756, learning_rate = 0.000000 (2628.7 examples/sec)
=> 2021-11-02 00:31:44.199012: step 109300, loss = 0.178096, learning_rate = 0.000000 (2654.1 examples/sec)
=> 2021-11-02 00:32:03.889045: step 109400, loss = 0.146439, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-02 00:32:23.588270: step 109500, loss = 0.246303, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-02 00:32:43.298830: step 109600, loss = 0.195771, learning_rate = 0.000000 (2619.7 examples/sec)
=> 2021-11-02 00:33:03.003138: step 109700, loss = 0.128516, learning_rate = 0.000000 (2620.5 examples/sec)
=> 2021-11-02 00:33:23.656461: step 109800, loss = 0.110219, learning_rate = 0.000000 (2631.7 examples/sec)
=> 2021-11-02 00:33:43.335268: step 109900, loss = 0.151635, learning_rate = 0.000000 (2624.1 examples/sec)
=> 2021-11-02 00:34:03.029016: step 110000, loss = 0.163458, learning_rate = 0.000000 (2623.2 examples/sec)
=> Model saved to file: ./logs/model-110000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947199, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 00:34:34.555480: step 110100, loss = 0.187860, learning_rate = 0.000000 (2622.7 examples/sec)
=> 2021-11-02 00:34:55.155800: step 110200, loss = 0.114968, learning_rate = 0.000000 (2643.8 examples/sec)
=> 2021-11-02 00:35:14.825389: step 110300, loss = 0.151800, learning_rate = 0.000000 (2625.2 examples/sec)
=> 2021-11-02 00:35:34.499439: step 110400, loss = 0.122069, learning_rate = 0.000000 (2624.4 examples/sec)
=> 2021-11-02 00:35:54.205975: step 110500, loss = 0.129223, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-02 00:36:14.844239: step 110600, loss = 0.125317, learning_rate = 0.000000 (2635.4 examples/sec)
=> 2021-11-02 00:36:34.562452: step 110700, loss = 0.142738, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 00:36:54.284119: step 110800, loss = 0.139122, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 00:37:14.011591: step 110900, loss = 0.114019, learning_rate = 0.000000 (2617.4 examples/sec)
=> 2021-11-02 00:37:34.863326: step 111000, loss = 0.077905, learning_rate = 0.000000 (2632.7 examples/sec)
=> Model saved to file: ./logs/model-111000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950643, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 00:38:06.404264: step 111100, loss = 0.132427, learning_rate = 0.000000 (2623.5 examples/sec)
=> 2021-11-02 00:38:26.061754: step 111200, loss = 0.120572, learning_rate = 0.000000 (2626.8 examples/sec)
=> 2021-11-02 00:38:45.748644: step 111300, loss = 0.141923, learning_rate = 0.000000 (2622.8 examples/sec)
=> 2021-11-02 00:39:06.408999: step 111400, loss = 0.162825, learning_rate = 0.000000 (2631.7 examples/sec)
=> 2021-11-02 00:39:26.103438: step 111500, loss = 0.085415, learning_rate = 0.000000 (2621.9 examples/sec)
=> 2021-11-02 00:39:45.778350: step 111600, loss = 0.103207, learning_rate = 0.000000 (2624.4 examples/sec)
=> 2021-11-02 00:40:05.474530: step 111700, loss = 0.110720, learning_rate = 0.000000 (2621.5 examples/sec)
=> 2021-11-02 00:40:26.158625: step 111800, loss = 0.120780, learning_rate = 0.000000 (2631.2 examples/sec)
=> 2021-11-02 00:40:45.838923: step 111900, loss = 0.211192, learning_rate = 0.000000 (2623.6 examples/sec)
=> 2021-11-02 00:41:05.557886: step 112000, loss = 0.135195, learning_rate = 0.000000 (2618.7 examples/sec)
=> Model saved to file: ./logs/model-112000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949801, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 00:41:37.190410: step 112100, loss = 0.092060, learning_rate = 0.000000 (2626.3 examples/sec)
=> 2021-11-02 00:41:57.795529: step 112200, loss = 0.157879, learning_rate = 0.000000 (2644.5 examples/sec)
=> 2021-11-02 00:42:17.454684: step 112300, loss = 0.122418, learning_rate = 0.000000 (2626.7 examples/sec)
=> 2021-11-02 00:42:37.128189: step 112400, loss = 0.134665, learning_rate = 0.000000 (2624.6 examples/sec)
=> 2021-11-02 00:42:56.831920: step 112500, loss = 0.108685, learning_rate = 0.000000 (2620.7 examples/sec)
=> 2021-11-02 00:43:16.542998: step 112600, loss = 0.214699, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-02 00:43:37.565720: step 112700, loss = 0.084716, learning_rate = 0.000000 (2620.5 examples/sec)
=> 2021-11-02 00:43:57.295526: step 112800, loss = 0.119583, learning_rate = 0.000000 (2617.7 examples/sec)
=> 2021-11-02 00:44:17.012063: step 112900, loss = 0.130714, learning_rate = 0.000000 (2618.8 examples/sec)
=> 2021-11-02 00:44:36.734150: step 113000, loss = 0.084072, learning_rate = 0.000000 (2618.2 examples/sec)
=> Model saved to file: ./logs/model-113000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949189, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 00:45:09.050577: step 113100, loss = 0.094030, learning_rate = 0.000000 (2637.3 examples/sec)
=> 2021-11-02 00:45:28.807221: step 113200, loss = 0.140139, learning_rate = 0.000000 (2613.4 examples/sec)
=> 2021-11-02 00:45:48.487740: step 113300, loss = 0.118793, learning_rate = 0.000000 (2623.4 examples/sec)
=> 2021-11-02 00:46:08.208551: step 113400, loss = 0.126398, learning_rate = 0.000000 (2618.5 examples/sec)
=> 2021-11-02 00:46:28.890523: step 113500, loss = 0.158162, learning_rate = 0.000000 (2626.8 examples/sec)
=> 2021-11-02 00:46:48.592979: step 113600, loss = 0.148341, learning_rate = 0.000000 (2620.7 examples/sec)
=> 2021-11-02 00:47:08.314421: step 113700, loss = 0.126283, learning_rate = 0.000000 (2618.3 examples/sec)
=> 2021-11-02 00:47:28.021881: step 113800, loss = 0.139024, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 00:47:48.734618: step 113900, loss = 0.125728, learning_rate = 0.000000 (2632.7 examples/sec)
=> 2021-11-02 00:48:08.451689: step 114000, loss = 0.102437, learning_rate = 0.000000 (2618.5 examples/sec)
=> Model saved to file: ./logs/model-114000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950796, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 00:48:39.915699: step 114100, loss = 0.114025, learning_rate = 0.000000 (2623.6 examples/sec)
=> 2021-11-02 00:48:59.577099: step 114200, loss = 0.116642, learning_rate = 0.000000 (2626.0 examples/sec)
=> 2021-11-02 00:49:20.324779: step 114300, loss = 0.168342, learning_rate = 0.000000 (2639.2 examples/sec)
=> 2021-11-02 00:49:40.007243: step 114400, loss = 0.095279, learning_rate = 0.000000 (2623.5 examples/sec)
=> 2021-11-02 00:49:59.712091: step 114500, loss = 0.193626, learning_rate = 0.000000 (2620.2 examples/sec)
=> 2021-11-02 00:50:19.431726: step 114600, loss = 0.134799, learning_rate = 0.000000 (2618.4 examples/sec)
=> 2021-11-02 00:50:40.075612: step 114700, loss = 0.104010, learning_rate = 0.000000 (2632.3 examples/sec)
=> 2021-11-02 00:50:59.797537: step 114800, loss = 0.148314, learning_rate = 0.000000 (2618.0 examples/sec)
=> 2021-11-02 00:51:19.540920: step 114900, loss = 0.172123, learning_rate = 0.000000 (2615.3 examples/sec)
=> 2021-11-02 00:51:39.266535: step 115000, loss = 0.161740, learning_rate = 0.000000 (2617.6 examples/sec)
=> Model saved to file: ./logs/model-115000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949571, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 00:52:11.760868: step 115100, loss = 0.132096, learning_rate = 0.000000 (2635.8 examples/sec)
=> 2021-11-02 00:52:31.423321: step 115200, loss = 0.140026, learning_rate = 0.000000 (2626.1 examples/sec)
=> 2021-11-02 00:52:51.092766: step 115300, loss = 0.094626, learning_rate = 0.000000 (2625.3 examples/sec)
=> 2021-11-02 00:53:10.805728: step 115400, loss = 0.112736, learning_rate = 0.000000 (2619.4 examples/sec)
=> 2021-11-02 00:53:30.498435: step 115500, loss = 0.130190, learning_rate = 0.000000 (2622.7 examples/sec)
=> 2021-11-02 00:53:51.152753: step 115600, loss = 0.152507, learning_rate = 0.000000 (2632.3 examples/sec)
=> 2021-11-02 00:54:10.878421: step 115700, loss = 0.143679, learning_rate = 0.000000 (2617.7 examples/sec)
=> 2021-11-02 00:54:30.621742: step 115800, loss = 0.111043, learning_rate = 0.000000 (2615.3 examples/sec)
=> 2021-11-02 00:54:50.449773: step 115900, loss = 0.088157, learning_rate = 0.000000 (2604.0 examples/sec)
=> 2021-11-02 00:55:11.204152: step 116000, loss = 0.144713, learning_rate = 0.000000 (2631.0 examples/sec)
=> Model saved to file: ./logs/model-116000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951102, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 00:55:42.627391: step 116100, loss = 0.064982, learning_rate = 0.000000 (2632.0 examples/sec)
=> 2021-11-02 00:56:02.261612: step 116200, loss = 0.117987, learning_rate = 0.000000 (2629.8 examples/sec)
=> 2021-11-02 00:56:21.902719: step 116300, loss = 0.096016, learning_rate = 0.000000 (2628.8 examples/sec)
=> 2021-11-02 00:56:42.449780: step 116400, loss = 0.090451, learning_rate = 0.000000 (2643.0 examples/sec)
=> 2021-11-02 00:57:02.120816: step 116500, loss = 0.143098, learning_rate = 0.000000 (2625.0 examples/sec)
=> 2021-11-02 00:57:21.825139: step 116600, loss = 0.194344, learning_rate = 0.000000 (2620.5 examples/sec)
=> 2021-11-02 00:57:41.535487: step 116700, loss = 0.119487, learning_rate = 0.000000 (2619.4 examples/sec)
=> 2021-11-02 00:58:02.191977: step 116800, loss = 0.173155, learning_rate = 0.000000 (2634.1 examples/sec)
=> 2021-11-02 00:58:21.918841: step 116900, loss = 0.097621, learning_rate = 0.000000 (2617.8 examples/sec)
=> 2021-11-02 00:58:41.640520: step 117000, loss = 0.147776, learning_rate = 0.000000 (2618.2 examples/sec)
=> Model saved to file: ./logs/model-117000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951714, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 00:59:13.105659: step 117100, loss = 0.091425, learning_rate = 0.000000 (2624.4 examples/sec)
=> 2021-11-02 00:59:33.687202: step 117200, loss = 0.085404, learning_rate = 0.000000 (2641.0 examples/sec)
=> 2021-11-02 00:59:53.341103: step 117300, loss = 0.206678, learning_rate = 0.000000 (2627.1 examples/sec)
=> 2021-11-02 01:00:13.024361: step 117400, loss = 0.104458, learning_rate = 0.000000 (2623.2 examples/sec)
=> 2021-11-02 01:00:32.747795: step 117500, loss = 0.080442, learning_rate = 0.000000 (2617.9 examples/sec)
=> 2021-11-02 01:00:53.419994: step 117600, loss = 0.093664, learning_rate = 0.000000 (2629.1 examples/sec)
=> 2021-11-02 01:01:13.149464: step 117700, loss = 0.151416, learning_rate = 0.000000 (2617.1 examples/sec)
=> 2021-11-02 01:01:32.870281: step 117800, loss = 0.149520, learning_rate = 0.000000 (2618.1 examples/sec)
=> 2021-11-02 01:01:52.607145: step 117900, loss = 0.098119, learning_rate = 0.000000 (2616.0 examples/sec)
=> 2021-11-02 01:02:13.292537: step 118000, loss = 0.119691, learning_rate = 0.000000 (2629.5 examples/sec)
=> Model saved to file: ./logs/model-118000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951102, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 01:02:44.642828: step 118100, loss = 0.168455, learning_rate = 0.000000 (2626.9 examples/sec)
=> 2021-11-02 01:03:04.291741: step 118200, loss = 0.087873, learning_rate = 0.000000 (2627.3 examples/sec)
=> 2021-11-02 01:03:24.021641: step 118300, loss = 0.116456, learning_rate = 0.000000 (2617.1 examples/sec)
=> 2021-11-02 01:03:43.734071: step 118400, loss = 0.151515, learning_rate = 0.000000 (2619.7 examples/sec)
=> 2021-11-02 01:04:04.350353: step 118500, loss = 0.110814, learning_rate = 0.000000 (2634.8 examples/sec)
=> 2021-11-02 01:04:24.075924: step 118600, loss = 0.118967, learning_rate = 0.000000 (2617.7 examples/sec)
=> 2021-11-02 01:04:43.801493: step 118700, loss = 0.157706, learning_rate = 0.000000 (2617.6 examples/sec)
=> 2021-11-02 01:05:03.523264: step 118800, loss = 0.096278, learning_rate = 0.000000 (2618.2 examples/sec)
=> 2021-11-02 01:05:24.183470: step 118900, loss = 0.087046, learning_rate = 0.000000 (2632.5 examples/sec)
=> 2021-11-02 01:05:43.914054: step 119000, loss = 0.092264, learning_rate = 0.000000 (2617.0 examples/sec)
=> Model saved to file: ./logs/model-119000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949724, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 01:06:15.449299: step 119100, loss = 0.130719, learning_rate = 0.000000 (2625.2 examples/sec)
=> 2021-11-02 01:06:35.099073: step 119200, loss = 0.106991, learning_rate = 0.000000 (2627.8 examples/sec)
=> 2021-11-02 01:06:55.705223: step 119300, loss = 0.155816, learning_rate = 0.000000 (2636.2 examples/sec)
=> 2021-11-02 01:07:15.394217: step 119400, loss = 0.155529, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-02 01:07:35.076854: step 119500, loss = 0.120398, learning_rate = 0.000000 (2623.3 examples/sec)
=> 2021-11-02 01:07:54.793091: step 119600, loss = 0.102027, learning_rate = 0.000000 (2618.9 examples/sec)
=> 2021-11-02 01:08:15.564760: step 119700, loss = 0.096027, learning_rate = 0.000000 (2636.0 examples/sec)
=> 2021-11-02 01:08:35.292994: step 119800, loss = 0.226486, learning_rate = 0.000000 (2617.5 examples/sec)
=> 2021-11-02 01:08:55.014128: step 119900, loss = 0.086659, learning_rate = 0.000000 (2618.1 examples/sec)
=> 2021-11-02 01:09:14.739519: step 120000, loss = 0.131350, learning_rate = 0.000000 (2617.6 examples/sec)
=> Model saved to file: ./logs/model-120000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948959, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 01:09:47.079190: step 120100, loss = 0.124349, learning_rate = 0.000000 (2638.7 examples/sec)
=> 2021-11-02 01:10:06.730286: step 120200, loss = 0.090588, learning_rate = 0.000000 (2627.6 examples/sec)
=> 2021-11-02 01:10:26.405557: step 120300, loss = 0.085637, learning_rate = 0.000000 (2624.4 examples/sec)
=> 2021-11-02 01:10:46.084473: step 120400, loss = 0.129448, learning_rate = 0.000000 (2623.9 examples/sec)
=> 2021-11-02 01:11:06.802946: step 120500, loss = 0.101582, learning_rate = 0.000000 (2632.4 examples/sec)
=> 2021-11-02 01:11:26.525788: step 120600, loss = 0.108820, learning_rate = 0.000000 (2618.3 examples/sec)
=> 2021-11-02 01:11:46.250115: step 120700, loss = 0.066227, learning_rate = 0.000000 (2617.6 examples/sec)
=> 2021-11-02 01:12:05.978252: step 120800, loss = 0.129037, learning_rate = 0.000000 (2617.3 examples/sec)
=> 2021-11-02 01:12:26.797910: step 120900, loss = 0.099816, learning_rate = 0.000000 (2634.2 examples/sec)
=> 2021-11-02 01:12:46.518111: step 121000, loss = 0.168919, learning_rate = 0.000000 (2618.5 examples/sec)
=> Model saved to file: ./logs/model-121000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949342, best accuracy 0.951714
=> patience = 99
=> 2021-11-02 01:13:17.905716: step 121100, loss = 0.144328, learning_rate = 0.000000 (2625.7 examples/sec)
=> 2021-11-02 01:13:37.640989: step 121200, loss = 0.098866, learning_rate = 0.000000 (2616.1 examples/sec)
=> 2021-11-02 01:13:57.331209: step 121300, loss = 0.117585, learning_rate = 0.000000 (2622.7 examples/sec)
=> 2021-11-02 01:14:17.943957: step 121400, loss = 0.108456, learning_rate = 0.000000 (2635.3 examples/sec)
=> 2021-11-02 01:14:37.653025: step 121500, loss = 0.166527, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 01:14:57.393404: step 121600, loss = 0.123486, learning_rate = 0.000000 (2615.6 examples/sec)
=> 2021-11-02 01:15:17.115836: step 121700, loss = 0.131689, learning_rate = 0.000000 (2618.1 examples/sec)
=> 2021-11-02 01:15:37.898086: step 121800, loss = 0.125968, learning_rate = 0.000000 (2635.9 examples/sec)
=> 2021-11-02 01:15:57.645831: step 121900, loss = 0.146857, learning_rate = 0.000000 (2614.6 examples/sec)
=> 2021-11-02 01:16:17.372899: step 122000, loss = 0.143545, learning_rate = 0.000000 (2617.6 examples/sec)
=> Model saved to file: ./logs/model-122000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952632, best accuracy 0.951714
=> Model saved to file: ./logs/model-122000.pth
=> patience = 100
=> 2021-11-02 01:16:49.493442: step 122100, loss = 0.084407, learning_rate = 0.000000 (2624.9 examples/sec)
=> 2021-11-02 01:17:10.194294: step 122200, loss = 0.097410, learning_rate = 0.000000 (2644.2 examples/sec)
=> 2021-11-02 01:17:29.841815: step 122300, loss = 0.116262, learning_rate = 0.000000 (2628.2 examples/sec)
=> 2021-11-02 01:17:49.518364: step 122400, loss = 0.112417, learning_rate = 0.000000 (2624.2 examples/sec)
=> 2021-11-02 01:18:09.242670: step 122500, loss = 0.081419, learning_rate = 0.000000 (2617.8 examples/sec)
=> 2021-11-02 01:18:29.951440: step 122600, loss = 0.121487, learning_rate = 0.000000 (2632.8 examples/sec)
=> 2021-11-02 01:18:49.652019: step 122700, loss = 0.143940, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-02 01:19:09.358239: step 122800, loss = 0.116610, learning_rate = 0.000000 (2620.3 examples/sec)
=> 2021-11-02 01:19:29.064900: step 122900, loss = 0.073396, learning_rate = 0.000000 (2620.1 examples/sec)
=> 2021-11-02 01:19:49.793085: step 123000, loss = 0.125405, learning_rate = 0.000000 (2634.2 examples/sec)
=> Model saved to file: ./logs/model-123000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951638, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 01:20:21.208542: step 123100, loss = 0.097500, learning_rate = 0.000000 (2628.2 examples/sec)
=> 2021-11-02 01:20:40.843015: step 123200, loss = 0.122371, learning_rate = 0.000000 (2629.6 examples/sec)
=> 2021-11-02 01:21:00.491429: step 123300, loss = 0.093021, learning_rate = 0.000000 (2627.7 examples/sec)
=> 2021-11-02 01:21:21.231419: step 123400, loss = 0.081797, learning_rate = 0.000000 (2641.1 examples/sec)
=> 2021-11-02 01:21:40.913140: step 123500, loss = 0.145439, learning_rate = 0.000000 (2623.4 examples/sec)
=> 2021-11-02 01:22:00.608542: step 123600, loss = 0.100541, learning_rate = 0.000000 (2621.8 examples/sec)
=> 2021-11-02 01:22:20.295972: step 123700, loss = 0.144320, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-02 01:22:40.882656: step 123800, loss = 0.114093, learning_rate = 0.000000 (2639.2 examples/sec)
=> 2021-11-02 01:23:00.612602: step 123900, loss = 0.136651, learning_rate = 0.000000 (2617.1 examples/sec)
=> 2021-11-02 01:23:20.333240: step 124000, loss = 0.086406, learning_rate = 0.000000 (2618.3 examples/sec)
=> Model saved to file: ./logs/model-124000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951791, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 01:23:51.914435: step 124100, loss = 0.177295, learning_rate = 0.000000 (2625.9 examples/sec)
=> 2021-11-02 01:24:11.549607: step 124200, loss = 0.123026, learning_rate = 0.000000 (2630.0 examples/sec)
=> 2021-11-02 01:24:32.258658: step 124300, loss = 0.115527, learning_rate = 0.000000 (2624.1 examples/sec)
=> 2021-11-02 01:24:51.882503: step 124400, loss = 0.132342, learning_rate = 0.000000 (2631.2 examples/sec)
=> 2021-11-02 01:25:11.520191: step 124500, loss = 0.156811, learning_rate = 0.000000 (2629.3 examples/sec)
=> 2021-11-02 01:25:31.171266: step 124600, loss = 0.109685, learning_rate = 0.000000 (2627.4 examples/sec)
=> 2021-11-02 01:25:51.836848: step 124700, loss = 0.107036, learning_rate = 0.000000 (2636.4 examples/sec)
=> 2021-11-02 01:26:11.518871: step 124800, loss = 0.121488, learning_rate = 0.000000 (2623.8 examples/sec)
=> 2021-11-02 01:26:31.217938: step 124900, loss = 0.084773, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-02 01:26:50.912893: step 125000, loss = 0.092176, learning_rate = 0.000000 (2621.5 examples/sec)
=> Model saved to file: ./logs/model-125000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951408, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 01:27:23.184074: step 125100, loss = 0.160407, learning_rate = 0.000000 (2636.4 examples/sec)
=> 2021-11-02 01:27:42.829778: step 125200, loss = 0.145218, learning_rate = 0.000000 (2628.2 examples/sec)
=> 2021-11-02 01:28:02.498643: step 125300, loss = 0.073711, learning_rate = 0.000000 (2625.2 examples/sec)
=> 2021-11-02 01:28:22.180913: step 125400, loss = 0.180734, learning_rate = 0.000000 (2623.5 examples/sec)
=> 2021-11-02 01:28:42.831078: step 125500, loss = 0.134892, learning_rate = 0.000000 (2635.9 examples/sec)
=> 2021-11-02 01:29:02.482056: step 125600, loss = 0.090985, learning_rate = 0.000000 (2627.7 examples/sec)
=> 2021-11-02 01:29:22.159897: step 125700, loss = 0.123160, learning_rate = 0.000000 (2624.2 examples/sec)
=> 2021-11-02 01:29:41.850189: step 125800, loss = 0.086550, learning_rate = 0.000000 (2622.4 examples/sec)
=> 2021-11-02 01:30:02.481880: step 125900, loss = 0.098443, learning_rate = 0.000000 (2634.8 examples/sec)
=> 2021-11-02 01:30:22.148857: step 126000, loss = 0.132580, learning_rate = 0.000000 (2625.7 examples/sec)
=> Model saved to file: ./logs/model-126000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951025, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 01:30:53.527975: step 126100, loss = 0.080243, learning_rate = 0.000000 (2631.3 examples/sec)
=> 2021-11-02 01:31:13.152714: step 126200, loss = 0.085669, learning_rate = 0.000000 (2631.2 examples/sec)
=> 2021-11-02 01:31:33.718347: step 126300, loss = 0.092401, learning_rate = 0.000000 (2643.0 examples/sec)
=> 2021-11-02 01:31:53.373050: step 126400, loss = 0.067698, learning_rate = 0.000000 (2626.9 examples/sec)
=> 2021-11-02 01:32:13.039451: step 126500, loss = 0.115646, learning_rate = 0.000000 (2625.4 examples/sec)
=> 2021-11-02 01:32:32.715678: step 126600, loss = 0.114555, learning_rate = 0.000000 (2624.0 examples/sec)
=> 2021-11-02 01:32:53.280114: step 126700, loss = 0.092864, learning_rate = 0.000000 (2641.7 examples/sec)
=> 2021-11-02 01:33:12.982994: step 126800, loss = 0.118390, learning_rate = 0.000000 (2620.5 examples/sec)
=> 2021-11-02 01:33:32.699284: step 126900, loss = 0.128369, learning_rate = 0.000000 (2618.7 examples/sec)
=> 2021-11-02 01:33:52.400942: step 127000, loss = 0.156981, learning_rate = 0.000000 (2620.6 examples/sec)
=> Model saved to file: ./logs/model-127000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951485, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 01:34:24.931872: step 127100, loss = 0.121148, learning_rate = 0.000000 (2643.4 examples/sec)
=> 2021-11-02 01:34:44.652339: step 127200, loss = 0.102148, learning_rate = 0.000000 (2618.3 examples/sec)
=> 2021-11-02 01:35:04.296036: step 127300, loss = 0.114088, learning_rate = 0.000000 (2628.6 examples/sec)
=> 2021-11-02 01:35:23.932763: step 127400, loss = 0.092723, learning_rate = 0.000000 (2629.5 examples/sec)
=> 2021-11-02 01:35:43.634061: step 127500, loss = 0.096233, learning_rate = 0.000000 (2621.0 examples/sec)
=> 2021-11-02 01:36:04.222235: step 127600, loss = 0.124835, learning_rate = 0.000000 (2639.0 examples/sec)
=> 2021-11-02 01:36:23.892282: step 127700, loss = 0.070298, learning_rate = 0.000000 (2625.1 examples/sec)
=> 2021-11-02 01:36:43.567158: step 127800, loss = 0.154803, learning_rate = 0.000000 (2624.3 examples/sec)
=> 2021-11-02 01:37:03.268782: step 127900, loss = 0.083040, learning_rate = 0.000000 (2620.7 examples/sec)
=> 2021-11-02 01:37:23.901108: step 128000, loss = 0.104909, learning_rate = 0.000000 (2633.8 examples/sec)
=> Model saved to file: ./logs/model-128000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949265, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 01:37:55.169131: step 128100, loss = 0.110227, learning_rate = 0.000000 (2625.4 examples/sec)
=> 2021-11-02 01:38:14.809386: step 128200, loss = 0.127379, learning_rate = 0.000000 (2629.0 examples/sec)
=> 2021-11-02 01:38:34.483295: step 128300, loss = 0.093218, learning_rate = 0.000000 (2624.5 examples/sec)
=> 2021-11-02 01:38:55.111155: step 128400, loss = 0.099986, learning_rate = 0.000000 (2635.0 examples/sec)
=> 2021-11-02 01:39:14.765928: step 128500, loss = 0.109730, learning_rate = 0.000000 (2627.2 examples/sec)
=> 2021-11-02 01:39:34.424189: step 128600, loss = 0.082933, learning_rate = 0.000000 (2626.6 examples/sec)
=> 2021-11-02 01:39:54.085114: step 128700, loss = 0.124085, learning_rate = 0.000000 (2626.1 examples/sec)
=> 2021-11-02 01:40:14.779358: step 128800, loss = 0.090911, learning_rate = 0.000000 (2640.5 examples/sec)
=> 2021-11-02 01:40:34.446003: step 128900, loss = 0.096804, learning_rate = 0.000000 (2625.5 examples/sec)
=> 2021-11-02 01:40:54.155918: step 129000, loss = 0.105773, learning_rate = 0.000000 (2619.9 examples/sec)
=> Model saved to file: ./logs/model-129000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950872, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 01:41:25.670970: step 129100, loss = 0.083654, learning_rate = 0.000000 (2631.3 examples/sec)
=> 2021-11-02 01:41:46.189368: step 129200, loss = 0.050973, learning_rate = 0.000000 (2651.2 examples/sec)
=> 2021-11-02 01:42:05.822613: step 129300, loss = 0.155032, learning_rate = 0.000000 (2630.0 examples/sec)
=> 2021-11-02 01:42:25.469434: step 129400, loss = 0.175983, learning_rate = 0.000000 (2628.1 examples/sec)
=> 2021-11-02 01:42:45.117206: step 129500, loss = 0.127841, learning_rate = 0.000000 (2628.1 examples/sec)
=> 2021-11-02 01:43:05.784944: step 129600, loss = 0.114810, learning_rate = 0.000000 (2631.2 examples/sec)
=> 2021-11-02 01:43:25.455508: step 129700, loss = 0.103836, learning_rate = 0.000000 (2624.9 examples/sec)
=> 2021-11-02 01:43:45.139441: step 129800, loss = 0.174175, learning_rate = 0.000000 (2623.1 examples/sec)
=> 2021-11-02 01:44:04.834392: step 129900, loss = 0.124582, learning_rate = 0.000000 (2621.6 examples/sec)
=> 2021-11-02 01:44:25.498749: step 130000, loss = 0.096053, learning_rate = 0.000000 (2634.8 examples/sec)
=> Model saved to file: ./logs/model-130000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949648, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 01:44:57.051519: step 130100, loss = 0.119203, learning_rate = 0.000000 (2627.0 examples/sec)
=> 2021-11-02 01:45:16.699080: step 130200, loss = 0.112911, learning_rate = 0.000000 (2628.3 examples/sec)
=> 2021-11-02 01:45:36.351140: step 130300, loss = 0.066575, learning_rate = 0.000000 (2627.4 examples/sec)
=> 2021-11-02 01:45:56.036706: step 130400, loss = 0.101913, learning_rate = 0.000000 (2622.9 examples/sec)
=> 2021-11-02 01:46:16.829640: step 130500, loss = 0.117796, learning_rate = 0.000000 (2638.5 examples/sec)
=> 2021-11-02 01:46:36.470193: step 130600, loss = 0.090723, learning_rate = 0.000000 (2629.0 examples/sec)
=> 2021-11-02 01:46:56.129542: step 130700, loss = 0.130639, learning_rate = 0.000000 (2626.6 examples/sec)
=> 2021-11-02 01:47:15.797842: step 130800, loss = 0.127533, learning_rate = 0.000000 (2625.4 examples/sec)
=> 2021-11-02 01:47:36.382981: step 130900, loss = 0.073179, learning_rate = 0.000000 (2638.1 examples/sec)
=> 2021-11-02 01:47:56.072340: step 131000, loss = 0.127555, learning_rate = 0.000000 (2622.4 examples/sec)
=> Model saved to file: ./logs/model-131000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952250, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 01:48:27.462075: step 131100, loss = 0.064577, learning_rate = 0.000000 (2628.0 examples/sec)
=> 2021-11-02 01:48:47.105199: step 131200, loss = 0.144511, learning_rate = 0.000000 (2628.6 examples/sec)
=> 2021-11-02 01:49:07.665617: step 131300, loss = 0.117640, learning_rate = 0.000000 (2642.3 examples/sec)
=> 2021-11-02 01:49:27.310608: step 131400, loss = 0.090217, learning_rate = 0.000000 (2628.9 examples/sec)
=> 2021-11-02 01:49:46.941959: step 131500, loss = 0.091172, learning_rate = 0.000000 (2630.1 examples/sec)
=> 2021-11-02 01:50:06.603436: step 131600, loss = 0.076166, learning_rate = 0.000000 (2626.1 examples/sec)
=> 2021-11-02 01:50:27.173220: step 131700, loss = 0.077784, learning_rate = 0.000000 (2642.2 examples/sec)
=> 2021-11-02 01:50:46.822026: step 131800, loss = 0.104816, learning_rate = 0.000000 (2627.8 examples/sec)
=> 2021-11-02 01:51:06.458256: step 131900, loss = 0.106768, learning_rate = 0.000000 (2629.4 examples/sec)
=> 2021-11-02 01:51:26.114531: step 132000, loss = 0.192968, learning_rate = 0.000000 (2626.9 examples/sec)
=> Model saved to file: ./logs/model-132000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951331, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 01:51:58.480812: step 132100, loss = 0.122487, learning_rate = 0.000000 (2643.6 examples/sec)
=> 2021-11-02 01:52:18.224866: step 132200, loss = 0.080455, learning_rate = 0.000000 (2615.5 examples/sec)
=> 2021-11-02 01:52:37.871504: step 132300, loss = 0.111624, learning_rate = 0.000000 (2628.2 examples/sec)
=> 2021-11-02 01:52:57.520135: step 132400, loss = 0.074253, learning_rate = 0.000000 (2628.0 examples/sec)
=> 2021-11-02 01:53:18.118660: step 132500, loss = 0.118168, learning_rate = 0.000000 (2639.5 examples/sec)
=> 2021-11-02 01:53:37.788861: step 132600, loss = 0.109544, learning_rate = 0.000000 (2624.9 examples/sec)
=> 2021-11-02 01:53:57.453871: step 132700, loss = 0.097399, learning_rate = 0.000000 (2625.7 examples/sec)
=> 2021-11-02 01:54:17.172566: step 132800, loss = 0.119777, learning_rate = 0.000000 (2618.7 examples/sec)
=> 2021-11-02 01:54:37.916075: step 132900, loss = 0.125897, learning_rate = 0.000000 (2635.5 examples/sec)
=> 2021-11-02 01:54:57.622127: step 133000, loss = 0.106527, learning_rate = 0.000000 (2620.3 examples/sec)
=> Model saved to file: ./logs/model-133000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.946204, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 01:55:28.918579: step 133100, loss = 0.093994, learning_rate = 0.000000 (2631.2 examples/sec)
=> 2021-11-02 01:55:48.553557: step 133200, loss = 0.061912, learning_rate = 0.000000 (2629.8 examples/sec)
=> 2021-11-02 01:56:08.194386: step 133300, loss = 0.137149, learning_rate = 0.000000 (2629.7 examples/sec)
=> 2021-11-02 01:56:28.770261: step 133400, loss = 0.119716, learning_rate = 0.000000 (2647.2 examples/sec)
=> 2021-11-02 01:56:48.449885: step 133500, loss = 0.059666, learning_rate = 0.000000 (2623.5 examples/sec)
=> 2021-11-02 01:57:08.151004: step 133600, loss = 0.107207, learning_rate = 0.000000 (2620.9 examples/sec)
=> 2021-11-02 01:57:27.851581: step 133700, loss = 0.105328, learning_rate = 0.000000 (2620.9 examples/sec)
=> 2021-11-02 01:57:48.586450: step 133800, loss = 0.169107, learning_rate = 0.000000 (2632.4 examples/sec)
=> 2021-11-02 01:58:08.296138: step 133900, loss = 0.117484, learning_rate = 0.000000 (2619.8 examples/sec)
=> 2021-11-02 01:58:28.019350: step 134000, loss = 0.096520, learning_rate = 0.000000 (2617.9 examples/sec)
=> Model saved to file: ./logs/model-134000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950643, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 01:58:59.575185: step 134100, loss = 0.118011, learning_rate = 0.000000 (2627.0 examples/sec)
=> 2021-11-02 01:59:20.160860: step 134200, loss = 0.078534, learning_rate = 0.000000 (2640.3 examples/sec)
=> 2021-11-02 01:59:39.804588: step 134300, loss = 0.119484, learning_rate = 0.000000 (2628.5 examples/sec)
=> 2021-11-02 01:59:59.462445: step 134400, loss = 0.082542, learning_rate = 0.000000 (2626.8 examples/sec)
=> 2021-11-02 02:00:19.152126: step 134500, loss = 0.088807, learning_rate = 0.000000 (2622.4 examples/sec)
=> 2021-11-02 02:00:39.969366: step 134600, loss = 0.191460, learning_rate = 0.000000 (2636.0 examples/sec)
=> 2021-11-02 02:00:59.646154: step 134700, loss = 0.081971, learning_rate = 0.000000 (2624.1 examples/sec)
=> 2021-11-02 02:01:19.336974: step 134800, loss = 0.115736, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-02 02:01:39.026835: step 134900, loss = 0.115914, learning_rate = 0.000000 (2622.8 examples/sec)
=> 2021-11-02 02:01:59.672407: step 135000, loss = 0.196014, learning_rate = 0.000000 (2632.2 examples/sec)
=> Model saved to file: ./logs/model-135000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951408, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 02:02:31.165241: step 135100, loss = 0.158148, learning_rate = 0.000000 (2630.1 examples/sec)
=> 2021-11-02 02:02:50.797727: step 135200, loss = 0.135553, learning_rate = 0.000000 (2630.0 examples/sec)
=> 2021-11-02 02:03:10.441123: step 135300, loss = 0.088133, learning_rate = 0.000000 (2628.6 examples/sec)
=> 2021-11-02 02:03:31.036193: step 135400, loss = 0.078593, learning_rate = 0.000000 (2641.5 examples/sec)
=> 2021-11-02 02:03:50.710479: step 135500, loss = 0.091987, learning_rate = 0.000000 (2624.3 examples/sec)
=> 2021-11-02 02:04:10.389821: step 135600, loss = 0.082089, learning_rate = 0.000000 (2623.7 examples/sec)
=> 2021-11-02 02:04:30.076645: step 135700, loss = 0.111110, learning_rate = 0.000000 (2622.8 examples/sec)
=> 2021-11-02 02:04:50.798412: step 135800, loss = 0.121858, learning_rate = 0.000000 (2637.1 examples/sec)
=> 2021-11-02 02:05:10.487988: step 135900, loss = 0.128561, learning_rate = 0.000000 (2622.6 examples/sec)
=> 2021-11-02 02:05:30.176400: step 136000, loss = 0.093766, learning_rate = 0.000000 (2622.5 examples/sec)
=> Model saved to file: ./logs/model-136000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948730, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 02:06:01.810400: step 136100, loss = 0.050464, learning_rate = 0.000000 (2626.4 examples/sec)
=> 2021-11-02 02:06:21.453385: step 136200, loss = 0.105795, learning_rate = 0.000000 (2629.4 examples/sec)
=> 2021-11-02 02:06:42.003153: step 136300, loss = 0.065044, learning_rate = 0.000000 (2644.3 examples/sec)
=> 2021-11-02 02:07:01.641182: step 136400, loss = 0.105690, learning_rate = 0.000000 (2629.2 examples/sec)
=> 2021-11-02 02:07:21.291187: step 136500, loss = 0.123707, learning_rate = 0.000000 (2627.6 examples/sec)
=> 2021-11-02 02:07:40.951794: step 136600, loss = 0.067791, learning_rate = 0.000000 (2626.1 examples/sec)
=> 2021-11-02 02:08:01.662048: step 136700, loss = 0.145377, learning_rate = 0.000000 (2643.8 examples/sec)
=> 2021-11-02 02:08:21.334764: step 136800, loss = 0.125053, learning_rate = 0.000000 (2624.6 examples/sec)
=> 2021-11-02 02:08:41.020853: step 136900, loss = 0.084992, learning_rate = 0.000000 (2622.8 examples/sec)
=> 2021-11-02 02:09:00.721232: step 137000, loss = 0.083019, learning_rate = 0.000000 (2621.0 examples/sec)
=> Model saved to file: ./logs/model-137000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951561, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 02:09:33.256639: step 137100, loss = 0.085415, learning_rate = 0.000000 (2655.9 examples/sec)
=> 2021-11-02 02:09:52.906297: step 137200, loss = 0.099471, learning_rate = 0.000000 (2627.8 examples/sec)
=> 2021-11-02 02:10:12.557086: step 137300, loss = 0.060575, learning_rate = 0.000000 (2627.5 examples/sec)
=> 2021-11-02 02:10:32.244656: step 137400, loss = 0.073948, learning_rate = 0.000000 (2622.7 examples/sec)
=> 2021-11-02 02:10:52.850607: step 137500, loss = 0.095244, learning_rate = 0.000000 (2649.5 examples/sec)
=> 2021-11-02 02:11:12.527242: step 137600, loss = 0.074791, learning_rate = 0.000000 (2625.6 examples/sec)
=> 2021-11-02 02:11:32.193920: step 137700, loss = 0.160342, learning_rate = 0.000000 (2626.3 examples/sec)
=> 2021-11-02 02:11:51.876463: step 137800, loss = 0.101717, learning_rate = 0.000000 (2623.4 examples/sec)
=> 2021-11-02 02:12:12.703913: step 137900, loss = 0.161442, learning_rate = 0.000000 (2634.0 examples/sec)
=> 2021-11-02 02:12:32.390359: step 138000, loss = 0.093006, learning_rate = 0.000000 (2622.9 examples/sec)
=> Model saved to file: ./logs/model-138000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949342, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 02:13:03.810393: step 138100, loss = 0.067312, learning_rate = 0.000000 (2626.5 examples/sec)
=> 2021-11-02 02:13:23.605954: step 138200, loss = 0.072000, learning_rate = 0.000000 (2608.1 examples/sec)
=> 2021-11-02 02:13:44.141440: step 138300, loss = 0.078766, learning_rate = 0.000000 (2644.5 examples/sec)
=> 2021-11-02 02:14:03.800474: step 138400, loss = 0.071980, learning_rate = 0.000000 (2626.5 examples/sec)
=> 2021-11-02 02:14:23.499081: step 138500, loss = 0.107857, learning_rate = 0.000000 (2621.3 examples/sec)
=> 2021-11-02 02:14:43.186574: step 138600, loss = 0.075559, learning_rate = 0.000000 (2622.7 examples/sec)
=> 2021-11-02 02:15:03.793017: step 138700, loss = 0.117184, learning_rate = 0.000000 (2637.2 examples/sec)
=> 2021-11-02 02:15:23.494491: step 138800, loss = 0.148015, learning_rate = 0.000000 (2621.0 examples/sec)
=> 2021-11-02 02:15:43.196467: step 138900, loss = 0.065822, learning_rate = 0.000000 (2620.6 examples/sec)
=> 2021-11-02 02:16:02.889429: step 139000, loss = 0.111941, learning_rate = 0.000000 (2621.8 examples/sec)
=> Model saved to file: ./logs/model-139000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949418, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 02:16:34.515974: step 139100, loss = 0.095023, learning_rate = 0.000000 (2625.8 examples/sec)
=> 2021-11-02 02:16:55.075256: step 139200, loss = 0.078914, learning_rate = 0.000000 (2645.8 examples/sec)
=> 2021-11-02 02:17:14.711625: step 139300, loss = 0.087081, learning_rate = 0.000000 (2629.5 examples/sec)
=> 2021-11-02 02:17:34.360895: step 139400, loss = 0.103126, learning_rate = 0.000000 (2627.6 examples/sec)
=> 2021-11-02 02:17:54.034518: step 139500, loss = 0.058795, learning_rate = 0.000000 (2624.4 examples/sec)
=> 2021-11-02 02:18:14.623531: step 139600, loss = 0.107597, learning_rate = 0.000000 (2638.6 examples/sec)
=> 2021-11-02 02:18:34.304978: step 139700, loss = 0.135463, learning_rate = 0.000000 (2623.4 examples/sec)
=> 2021-11-02 02:18:53.986606: step 139800, loss = 0.133441, learning_rate = 0.000000 (2623.3 examples/sec)
=> 2021-11-02 02:19:13.697993: step 139900, loss = 0.111807, learning_rate = 0.000000 (2619.7 examples/sec)
=> 2021-11-02 02:19:34.291059: step 140000, loss = 0.094116, learning_rate = 0.000000 (2638.4 examples/sec)
=> Model saved to file: ./logs/model-140000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952020, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 02:20:05.866457: step 140100, loss = 0.074055, learning_rate = 0.000000 (2628.1 examples/sec)
=> 2021-11-02 02:20:25.512080: step 140200, loss = 0.104941, learning_rate = 0.000000 (2628.3 examples/sec)
=> 2021-11-02 02:20:45.167235: step 140300, loss = 0.114993, learning_rate = 0.000000 (2627.0 examples/sec)
=> 2021-11-02 02:21:05.739715: step 140400, loss = 0.073672, learning_rate = 0.000000 (2640.7 examples/sec)
=> 2021-11-02 02:21:25.409155: step 140500, loss = 0.145256, learning_rate = 0.000000 (2625.2 examples/sec)
=> 2021-11-02 02:21:45.139323: step 140600, loss = 0.121462, learning_rate = 0.000000 (2616.9 examples/sec)
=> 2021-11-02 02:22:04.814373: step 140700, loss = 0.056087, learning_rate = 0.000000 (2624.2 examples/sec)
=> 2021-11-02 02:22:25.388769: step 140800, loss = 0.107588, learning_rate = 0.000000 (2639.6 examples/sec)
=> 2021-11-02 02:22:45.096209: step 140900, loss = 0.112614, learning_rate = 0.000000 (2619.8 examples/sec)
=> 2021-11-02 02:23:04.800091: step 141000, loss = 0.120169, learning_rate = 0.000000 (2620.4 examples/sec)
=> Model saved to file: ./logs/model-141000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949418, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 02:23:36.220802: step 141100, loss = 0.103236, learning_rate = 0.000000 (2627.1 examples/sec)
=> 2021-11-02 02:23:56.801449: step 141200, loss = 0.063975, learning_rate = 0.000000 (2640.9 examples/sec)
=> 2021-11-02 02:24:16.456298: step 141300, loss = 0.130742, learning_rate = 0.000000 (2627.0 examples/sec)
=> 2021-11-02 02:24:36.115343: step 141400, loss = 0.099685, learning_rate = 0.000000 (2626.4 examples/sec)
=> 2021-11-02 02:24:55.814920: step 141500, loss = 0.134556, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-02 02:25:16.382810: step 141600, loss = 0.056260, learning_rate = 0.000000 (2641.7 examples/sec)
=> 2021-11-02 02:25:36.051400: step 141700, loss = 0.052941, learning_rate = 0.000000 (2625.2 examples/sec)
=> 2021-11-02 02:25:55.787951: step 141800, loss = 0.091439, learning_rate = 0.000000 (2616.3 examples/sec)
=> 2021-11-02 02:26:15.497102: step 141900, loss = 0.087109, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 02:26:35.185619: step 142000, loss = 0.109653, learning_rate = 0.000000 (2623.2 examples/sec)
=> Model saved to file: ./logs/model-142000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951867, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 02:27:07.463322: step 142100, loss = 0.145988, learning_rate = 0.000000 (2641.9 examples/sec)
=> 2021-11-02 02:27:27.100474: step 142200, loss = 0.081075, learning_rate = 0.000000 (2629.5 examples/sec)
=> 2021-11-02 02:27:46.740193: step 142300, loss = 0.068386, learning_rate = 0.000000 (2629.0 examples/sec)
=> 2021-11-02 02:28:06.391706: step 142400, loss = 0.121338, learning_rate = 0.000000 (2627.5 examples/sec)
=> 2021-11-02 02:28:27.096510: step 142500, loss = 0.093982, learning_rate = 0.000000 (2641.3 examples/sec)
=> 2021-11-02 02:28:46.771399: step 142600, loss = 0.086267, learning_rate = 0.000000 (2624.4 examples/sec)
=> 2021-11-02 02:29:06.458989: step 142700, loss = 0.132384, learning_rate = 0.000000 (2622.6 examples/sec)
=> 2021-11-02 02:29:26.157131: step 142800, loss = 0.065051, learning_rate = 0.000000 (2621.3 examples/sec)
=> 2021-11-02 02:29:46.793254: step 142900, loss = 0.081653, learning_rate = 0.000000 (2633.6 examples/sec)
=> 2021-11-02 02:30:06.479889: step 143000, loss = 0.074318, learning_rate = 0.000000 (2622.9 examples/sec)
=> Model saved to file: ./logs/model-143000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950337, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 02:30:37.965486: step 143100, loss = 0.090764, learning_rate = 0.000000 (2630.7 examples/sec)
=> 2021-11-02 02:30:57.601231: step 143200, loss = 0.099801, learning_rate = 0.000000 (2629.7 examples/sec)
=> 2021-11-02 02:31:18.420640: step 143300, loss = 0.069599, learning_rate = 0.000000 (2639.2 examples/sec)
=> 2021-11-02 02:31:38.058532: step 143400, loss = 0.105885, learning_rate = 0.000000 (2629.4 examples/sec)
=> 2021-11-02 02:31:57.712332: step 143500, loss = 0.075612, learning_rate = 0.000000 (2627.3 examples/sec)
=> 2021-11-02 02:32:17.401476: step 143600, loss = 0.069581, learning_rate = 0.000000 (2622.4 examples/sec)
=> 2021-11-02 02:32:38.079779: step 143700, loss = 0.069651, learning_rate = 0.000000 (2639.0 examples/sec)
=> 2021-11-02 02:32:57.786374: step 143800, loss = 0.102650, learning_rate = 0.000000 (2620.3 examples/sec)
=> 2021-11-02 02:33:17.552190: step 143900, loss = 0.097514, learning_rate = 0.000000 (2612.2 examples/sec)
=> 2021-11-02 02:33:37.254444: step 144000, loss = 0.067862, learning_rate = 0.000000 (2620.6 examples/sec)
=> Model saved to file: ./logs/model-144000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949801, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 02:34:09.528290: step 144100, loss = 0.092451, learning_rate = 0.000000 (2638.8 examples/sec)
=> 2021-11-02 02:34:29.170174: step 144200, loss = 0.095364, learning_rate = 0.000000 (2628.9 examples/sec)
=> 2021-11-02 02:34:48.822279: step 144300, loss = 0.073035, learning_rate = 0.000000 (2627.4 examples/sec)
=> 2021-11-02 02:35:08.568341: step 144400, loss = 0.059542, learning_rate = 0.000000 (2614.9 examples/sec)
=> 2021-11-02 02:35:29.325682: step 144500, loss = 0.038735, learning_rate = 0.000000 (2641.8 examples/sec)
=> 2021-11-02 02:35:48.976766: step 144600, loss = 0.063936, learning_rate = 0.000000 (2627.4 examples/sec)
=> 2021-11-02 02:36:08.649596: step 144700, loss = 0.157816, learning_rate = 0.000000 (2624.7 examples/sec)
=> 2021-11-02 02:36:28.355372: step 144800, loss = 0.125578, learning_rate = 0.000000 (2620.1 examples/sec)
=> 2021-11-02 02:36:48.022546: step 144900, loss = 0.072286, learning_rate = 0.000000 (2626.0 examples/sec)
=> 2021-11-02 02:37:08.892948: step 145000, loss = 0.102655, learning_rate = 0.000000 (2620.4 examples/sec)
=> Model saved to file: ./logs/model-145000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951867, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 02:37:40.396746: step 145100, loss = 0.070772, learning_rate = 0.000000 (2629.4 examples/sec)
=> 2021-11-02 02:38:00.020036: step 145200, loss = 0.073696, learning_rate = 0.000000 (2633.0 examples/sec)
=> 2021-11-02 02:38:19.682162: step 145300, loss = 0.146049, learning_rate = 0.000000 (2627.2 examples/sec)
=> 2021-11-02 02:38:40.245352: step 145400, loss = 0.051122, learning_rate = 0.000000 (2643.0 examples/sec)
=> 2021-11-02 02:38:59.911103: step 145500, loss = 0.133177, learning_rate = 0.000000 (2625.6 examples/sec)
=> 2021-11-02 02:39:19.607595: step 145600, loss = 0.065224, learning_rate = 0.000000 (2621.7 examples/sec)
=> 2021-11-02 02:39:39.299126: step 145700, loss = 0.059258, learning_rate = 0.000000 (2622.3 examples/sec)
=> 2021-11-02 02:39:59.897735: step 145800, loss = 0.064894, learning_rate = 0.000000 (2647.0 examples/sec)
=> 2021-11-02 02:40:19.593925: step 145900, loss = 0.111733, learning_rate = 0.000000 (2621.7 examples/sec)
=> 2021-11-02 02:40:39.292029: step 146000, loss = 0.066937, learning_rate = 0.000000 (2621.3 examples/sec)
=> Model saved to file: ./logs/model-146000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949189, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 02:41:10.722253: step 146100, loss = 0.064103, learning_rate = 0.000000 (2627.2 examples/sec)
=> 2021-11-02 02:41:31.342163: step 146200, loss = 0.117053, learning_rate = 0.000000 (2639.5 examples/sec)
=> 2021-11-02 02:41:50.982427: step 146300, loss = 0.089568, learning_rate = 0.000000 (2629.0 examples/sec)
=> 2021-11-02 02:42:10.646014: step 146400, loss = 0.093525, learning_rate = 0.000000 (2625.7 examples/sec)
=> 2021-11-02 02:42:30.306337: step 146500, loss = 0.103979, learning_rate = 0.000000 (2626.4 examples/sec)
=> 2021-11-02 02:42:50.903328: step 146600, loss = 0.053550, learning_rate = 0.000000 (2639.9 examples/sec)
=> 2021-11-02 02:43:10.580981: step 146700, loss = 0.074657, learning_rate = 0.000000 (2623.9 examples/sec)
=> 2021-11-02 02:43:30.329676: step 146800, loss = 0.101265, learning_rate = 0.000000 (2614.3 examples/sec)
=> 2021-11-02 02:43:50.002937: step 146900, loss = 0.190580, learning_rate = 0.000000 (2624.5 examples/sec)
=> 2021-11-02 02:44:10.629098: step 147000, loss = 0.076919, learning_rate = 0.000000 (2642.7 examples/sec)
=> Model saved to file: ./logs/model-147000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951331, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 02:44:42.325324: step 147100, loss = 0.092243, learning_rate = 0.000000 (2607.2 examples/sec)
=> 2021-11-02 02:45:01.950232: step 147200, loss = 0.090759, learning_rate = 0.000000 (2631.2 examples/sec)
=> 2021-11-02 02:45:21.589982: step 147300, loss = 0.109474, learning_rate = 0.000000 (2629.0 examples/sec)
=> 2021-11-02 02:45:42.230346: step 147400, loss = 0.104620, learning_rate = 0.000000 (2639.5 examples/sec)
=> 2021-11-02 02:46:01.890647: step 147500, loss = 0.046142, learning_rate = 0.000000 (2626.4 examples/sec)
=> 2021-11-02 02:46:21.562476: step 147600, loss = 0.098415, learning_rate = 0.000000 (2624.9 examples/sec)
=> 2021-11-02 02:46:41.235322: step 147700, loss = 0.054333, learning_rate = 0.000000 (2624.7 examples/sec)
=> 2021-11-02 02:47:01.900498: step 147800, loss = 0.080583, learning_rate = 0.000000 (2640.0 examples/sec)
=> 2021-11-02 02:47:21.583856: step 147900, loss = 0.093622, learning_rate = 0.000000 (2623.3 examples/sec)
=> 2021-11-02 02:47:41.336557: step 148000, loss = 0.065040, learning_rate = 0.000000 (2613.9 examples/sec)
=> Model saved to file: ./logs/model-148000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951102, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 02:48:12.715158: step 148100, loss = 0.099041, learning_rate = 0.000000 (2627.1 examples/sec)
=> 2021-11-02 02:48:32.375353: step 148200, loss = 0.166535, learning_rate = 0.000000 (2626.4 examples/sec)
=> 2021-11-02 02:48:53.026534: step 148300, loss = 0.127763, learning_rate = 0.000000 (2642.1 examples/sec)
=> 2021-11-02 02:49:12.703404: step 148400, loss = 0.127648, learning_rate = 0.000000 (2624.2 examples/sec)
=> 2021-11-02 02:49:32.371234: step 148500, loss = 0.088301, learning_rate = 0.000000 (2625.4 examples/sec)
=> 2021-11-02 02:49:52.091327: step 148600, loss = 0.052199, learning_rate = 0.000000 (2618.3 examples/sec)
=> 2021-11-02 02:50:12.877546: step 148700, loss = 0.056702, learning_rate = 0.000000 (2638.8 examples/sec)
=> 2021-11-02 02:50:32.562373: step 148800, loss = 0.083108, learning_rate = 0.000000 (2623.0 examples/sec)
=> 2021-11-02 02:50:52.273489: step 148900, loss = 0.054822, learning_rate = 0.000000 (2619.5 examples/sec)
=> 2021-11-02 02:51:11.982091: step 149000, loss = 0.059692, learning_rate = 0.000000 (2620.0 examples/sec)
=> Model saved to file: ./logs/model-149000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952632, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 02:51:44.394507: step 149100, loss = 0.099647, learning_rate = 0.000000 (2637.4 examples/sec)
=> 2021-11-02 02:52:04.031555: step 149200, loss = 0.056361, learning_rate = 0.000000 (2629.5 examples/sec)
=> 2021-11-02 02:52:23.682290: step 149300, loss = 0.094741, learning_rate = 0.000000 (2627.6 examples/sec)
=> 2021-11-02 02:52:43.344048: step 149400, loss = 0.065347, learning_rate = 0.000000 (2626.2 examples/sec)
=> 2021-11-02 02:53:03.978280: step 149500, loss = 0.076113, learning_rate = 0.000000 (2638.7 examples/sec)
=> 2021-11-02 02:53:23.676159: step 149600, loss = 0.136394, learning_rate = 0.000000 (2621.3 examples/sec)
=> 2021-11-02 02:53:43.348067: step 149700, loss = 0.114372, learning_rate = 0.000000 (2624.7 examples/sec)
=> 2021-11-02 02:54:03.049676: step 149800, loss = 0.105624, learning_rate = 0.000000 (2620.7 examples/sec)
=> 2021-11-02 02:54:23.875242: step 149900, loss = 0.095112, learning_rate = 0.000000 (2639.6 examples/sec)
=> 2021-11-02 02:54:43.583409: step 150000, loss = 0.056343, learning_rate = 0.000000 (2619.9 examples/sec)
=> Model saved to file: ./logs/model-150000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951485, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 02:55:15.105924: step 150100, loss = 0.138500, learning_rate = 0.000000 (2627.7 examples/sec)
=> 2021-11-02 02:55:34.738223: step 150200, loss = 0.081132, learning_rate = 0.000000 (2629.8 examples/sec)
=> 2021-11-02 02:55:55.274687: step 150300, loss = 0.089086, learning_rate = 0.000000 (2646.1 examples/sec)
=> 2021-11-02 02:56:14.950452: step 150400, loss = 0.130092, learning_rate = 0.000000 (2624.3 examples/sec)
=> 2021-11-02 02:56:34.662042: step 150500, loss = 0.061175, learning_rate = 0.000000 (2619.3 examples/sec)
=> 2021-11-02 02:56:54.353517: step 150600, loss = 0.071045, learning_rate = 0.000000 (2621.9 examples/sec)
=> 2021-11-02 02:57:15.161461: step 150700, loss = 0.069805, learning_rate = 0.000000 (2629.2 examples/sec)
=> 2021-11-02 02:57:34.866508: step 150800, loss = 0.111960, learning_rate = 0.000000 (2620.9 examples/sec)
=> 2021-11-02 02:57:54.572399: step 150900, loss = 0.062884, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 02:58:14.279369: step 151000, loss = 0.076314, learning_rate = 0.000000 (2620.1 examples/sec)
=> Model saved to file: ./logs/model-151000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952173, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 02:58:45.575465: step 151100, loss = 0.094348, learning_rate = 0.000000 (2625.6 examples/sec)
=> 2021-11-02 02:59:06.105001: step 151200, loss = 0.079223, learning_rate = 0.000000 (2646.2 examples/sec)
=> 2021-11-02 02:59:25.795978: step 151300, loss = 0.081810, learning_rate = 0.000000 (2622.3 examples/sec)
=> 2021-11-02 02:59:45.429671: step 151400, loss = 0.063757, learning_rate = 0.000000 (2629.9 examples/sec)
=> 2021-11-02 03:00:05.074969: step 151500, loss = 0.093377, learning_rate = 0.000000 (2628.4 examples/sec)
=> 2021-11-02 03:00:25.852430: step 151600, loss = 0.079292, learning_rate = 0.000000 (2639.2 examples/sec)
=> 2021-11-02 03:00:45.499109: step 151700, loss = 0.116892, learning_rate = 0.000000 (2628.1 examples/sec)
=> 2021-11-02 03:01:05.164758: step 151800, loss = 0.116128, learning_rate = 0.000000 (2625.8 examples/sec)
=> 2021-11-02 03:01:24.840848: step 151900, loss = 0.079676, learning_rate = 0.000000 (2624.4 examples/sec)
=> 2021-11-02 03:01:45.521373: step 152000, loss = 0.070061, learning_rate = 0.000000 (2639.1 examples/sec)
=> Model saved to file: ./logs/model-152000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951025, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 03:02:17.098569: step 152100, loss = 0.086432, learning_rate = 0.000000 (2629.0 examples/sec)
=> 2021-11-02 03:02:36.748894: step 152200, loss = 0.083363, learning_rate = 0.000000 (2627.7 examples/sec)
=> 2021-11-02 03:02:56.407088: step 152300, loss = 0.069676, learning_rate = 0.000000 (2626.6 examples/sec)
=> 2021-11-02 03:03:17.225466: step 152400, loss = 0.049638, learning_rate = 0.000000 (2646.1 examples/sec)
=> 2021-11-02 03:03:36.897983: step 152500, loss = 0.085028, learning_rate = 0.000000 (2624.7 examples/sec)
=> 2021-11-02 03:03:56.565790: step 152600, loss = 0.154953, learning_rate = 0.000000 (2625.4 examples/sec)
=> 2021-11-02 03:04:16.253753: step 152700, loss = 0.078776, learning_rate = 0.000000 (2623.0 examples/sec)
=> 2021-11-02 03:04:36.826924: step 152800, loss = 0.097978, learning_rate = 0.000000 (2640.7 examples/sec)
=> 2021-11-02 03:04:56.505996: step 152900, loss = 0.117743, learning_rate = 0.000000 (2623.8 examples/sec)
=> 2021-11-02 03:05:16.151236: step 153000, loss = 0.158388, learning_rate = 0.000000 (2628.3 examples/sec)
=> Model saved to file: ./logs/model-153000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952097, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 03:05:47.502484: step 153100, loss = 0.070938, learning_rate = 0.000000 (2634.6 examples/sec)
=> 2021-11-02 03:06:08.053766: step 153200, loss = 0.044178, learning_rate = 0.000000 (2646.1 examples/sec)
=> 2021-11-02 03:06:27.685958: step 153300, loss = 0.111158, learning_rate = 0.000000 (2630.0 examples/sec)
=> 2021-11-02 03:06:47.320164: step 153400, loss = 0.057247, learning_rate = 0.000000 (2629.8 examples/sec)
=> 2021-11-02 03:07:06.985139: step 153500, loss = 0.059441, learning_rate = 0.000000 (2625.7 examples/sec)
=> 2021-11-02 03:07:27.598725: step 153600, loss = 0.053838, learning_rate = 0.000000 (2642.0 examples/sec)
=> 2021-11-02 03:07:47.361011: step 153700, loss = 0.078633, learning_rate = 0.000000 (2612.8 examples/sec)
=> 2021-11-02 03:08:07.039990: step 153800, loss = 0.089978, learning_rate = 0.000000 (2623.9 examples/sec)
=> 2021-11-02 03:08:26.731910: step 153900, loss = 0.123974, learning_rate = 0.000000 (2622.0 examples/sec)
=> 2021-11-02 03:08:46.421988: step 154000, loss = 0.125562, learning_rate = 0.000000 (2623.1 examples/sec)
=> Model saved to file: ./logs/model-154000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949954, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 03:09:18.893830: step 154100, loss = 0.056227, learning_rate = 0.000000 (2639.9 examples/sec)
=> 2021-11-02 03:09:38.633029: step 154200, loss = 0.054962, learning_rate = 0.000000 (2615.6 examples/sec)
=> 2021-11-02 03:09:58.284431: step 154300, loss = 0.078084, learning_rate = 0.000000 (2627.4 examples/sec)
=> 2021-11-02 03:10:17.937318: step 154400, loss = 0.070082, learning_rate = 0.000000 (2627.2 examples/sec)
=> 2021-11-02 03:10:38.616403: step 154500, loss = 0.097989, learning_rate = 0.000000 (2641.3 examples/sec)
=> 2021-11-02 03:10:58.271737: step 154600, loss = 0.091325, learning_rate = 0.000000 (2627.2 examples/sec)
=> 2021-11-02 03:11:17.917266: step 154700, loss = 0.070510, learning_rate = 0.000000 (2628.4 examples/sec)
=> 2021-11-02 03:11:37.567222: step 154800, loss = 0.104603, learning_rate = 0.000000 (2627.6 examples/sec)
=> 2021-11-02 03:11:58.112261: step 154900, loss = 0.061566, learning_rate = 0.000000 (2644.6 examples/sec)
=> 2021-11-02 03:12:17.789596: step 155000, loss = 0.133526, learning_rate = 0.000000 (2624.0 examples/sec)
=> Model saved to file: ./logs/model-155000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952097, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 03:12:49.228616: step 155100, loss = 0.061955, learning_rate = 0.000000 (2626.9 examples/sec)
=> 2021-11-02 03:13:08.842653: step 155200, loss = 0.071534, learning_rate = 0.000000 (2632.6 examples/sec)
=> 2021-11-02 03:13:29.533862: step 155300, loss = 0.080432, learning_rate = 0.000000 (2644.6 examples/sec)
=> 2021-11-02 03:13:49.173609: step 155400, loss = 0.093289, learning_rate = 0.000000 (2629.0 examples/sec)
=> 2021-11-02 03:14:08.827183: step 155500, loss = 0.085734, learning_rate = 0.000000 (2627.3 examples/sec)
=> 2021-11-02 03:14:28.481966: step 155600, loss = 0.068866, learning_rate = 0.000000 (2627.2 examples/sec)
=> 2021-11-02 03:14:49.060283: step 155700, loss = 0.060323, learning_rate = 0.000000 (2639.0 examples/sec)
=> 2021-11-02 03:15:08.724177: step 155800, loss = 0.049368, learning_rate = 0.000000 (2626.1 examples/sec)
=> 2021-11-02 03:15:28.378044: step 155900, loss = 0.102375, learning_rate = 0.000000 (2627.3 examples/sec)
=> 2021-11-02 03:15:48.033878: step 156000, loss = 0.065810, learning_rate = 0.000000 (2627.0 examples/sec)
=> Model saved to file: ./logs/model-156000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949648, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 03:16:20.533231: step 156100, loss = 0.095165, learning_rate = 0.000000 (2639.9 examples/sec)
=> 2021-11-02 03:16:40.186457: step 156200, loss = 0.088536, learning_rate = 0.000000 (2627.1 examples/sec)
=> 2021-11-02 03:16:59.845073: step 156300, loss = 0.087134, learning_rate = 0.000000 (2626.5 examples/sec)
=> 2021-11-02 03:17:19.517776: step 156400, loss = 0.044133, learning_rate = 0.000000 (2624.6 examples/sec)
=> 2021-11-02 03:17:40.249397: step 156500, loss = 0.078605, learning_rate = 0.000000 (2638.6 examples/sec)
=> 2021-11-02 03:17:59.927950: step 156600, loss = 0.071646, learning_rate = 0.000000 (2624.1 examples/sec)
=> 2021-11-02 03:18:19.607235: step 156700, loss = 0.062078, learning_rate = 0.000000 (2623.9 examples/sec)
=> 2021-11-02 03:18:39.291547: step 156800, loss = 0.059035, learning_rate = 0.000000 (2623.2 examples/sec)
=> 2021-11-02 03:18:58.978708: step 156900, loss = 0.055077, learning_rate = 0.000000 (2623.7 examples/sec)
=> 2021-11-02 03:19:19.763556: step 157000, loss = 0.075922, learning_rate = 0.000000 (2630.3 examples/sec)
=> Model saved to file: ./logs/model-157000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951561, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 03:19:51.148804: step 157100, loss = 0.048816, learning_rate = 0.000000 (2628.0 examples/sec)
=> 2021-11-02 03:20:10.797704: step 157200, loss = 0.083115, learning_rate = 0.000000 (2628.1 examples/sec)
=> 2021-11-02 03:20:30.443895: step 157300, loss = 0.108612, learning_rate = 0.000000 (2628.1 examples/sec)
=> 2021-11-02 03:20:51.036760: step 157400, loss = 0.052131, learning_rate = 0.000000 (2641.0 examples/sec)
=> 2021-11-02 03:21:10.708350: step 157500, loss = 0.032808, learning_rate = 0.000000 (2625.9 examples/sec)
=> 2021-11-02 03:21:30.389190: step 157600, loss = 0.086859, learning_rate = 0.000000 (2623.5 examples/sec)
=> 2021-11-02 03:21:50.091229: step 157700, loss = 0.084579, learning_rate = 0.000000 (2620.7 examples/sec)
=> 2021-11-02 03:22:10.746224: step 157800, loss = 0.099219, learning_rate = 0.000000 (2635.4 examples/sec)
=> 2021-11-02 03:22:30.459103: step 157900, loss = 0.080550, learning_rate = 0.000000 (2619.5 examples/sec)
=> 2021-11-02 03:22:50.176338: step 158000, loss = 0.094026, learning_rate = 0.000000 (2619.1 examples/sec)
=> Model saved to file: ./logs/model-158000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949648, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 03:23:21.727453: step 158100, loss = 0.051905, learning_rate = 0.000000 (2627.0 examples/sec)
=> 2021-11-02 03:23:42.510555: step 158200, loss = 0.095228, learning_rate = 0.000000 (2645.7 examples/sec)
=> 2021-11-02 03:24:02.157553: step 158300, loss = 0.062583, learning_rate = 0.000000 (2628.1 examples/sec)
=> 2021-11-02 03:24:21.867561: step 158400, loss = 0.087303, learning_rate = 0.000000 (2619.7 examples/sec)
=> 2021-11-02 03:24:41.542696: step 158500, loss = 0.062232, learning_rate = 0.000000 (2624.3 examples/sec)
=> 2021-11-02 03:25:02.246925: step 158600, loss = 0.090275, learning_rate = 0.000000 (2635.7 examples/sec)
=> 2021-11-02 03:25:21.944155: step 158700, loss = 0.084531, learning_rate = 0.000000 (2621.4 examples/sec)
=> 2021-11-02 03:25:41.625978: step 158800, loss = 0.072809, learning_rate = 0.000000 (2623.4 examples/sec)
=> 2021-11-02 03:26:01.330029: step 158900, loss = 0.063588, learning_rate = 0.000000 (2620.6 examples/sec)
=> 2021-11-02 03:26:21.955178: step 159000, loss = 0.044776, learning_rate = 0.000000 (2639.5 examples/sec)
=> Model saved to file: ./logs/model-159000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952097, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 03:26:53.335889: step 159100, loss = 0.066681, learning_rate = 0.000000 (2628.2 examples/sec)
=> 2021-11-02 03:27:12.964112: step 159200, loss = 0.119841, learning_rate = 0.000000 (2630.6 examples/sec)
=> 2021-11-02 03:27:32.613913: step 159300, loss = 0.056014, learning_rate = 0.000000 (2627.7 examples/sec)
=> 2021-11-02 03:27:53.478548: step 159400, loss = 0.082505, learning_rate = 0.000000 (2637.3 examples/sec)
=> 2021-11-02 03:28:13.185006: step 159500, loss = 0.106594, learning_rate = 0.000000 (2619.9 examples/sec)
=> 2021-11-02 03:28:32.902832: step 159600, loss = 0.056820, learning_rate = 0.000000 (2618.7 examples/sec)
=> 2021-11-02 03:28:52.619207: step 159700, loss = 0.095154, learning_rate = 0.000000 (2618.7 examples/sec)
=> 2021-11-02 03:29:12.343594: step 159800, loss = 0.120490, learning_rate = 0.000000 (2618.4 examples/sec)
=> 2021-11-02 03:29:33.206341: step 159900, loss = 0.097506, learning_rate = 0.000000 (2631.7 examples/sec)
=> 2021-11-02 03:29:52.910788: step 160000, loss = 0.073018, learning_rate = 0.000000 (2620.6 examples/sec)
=> Model saved to file: ./logs/model-160000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951331, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 03:30:24.538070: step 160100, loss = 0.079303, learning_rate = 0.000000 (2627.7 examples/sec)
=> 2021-11-02 03:30:44.188087: step 160200, loss = 0.117962, learning_rate = 0.000000 (2627.9 examples/sec)
=> 2021-11-02 03:31:04.738945: step 160300, loss = 0.113752, learning_rate = 0.000000 (2647.2 examples/sec)
=> 2021-11-02 03:31:24.412925: step 160400, loss = 0.051631, learning_rate = 0.000000 (2624.5 examples/sec)
=> 2021-11-02 03:31:44.096500: step 160500, loss = 0.131844, learning_rate = 0.000000 (2623.5 examples/sec)
=> 2021-11-02 03:32:03.804616: step 160600, loss = 0.046734, learning_rate = 0.000000 (2620.3 examples/sec)
=> 2021-11-02 03:32:24.421799: step 160700, loss = 0.038191, learning_rate = 0.000000 (2638.1 examples/sec)
=> 2021-11-02 03:32:44.144451: step 160800, loss = 0.065166, learning_rate = 0.000000 (2618.0 examples/sec)
=> 2021-11-02 03:33:03.875711: step 160900, loss = 0.055929, learning_rate = 0.000000 (2617.0 examples/sec)
=> 2021-11-02 03:33:23.605500: step 161000, loss = 0.088485, learning_rate = 0.000000 (2616.9 examples/sec)
=> Model saved to file: ./logs/model-161000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952632, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 03:33:55.933245: step 161100, loss = 0.040611, learning_rate = 0.000000 (2644.2 examples/sec)
=> 2021-11-02 03:34:15.592073: step 161200, loss = 0.052691, learning_rate = 0.000000 (2626.6 examples/sec)
=> 2021-11-02 03:34:35.242465: step 161300, loss = 0.053454, learning_rate = 0.000000 (2627.6 examples/sec)
=> 2021-11-02 03:34:54.933935: step 161400, loss = 0.058023, learning_rate = 0.000000 (2622.3 examples/sec)
=> 2021-11-02 03:35:15.694887: step 161500, loss = 0.036597, learning_rate = 0.000000 (2630.6 examples/sec)
=> 2021-11-02 03:35:35.407756: step 161600, loss = 0.138303, learning_rate = 0.000000 (2619.1 examples/sec)
=> 2021-11-02 03:35:55.133813: step 161700, loss = 0.055275, learning_rate = 0.000000 (2617.5 examples/sec)
=> 2021-11-02 03:36:14.860848: step 161800, loss = 0.072480, learning_rate = 0.000000 (2617.6 examples/sec)
=> 2021-11-02 03:36:35.548386: step 161900, loss = 0.080193, learning_rate = 0.000000 (2633.8 examples/sec)
=> 2021-11-02 03:36:55.324761: step 162000, loss = 0.084239, learning_rate = 0.000000 (2610.9 examples/sec)
=> Model saved to file: ./logs/model-162000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950949, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 03:37:26.823035: step 162100, loss = 0.092230, learning_rate = 0.000000 (2628.8 examples/sec)
=> 2021-11-02 03:37:46.451873: step 162200, loss = 0.126581, learning_rate = 0.000000 (2630.4 examples/sec)
=> 2021-11-02 03:38:07.045097: step 162300, loss = 0.093113, learning_rate = 0.000000 (2644.9 examples/sec)
=> 2021-11-02 03:38:26.701732: step 162400, loss = 0.063771, learning_rate = 0.000000 (2626.7 examples/sec)
=> 2021-11-02 03:38:46.399083: step 162500, loss = 0.058252, learning_rate = 0.000000 (2621.4 examples/sec)
=> 2021-11-02 03:39:06.155852: step 162600, loss = 0.065263, learning_rate = 0.000000 (2613.6 examples/sec)
=> 2021-11-02 03:39:25.872967: step 162700, loss = 0.034832, learning_rate = 0.000000 (2619.4 examples/sec)
=> 2021-11-02 03:39:46.593574: step 162800, loss = 0.054147, learning_rate = 0.000000 (2633.4 examples/sec)
=> 2021-11-02 03:40:06.313872: step 162900, loss = 0.107655, learning_rate = 0.000000 (2618.7 examples/sec)
=> 2021-11-02 03:40:26.040784: step 163000, loss = 0.098712, learning_rate = 0.000000 (2617.4 examples/sec)
=> Model saved to file: ./logs/model-163000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950796, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 03:40:57.557719: step 163100, loss = 0.092554, learning_rate = 0.000000 (2624.4 examples/sec)
=> 2021-11-02 03:41:18.153807: step 163200, loss = 0.084810, learning_rate = 0.000000 (2656.4 examples/sec)
=> 2021-11-02 03:41:37.844517: step 163300, loss = 0.108016, learning_rate = 0.000000 (2622.2 examples/sec)
=> 2021-11-02 03:41:57.555205: step 163400, loss = 0.049644, learning_rate = 0.000000 (2619.8 examples/sec)
=> 2021-11-02 03:42:17.280585: step 163500, loss = 0.104209, learning_rate = 0.000000 (2617.6 examples/sec)
=> 2021-11-02 03:42:37.911210: step 163600, loss = 0.100918, learning_rate = 0.000000 (2634.2 examples/sec)
=> 2021-11-02 03:42:57.631793: step 163700, loss = 0.084264, learning_rate = 0.000000 (2618.3 examples/sec)
=> 2021-11-02 03:43:17.342278: step 163800, loss = 0.130518, learning_rate = 0.000000 (2619.6 examples/sec)
=> 2021-11-02 03:43:37.061106: step 163900, loss = 0.099150, learning_rate = 0.000000 (2618.4 examples/sec)
=> 2021-11-02 03:43:57.868773: step 164000, loss = 0.033962, learning_rate = 0.000000 (2636.7 examples/sec)
=> Model saved to file: ./logs/model-164000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952097, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 03:44:29.394745: step 164100, loss = 0.072175, learning_rate = 0.000000 (2625.8 examples/sec)
=> 2021-11-02 03:44:49.034529: step 164200, loss = 0.051073, learning_rate = 0.000000 (2628.9 examples/sec)
=> 2021-11-02 03:45:08.706994: step 164300, loss = 0.067411, learning_rate = 0.000000 (2624.8 examples/sec)
=> 2021-11-02 03:45:29.539252: step 164400, loss = 0.067881, learning_rate = 0.000000 (2640.1 examples/sec)
=> 2021-11-02 03:45:49.241432: step 164500, loss = 0.053346, learning_rate = 0.000000 (2621.0 examples/sec)
=> 2021-11-02 03:46:08.969223: step 164600, loss = 0.046332, learning_rate = 0.000000 (2617.3 examples/sec)
=> 2021-11-02 03:46:28.694346: step 164700, loss = 0.085687, learning_rate = 0.000000 (2617.9 examples/sec)
=> 2021-11-02 03:46:49.334758: step 164800, loss = 0.099334, learning_rate = 0.000000 (2635.9 examples/sec)
=> 2021-11-02 03:47:09.074738: step 164900, loss = 0.095636, learning_rate = 0.000000 (2615.8 examples/sec)
=> 2021-11-02 03:47:28.800320: step 165000, loss = 0.050846, learning_rate = 0.000000 (2617.9 examples/sec)
=> Model saved to file: ./logs/model-165000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951944, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 03:48:00.315023: step 165100, loss = 0.059487, learning_rate = 0.000000 (2624.7 examples/sec)
=> 2021-11-02 03:48:20.878107: step 165200, loss = 0.081085, learning_rate = 0.000000 (2647.0 examples/sec)
=> 2021-11-02 03:48:40.552372: step 165300, loss = 0.082272, learning_rate = 0.000000 (2624.6 examples/sec)
=> 2021-11-02 03:49:00.222389: step 165400, loss = 0.060147, learning_rate = 0.000000 (2624.9 examples/sec)
=> 2021-11-02 03:49:19.913660: step 165500, loss = 0.102858, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-02 03:49:39.599148: step 165600, loss = 0.055459, learning_rate = 0.000000 (2623.6 examples/sec)
=> 2021-11-02 03:50:00.398259: step 165700, loss = 0.094278, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-02 03:50:20.113016: step 165800, loss = 0.088536, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 03:50:39.819756: step 165900, loss = 0.058225, learning_rate = 0.000000 (2620.2 examples/sec)
=> 2021-11-02 03:50:59.547181: step 166000, loss = 0.075147, learning_rate = 0.000000 (2617.4 examples/sec)
=> Model saved to file: ./logs/model-166000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949878, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 03:51:31.806319: step 166100, loss = 0.059505, learning_rate = 0.000000 (2643.8 examples/sec)
=> 2021-11-02 03:51:51.450234: step 166200, loss = 0.079588, learning_rate = 0.000000 (2628.6 examples/sec)
=> 2021-11-02 03:52:11.121666: step 166300, loss = 0.056485, learning_rate = 0.000000 (2624.9 examples/sec)
=> 2021-11-02 03:52:30.828995: step 166400, loss = 0.079944, learning_rate = 0.000000 (2620.1 examples/sec)
=> 2021-11-02 03:52:51.414239: step 166500, loss = 0.057090, learning_rate = 0.000000 (2639.8 examples/sec)
=> 2021-11-02 03:53:11.122285: step 166600, loss = 0.102996, learning_rate = 0.000000 (2619.8 examples/sec)
=> 2021-11-02 03:53:30.844041: step 166700, loss = 0.086397, learning_rate = 0.000000 (2618.3 examples/sec)
=> 2021-11-02 03:53:50.565798: step 166800, loss = 0.057674, learning_rate = 0.000000 (2618.0 examples/sec)
=> 2021-11-02 03:54:11.350406: step 166900, loss = 0.053723, learning_rate = 0.000000 (2630.5 examples/sec)
=> 2021-11-02 03:54:31.072632: step 167000, loss = 0.079629, learning_rate = 0.000000 (2618.1 examples/sec)
=> Model saved to file: ./logs/model-167000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951638, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 03:55:02.496725: step 167100, loss = 0.087871, learning_rate = 0.000000 (2618.4 examples/sec)
=> 2021-11-02 03:55:22.145950: step 167200, loss = 0.051252, learning_rate = 0.000000 (2627.9 examples/sec)
=> 2021-11-02 03:55:42.866783: step 167300, loss = 0.045262, learning_rate = 0.000000 (2637.1 examples/sec)
=> 2021-11-02 03:56:02.542198: step 167400, loss = 0.102200, learning_rate = 0.000000 (2624.2 examples/sec)
=> 2021-11-02 03:56:22.216741: step 167500, loss = 0.108268, learning_rate = 0.000000 (2624.4 examples/sec)
=> 2021-11-02 03:56:41.905339: step 167600, loss = 0.063861, learning_rate = 0.000000 (2622.3 examples/sec)
=> 2021-11-02 03:57:02.517987: step 167700, loss = 0.081183, learning_rate = 0.000000 (2638.1 examples/sec)
=> 2021-11-02 03:57:22.216361: step 167800, loss = 0.038626, learning_rate = 0.000000 (2621.6 examples/sec)
=> 2021-11-02 03:57:41.918671: step 167900, loss = 0.075950, learning_rate = 0.000000 (2620.9 examples/sec)
=> 2021-11-02 03:58:01.623787: step 168000, loss = 0.052793, learning_rate = 0.000000 (2620.8 examples/sec)
=> Model saved to file: ./logs/model-168000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947352, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 03:58:33.968077: step 168100, loss = 0.058972, learning_rate = 0.000000 (2634.9 examples/sec)
=> 2021-11-02 03:58:53.624155: step 168200, loss = 0.056176, learning_rate = 0.000000 (2626.9 examples/sec)
=> 2021-11-02 03:59:13.287205: step 168300, loss = 0.082372, learning_rate = 0.000000 (2626.3 examples/sec)
=> 2021-11-02 03:59:32.958221: step 168400, loss = 0.080784, learning_rate = 0.000000 (2624.9 examples/sec)
=> 2021-11-02 03:59:53.560562: step 168500, loss = 0.080491, learning_rate = 0.000000 (2639.4 examples/sec)
=> 2021-11-02 04:00:13.240356: step 168600, loss = 0.067951, learning_rate = 0.000000 (2624.4 examples/sec)
=> 2021-11-02 04:00:32.918618: step 168700, loss = 0.064098, learning_rate = 0.000000 (2623.8 examples/sec)
=> 2021-11-02 04:00:52.621028: step 168800, loss = 0.068479, learning_rate = 0.000000 (2620.7 examples/sec)
=> 2021-11-02 04:01:12.351694: step 168900, loss = 0.113001, learning_rate = 0.000000 (2617.0 examples/sec)
=> 2021-11-02 04:01:32.946324: step 169000, loss = 0.065714, learning_rate = 0.000000 (2639.0 examples/sec)
=> Model saved to file: ./logs/model-169000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950337, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 04:02:04.440314: step 169100, loss = 0.069400, learning_rate = 0.000000 (2621.7 examples/sec)
=> 2021-11-02 04:02:24.087873: step 169200, loss = 0.038874, learning_rate = 0.000000 (2628.1 examples/sec)
=> 2021-11-02 04:02:43.745524: step 169300, loss = 0.070400, learning_rate = 0.000000 (2626.7 examples/sec)
=> 2021-11-02 04:03:04.352509: step 169400, loss = 0.045550, learning_rate = 0.000000 (2637.1 examples/sec)
=> 2021-11-02 04:03:24.016539: step 169500, loss = 0.057074, learning_rate = 0.000000 (2625.8 examples/sec)
=> 2021-11-02 04:03:43.691238: step 169600, loss = 0.041100, learning_rate = 0.000000 (2624.4 examples/sec)
=> 2021-11-02 04:04:03.397381: step 169700, loss = 0.053532, learning_rate = 0.000000 (2620.3 examples/sec)
=> 2021-11-02 04:04:24.037296: step 169800, loss = 0.046592, learning_rate = 0.000000 (2632.9 examples/sec)
=> 2021-11-02 04:04:43.735478: step 169900, loss = 0.046287, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-02 04:05:03.436279: step 170000, loss = 0.051592, learning_rate = 0.000000 (2620.9 examples/sec)
=> Model saved to file: ./logs/model-170000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952173, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 04:05:34.763158: step 170100, loss = 0.099442, learning_rate = 0.000000 (2624.5 examples/sec)
=> 2021-11-02 04:05:55.371511: step 170200, loss = 0.040523, learning_rate = 0.000000 (2639.6 examples/sec)
=> 2021-11-02 04:06:15.056889: step 170300, loss = 0.082829, learning_rate = 0.000000 (2623.3 examples/sec)
=> 2021-11-02 04:06:34.734381: step 170400, loss = 0.072898, learning_rate = 0.000000 (2624.1 examples/sec)
=> 2021-11-02 04:06:54.429605: step 170500, loss = 0.086930, learning_rate = 0.000000 (2621.6 examples/sec)
=> 2021-11-02 04:07:15.021290: step 170600, loss = 0.086741, learning_rate = 0.000000 (2638.6 examples/sec)
=> 2021-11-02 04:07:34.709381: step 170700, loss = 0.074981, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-02 04:07:54.403722: step 170800, loss = 0.034566, learning_rate = 0.000000 (2621.9 examples/sec)
=> 2021-11-02 04:08:14.120436: step 170900, loss = 0.074500, learning_rate = 0.000000 (2618.7 examples/sec)
=> 2021-11-02 04:08:34.764573: step 171000, loss = 0.082755, learning_rate = 0.000000 (2637.3 examples/sec)
=> Model saved to file: ./logs/model-171000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951102, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 04:09:06.281234: step 171100, loss = 0.036381, learning_rate = 0.000000 (2624.3 examples/sec)
=> 2021-11-02 04:09:25.943161: step 171200, loss = 0.114575, learning_rate = 0.000000 (2626.3 examples/sec)
=> 2021-11-02 04:09:45.606434: step 171300, loss = 0.099834, learning_rate = 0.000000 (2625.8 examples/sec)
=> 2021-11-02 04:10:06.198790: step 171400, loss = 0.088649, learning_rate = 0.000000 (2638.8 examples/sec)
=> 2021-11-02 04:10:25.899599: step 171500, loss = 0.064702, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-02 04:10:45.571972: step 171600, loss = 0.050001, learning_rate = 0.000000 (2624.6 examples/sec)
=> 2021-11-02 04:11:05.273198: step 171700, loss = 0.040512, learning_rate = 0.000000 (2620.9 examples/sec)
=> 2021-11-02 04:11:24.994661: step 171800, loss = 0.078339, learning_rate = 0.000000 (2618.4 examples/sec)
=> 2021-11-02 04:11:45.630685: step 171900, loss = 0.100980, learning_rate = 0.000000 (2637.1 examples/sec)
=> 2021-11-02 04:12:05.347809: step 172000, loss = 0.064130, learning_rate = 0.000000 (2618.7 examples/sec)
=> Model saved to file: ./logs/model-172000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949571, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 04:12:36.839384: step 172100, loss = 0.049557, learning_rate = 0.000000 (2625.0 examples/sec)
=> 2021-11-02 04:12:56.494319: step 172200, loss = 0.075554, learning_rate = 0.000000 (2626.8 examples/sec)
=> 2021-11-02 04:13:17.075870: step 172300, loss = 0.076545, learning_rate = 0.000000 (2640.2 examples/sec)
=> 2021-11-02 04:13:36.771329: step 172400, loss = 0.099032, learning_rate = 0.000000 (2622.2 examples/sec)
=> 2021-11-02 04:13:56.453293: step 172500, loss = 0.049115, learning_rate = 0.000000 (2623.4 examples/sec)
=> 2021-11-02 04:14:16.153098: step 172600, loss = 0.032629, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-02 04:14:36.795008: step 172700, loss = 0.066016, learning_rate = 0.000000 (2632.4 examples/sec)
=> 2021-11-02 04:14:56.494298: step 172800, loss = 0.095334, learning_rate = 0.000000 (2621.1 examples/sec)
=> 2021-11-02 04:15:16.196035: step 172900, loss = 0.046039, learning_rate = 0.000000 (2620.7 examples/sec)
=> 2021-11-02 04:15:35.908183: step 173000, loss = 0.065743, learning_rate = 0.000000 (2619.3 examples/sec)
=> Model saved to file: ./logs/model-173000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952250, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 04:16:08.364791: step 173100, loss = 0.061471, learning_rate = 0.000000 (2637.0 examples/sec)
=> 2021-11-02 04:16:28.033785: step 173200, loss = 0.072802, learning_rate = 0.000000 (2625.3 examples/sec)
=> 2021-11-02 04:16:47.699325: step 173300, loss = 0.050960, learning_rate = 0.000000 (2625.4 examples/sec)
=> 2021-11-02 04:17:07.378033: step 173400, loss = 0.072884, learning_rate = 0.000000 (2623.9 examples/sec)
=> 2021-11-02 04:17:27.983301: step 173500, loss = 0.053376, learning_rate = 0.000000 (2638.7 examples/sec)
=> 2021-11-02 04:17:47.679585: step 173600, loss = 0.085358, learning_rate = 0.000000 (2621.5 examples/sec)
=> 2021-11-02 04:18:07.379421: step 173700, loss = 0.065352, learning_rate = 0.000000 (2621.0 examples/sec)
=> 2021-11-02 04:18:27.085278: step 173800, loss = 0.038131, learning_rate = 0.000000 (2620.3 examples/sec)
=> 2021-11-02 04:18:47.722825: step 173900, loss = 0.109370, learning_rate = 0.000000 (2632.5 examples/sec)
=> 2021-11-02 04:19:07.443489: step 174000, loss = 0.059078, learning_rate = 0.000000 (2618.3 examples/sec)
=> Model saved to file: ./logs/model-174000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951255, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 04:19:38.756293: step 174100, loss = 0.071036, learning_rate = 0.000000 (2626.5 examples/sec)
=> 2021-11-02 04:19:58.415733: step 174200, loss = 0.059971, learning_rate = 0.000000 (2626.6 examples/sec)
=> 2021-11-02 04:20:18.994105: step 174300, loss = 0.032104, learning_rate = 0.000000 (2639.2 examples/sec)
=> 2021-11-02 04:20:38.663395: step 174400, loss = 0.052282, learning_rate = 0.000000 (2625.2 examples/sec)
=> 2021-11-02 04:20:58.344838: step 174500, loss = 0.040937, learning_rate = 0.000000 (2623.8 examples/sec)
=> 2021-11-02 04:21:18.042727: step 174600, loss = 0.038627, learning_rate = 0.000000 (2621.5 examples/sec)
=> 2021-11-02 04:21:37.742725: step 174700, loss = 0.039626, learning_rate = 0.000000 (2621.7 examples/sec)
=> 2021-11-02 04:21:58.515361: step 174800, loss = 0.054123, learning_rate = 0.000000 (2630.7 examples/sec)
=> 2021-11-02 04:22:18.223214: step 174900, loss = 0.096787, learning_rate = 0.000000 (2619.8 examples/sec)
=> 2021-11-02 04:22:37.929853: step 175000, loss = 0.080881, learning_rate = 0.000000 (2620.2 examples/sec)
=> Model saved to file: ./logs/model-175000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951178, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 04:23:09.322818: step 175100, loss = 0.115325, learning_rate = 0.000000 (2625.4 examples/sec)
=> 2021-11-02 04:23:30.039265: step 175200, loss = 0.063772, learning_rate = 0.000000 (2645.6 examples/sec)
=> 2021-11-02 04:23:49.689570: step 175300, loss = 0.061453, learning_rate = 0.000000 (2627.7 examples/sec)
=> 2021-11-02 04:24:09.362576: step 175400, loss = 0.028570, learning_rate = 0.000000 (2624.9 examples/sec)
=> 2021-11-02 04:24:29.058565: step 175500, loss = 0.052376, learning_rate = 0.000000 (2621.7 examples/sec)
=> 2021-11-02 04:24:49.693130: step 175600, loss = 0.079006, learning_rate = 0.000000 (2637.7 examples/sec)
=> 2021-11-02 04:25:09.402658: step 175700, loss = 0.085813, learning_rate = 0.000000 (2619.8 examples/sec)
=> 2021-11-02 04:25:29.120785: step 175800, loss = 0.119159, learning_rate = 0.000000 (2618.8 examples/sec)
=> 2021-11-02 04:25:48.826487: step 175900, loss = 0.047730, learning_rate = 0.000000 (2620.3 examples/sec)
=> 2021-11-02 04:26:09.622161: step 176000, loss = 0.113676, learning_rate = 0.000000 (2633.6 examples/sec)
=> Model saved to file: ./logs/model-176000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951867, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 04:26:40.878323: step 176100, loss = 0.051195, learning_rate = 0.000000 (2626.2 examples/sec)
=> 2021-11-02 04:27:00.530866: step 176200, loss = 0.047343, learning_rate = 0.000000 (2627.5 examples/sec)
=> 2021-11-02 04:27:20.187338: step 176300, loss = 0.054486, learning_rate = 0.000000 (2626.8 examples/sec)
=> 2021-11-02 04:27:40.899316: step 176400, loss = 0.061111, learning_rate = 0.000000 (2640.1 examples/sec)
=> 2021-11-02 04:28:00.578723: step 176500, loss = 0.041440, learning_rate = 0.000000 (2623.8 examples/sec)
=> 2021-11-02 04:28:20.272694: step 176600, loss = 0.061070, learning_rate = 0.000000 (2621.8 examples/sec)
=> 2021-11-02 04:28:39.989671: step 176700, loss = 0.054642, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 04:29:00.669538: step 176800, loss = 0.070270, learning_rate = 0.000000 (2634.0 examples/sec)
=> 2021-11-02 04:29:20.381126: step 176900, loss = 0.131998, learning_rate = 0.000000 (2619.5 examples/sec)
=> 2021-11-02 04:29:40.093735: step 177000, loss = 0.050871, learning_rate = 0.000000 (2619.2 examples/sec)
=> Model saved to file: ./logs/model-177000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951255, best accuracy 0.952632
=> patience = 99
=> 2021-11-02 04:30:11.630376: step 177100, loss = 0.068033, learning_rate = 0.000000 (2625.7 examples/sec)
=> 2021-11-02 04:30:32.291203: step 177200, loss = 0.065184, learning_rate = 0.000000 (2641.0 examples/sec)
=> 2021-11-02 04:30:51.965134: step 177300, loss = 0.055488, learning_rate = 0.000000 (2624.0 examples/sec)
=> 2021-11-02 04:31:11.632307: step 177400, loss = 0.110984, learning_rate = 0.000000 (2625.6 examples/sec)
=> 2021-11-02 04:31:31.282772: step 177500, loss = 0.068803, learning_rate = 0.000000 (2627.5 examples/sec)
=> 2021-11-02 04:31:50.955431: step 177600, loss = 0.036715, learning_rate = 0.000000 (2625.2 examples/sec)
=> 2021-11-02 04:32:11.584591: step 177700, loss = 0.034882, learning_rate = 0.000000 (2636.5 examples/sec)
=> 2021-11-02 04:32:31.257600: step 177800, loss = 0.051787, learning_rate = 0.000000 (2624.7 examples/sec)
=> 2021-11-02 04:32:50.947944: step 177900, loss = 0.066215, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-02 04:33:10.721833: step 178000, loss = 0.080567, learning_rate = 0.000000 (2611.2 examples/sec)
=> Model saved to file: ./logs/model-178000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953092, best accuracy 0.952632
=> Model saved to file: ./logs/model-178000.pth
=> patience = 100
=> 2021-11-02 04:33:43.690846: step 178100, loss = 0.044520, learning_rate = 0.000000 (2640.1 examples/sec)
=> 2021-11-02 04:34:03.323118: step 178200, loss = 0.049718, learning_rate = 0.000000 (2630.0 examples/sec)
=> 2021-11-02 04:34:22.975190: step 178300, loss = 0.038922, learning_rate = 0.000000 (2627.6 examples/sec)
=> 2021-11-02 04:34:42.647779: step 178400, loss = 0.048101, learning_rate = 0.000000 (2624.6 examples/sec)
=> 2021-11-02 04:35:03.222938: step 178500, loss = 0.093391, learning_rate = 0.000000 (2641.5 examples/sec)
=> 2021-11-02 04:35:22.935755: step 178600, loss = 0.127267, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 04:35:42.653257: step 178700, loss = 0.073941, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 04:36:02.379815: step 178800, loss = 0.057816, learning_rate = 0.000000 (2617.3 examples/sec)
=> 2021-11-02 04:36:23.070703: step 178900, loss = 0.069098, learning_rate = 0.000000 (2629.1 examples/sec)
=> 2021-11-02 04:36:42.796447: step 179000, loss = 0.098428, learning_rate = 0.000000 (2617.6 examples/sec)
=> Model saved to file: ./logs/model-179000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951714, best accuracy 0.953092
=> patience = 99
=> 2021-11-02 04:37:14.418354: step 179100, loss = 0.059888, learning_rate = 0.000000 (2624.5 examples/sec)
=> 2021-11-02 04:37:34.068386: step 179200, loss = 0.052923, learning_rate = 0.000000 (2627.6 examples/sec)
=> 2021-11-02 04:37:54.692025: step 179300, loss = 0.071184, learning_rate = 0.000000 (2637.0 examples/sec)
=> 2021-11-02 04:38:14.364861: step 179400, loss = 0.068280, learning_rate = 0.000000 (2624.8 examples/sec)
=> 2021-11-02 04:38:34.030744: step 179500, loss = 0.041160, learning_rate = 0.000000 (2625.8 examples/sec)
=> 2021-11-02 04:38:53.720141: step 179600, loss = 0.045072, learning_rate = 0.000000 (2622.7 examples/sec)
=> 2021-11-02 04:39:14.452559: step 179700, loss = 0.071909, learning_rate = 0.000000 (2637.0 examples/sec)
=> 2021-11-02 04:39:34.164295: step 179800, loss = 0.046186, learning_rate = 0.000000 (2619.5 examples/sec)
=> 2021-11-02 04:39:53.880840: step 179900, loss = 0.063331, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 04:40:13.593812: step 180000, loss = 0.064002, learning_rate = 0.000000 (2619.2 examples/sec)
=> Model saved to file: ./logs/model-180000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953245, best accuracy 0.953092
=> Model saved to file: ./logs/model-180000.pth
=> patience = 100
=> 2021-11-02 04:40:46.690604: step 180100, loss = 0.058398, learning_rate = 0.000000 (2641.6 examples/sec)
=> 2021-11-02 04:41:06.338063: step 180200, loss = 0.101746, learning_rate = 0.000000 (2627.9 examples/sec)
=> 2021-11-02 04:41:26.003883: step 180300, loss = 0.058709, learning_rate = 0.000000 (2625.6 examples/sec)
=> 2021-11-02 04:41:45.661762: step 180400, loss = 0.104329, learning_rate = 0.000000 (2626.5 examples/sec)
=> 2021-11-02 04:42:05.383116: step 180500, loss = 0.069287, learning_rate = 0.000000 (2619.0 examples/sec)
=> 2021-11-02 04:42:26.091489: step 180600, loss = 0.087585, learning_rate = 0.000000 (2633.6 examples/sec)
=> 2021-11-02 04:42:45.809239: step 180700, loss = 0.059424, learning_rate = 0.000000 (2618.7 examples/sec)
=> 2021-11-02 04:43:05.529236: step 180800, loss = 0.080039, learning_rate = 0.000000 (2618.5 examples/sec)
=> 2021-11-02 04:43:25.258758: step 180900, loss = 0.026006, learning_rate = 0.000000 (2617.1 examples/sec)
=> 2021-11-02 04:43:45.934294: step 181000, loss = 0.076481, learning_rate = 0.000000 (2634.7 examples/sec)
=> Model saved to file: ./logs/model-181000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950719, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 04:44:17.336931: step 181100, loss = 0.053408, learning_rate = 0.000000 (2625.1 examples/sec)
=> 2021-11-02 04:44:36.973195: step 181200, loss = 0.067995, learning_rate = 0.000000 (2629.4 examples/sec)
=> 2021-11-02 04:44:56.634171: step 181300, loss = 0.114808, learning_rate = 0.000000 (2626.1 examples/sec)
=> 2021-11-02 04:45:17.220186: step 181400, loss = 0.043137, learning_rate = 0.000000 (2640.1 examples/sec)
=> 2021-11-02 04:45:36.913794: step 181500, loss = 0.067754, learning_rate = 0.000000 (2621.8 examples/sec)
=> 2021-11-02 04:45:56.692120: step 181600, loss = 0.074721, learning_rate = 0.000000 (2610.4 examples/sec)
=> 2021-11-02 04:46:16.416260: step 181700, loss = 0.058184, learning_rate = 0.000000 (2617.9 examples/sec)
=> 2021-11-02 04:46:37.071117: step 181800, loss = 0.043697, learning_rate = 0.000000 (2632.3 examples/sec)
=> 2021-11-02 04:46:56.791974: step 181900, loss = 0.052910, learning_rate = 0.000000 (2618.2 examples/sec)
=> 2021-11-02 04:47:16.516190: step 182000, loss = 0.042722, learning_rate = 0.000000 (2617.6 examples/sec)
=> Model saved to file: ./logs/model-182000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951867, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 04:47:47.841733: step 182100, loss = 0.087839, learning_rate = 0.000000 (2624.6 examples/sec)
=> 2021-11-02 04:48:08.448700: step 182200, loss = 0.041339, learning_rate = 0.000000 (2640.5 examples/sec)
=> 2021-11-02 04:48:28.107079: step 182300, loss = 0.053105, learning_rate = 0.000000 (2626.5 examples/sec)
=> 2021-11-02 04:48:47.817512: step 182400, loss = 0.077197, learning_rate = 0.000000 (2619.7 examples/sec)
=> 2021-11-02 04:49:07.541212: step 182500, loss = 0.049057, learning_rate = 0.000000 (2617.8 examples/sec)
=> 2021-11-02 04:49:28.148675: step 182600, loss = 0.040717, learning_rate = 0.000000 (2637.8 examples/sec)
=> 2021-11-02 04:49:47.869976: step 182700, loss = 0.112933, learning_rate = 0.000000 (2618.2 examples/sec)
=> 2021-11-02 04:50:07.596903: step 182800, loss = 0.031504, learning_rate = 0.000000 (2617.7 examples/sec)
=> 2021-11-02 04:50:27.327527: step 182900, loss = 0.058317, learning_rate = 0.000000 (2617.1 examples/sec)
=> 2021-11-02 04:50:48.088143: step 183000, loss = 0.059947, learning_rate = 0.000000 (2634.4 examples/sec)
=> Model saved to file: ./logs/model-183000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950260, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 04:51:19.763277: step 183100, loss = 0.034503, learning_rate = 0.000000 (2625.0 examples/sec)
=> 2021-11-02 04:51:39.402948: step 183200, loss = 0.059230, learning_rate = 0.000000 (2628.8 examples/sec)
=> 2021-11-02 04:51:59.058815: step 183300, loss = 0.061687, learning_rate = 0.000000 (2627.0 examples/sec)
=> 2021-11-02 04:52:18.712083: step 183400, loss = 0.074671, learning_rate = 0.000000 (2627.6 examples/sec)
=> 2021-11-02 04:52:39.334751: step 183500, loss = 0.043960, learning_rate = 0.000000 (2633.1 examples/sec)
=> 2021-11-02 04:52:59.041455: step 183600, loss = 0.062963, learning_rate = 0.000000 (2620.2 examples/sec)
=> 2021-11-02 04:53:18.762067: step 183700, loss = 0.080260, learning_rate = 0.000000 (2618.3 examples/sec)
=> 2021-11-02 04:53:38.480335: step 183800, loss = 0.073031, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 04:53:59.251088: step 183900, loss = 0.055429, learning_rate = 0.000000 (2631.6 examples/sec)
=> 2021-11-02 04:54:18.968016: step 184000, loss = 0.045634, learning_rate = 0.000000 (2619.0 examples/sec)
=> Model saved to file: ./logs/model-184000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951025, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 04:54:50.609603: step 184100, loss = 0.058535, learning_rate = 0.000000 (2627.4 examples/sec)
=> 2021-11-02 04:55:10.263749: step 184200, loss = 0.061973, learning_rate = 0.000000 (2627.3 examples/sec)
=> 2021-11-02 04:55:30.908328: step 184300, loss = 0.021949, learning_rate = 0.000000 (2643.4 examples/sec)
=> 2021-11-02 04:55:50.604749: step 184400, loss = 0.060175, learning_rate = 0.000000 (2621.5 examples/sec)
=> 2021-11-02 04:56:10.326505: step 184500, loss = 0.046273, learning_rate = 0.000000 (2618.3 examples/sec)
=> 2021-11-02 04:56:30.058500: step 184600, loss = 0.052091, learning_rate = 0.000000 (2616.7 examples/sec)
=> 2021-11-02 04:56:50.663428: step 184700, loss = 0.056367, learning_rate = 0.000000 (2636.6 examples/sec)
=> 2021-11-02 04:57:10.383607: step 184800, loss = 0.037329, learning_rate = 0.000000 (2618.5 examples/sec)
=> 2021-11-02 04:57:30.094952: step 184900, loss = 0.054640, learning_rate = 0.000000 (2619.4 examples/sec)
=> 2021-11-02 04:57:49.817329: step 185000, loss = 0.027028, learning_rate = 0.000000 (2617.9 examples/sec)
=> Model saved to file: ./logs/model-185000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951638, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 04:58:22.334864: step 185100, loss = 0.073508, learning_rate = 0.000000 (2633.2 examples/sec)
=> 2021-11-02 04:58:41.981337: step 185200, loss = 0.082117, learning_rate = 0.000000 (2628.1 examples/sec)
=> 2021-11-02 04:59:01.678164: step 185300, loss = 0.054500, learning_rate = 0.000000 (2621.4 examples/sec)
=> 2021-11-02 04:59:21.400093: step 185400, loss = 0.053930, learning_rate = 0.000000 (2618.2 examples/sec)
=> 2021-11-02 04:59:42.027038: step 185500, loss = 0.115243, learning_rate = 0.000000 (2634.1 examples/sec)
=> 2021-11-02 05:00:01.741171: step 185600, loss = 0.070926, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 05:00:21.469639: step 185700, loss = 0.087935, learning_rate = 0.000000 (2617.3 examples/sec)
=> 2021-11-02 05:00:41.191978: step 185800, loss = 0.054526, learning_rate = 0.000000 (2618.0 examples/sec)
=> 2021-11-02 05:01:01.943853: step 185900, loss = 0.073986, learning_rate = 0.000000 (2630.0 examples/sec)
=> 2021-11-02 05:01:21.676244: step 186000, loss = 0.053978, learning_rate = 0.000000 (2616.6 examples/sec)
=> Model saved to file: ./logs/model-186000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952862, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 05:01:53.179549: step 186100, loss = 0.053837, learning_rate = 0.000000 (2629.0 examples/sec)
=> 2021-11-02 05:02:12.826629: step 186200, loss = 0.055243, learning_rate = 0.000000 (2628.1 examples/sec)
=> 2021-11-02 05:02:32.476556: step 186300, loss = 0.050962, learning_rate = 0.000000 (2628.1 examples/sec)
=> 2021-11-02 05:02:53.210365: step 186400, loss = 0.064324, learning_rate = 0.000000 (2619.0 examples/sec)
=> 2021-11-02 05:03:12.916408: step 186500, loss = 0.100792, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-02 05:03:32.634030: step 186600, loss = 0.085258, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 05:03:52.353166: step 186700, loss = 0.062947, learning_rate = 0.000000 (2618.5 examples/sec)
=> 2021-11-02 05:04:13.234574: step 186800, loss = 0.052086, learning_rate = 0.000000 (2634.4 examples/sec)
=> 2021-11-02 05:04:32.961032: step 186900, loss = 0.052633, learning_rate = 0.000000 (2617.5 examples/sec)
=> 2021-11-02 05:04:52.679107: step 187000, loss = 0.058793, learning_rate = 0.000000 (2618.5 examples/sec)
=> Model saved to file: ./logs/model-187000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950719, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 05:05:24.074829: step 187100, loss = 0.041837, learning_rate = 0.000000 (2625.2 examples/sec)
=> 2021-11-02 05:05:44.783773: step 187200, loss = 0.050796, learning_rate = 0.000000 (2644.5 examples/sec)
=> 2021-11-02 05:06:04.426606: step 187300, loss = 0.051127, learning_rate = 0.000000 (2628.5 examples/sec)
=> 2021-11-02 05:06:24.130496: step 187400, loss = 0.056679, learning_rate = 0.000000 (2620.3 examples/sec)
=> 2021-11-02 05:06:43.827724: step 187500, loss = 0.058390, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-02 05:07:04.511397: step 187600, loss = 0.047177, learning_rate = 0.000000 (2651.8 examples/sec)
=> 2021-11-02 05:07:24.221754: step 187700, loss = 0.081633, learning_rate = 0.000000 (2619.7 examples/sec)
=> 2021-11-02 05:07:43.936427: step 187800, loss = 0.037179, learning_rate = 0.000000 (2619.1 examples/sec)
=> 2021-11-02 05:08:03.662711: step 187900, loss = 0.060222, learning_rate = 0.000000 (2617.5 examples/sec)
=> 2021-11-02 05:08:24.306574: step 188000, loss = 0.066654, learning_rate = 0.000000 (2632.2 examples/sec)
=> Model saved to file: ./logs/model-188000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.946511, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 05:08:55.949384: step 188100, loss = 0.043400, learning_rate = 0.000000 (2626.5 examples/sec)
=> 2021-11-02 05:09:15.597290: step 188200, loss = 0.111465, learning_rate = 0.000000 (2627.8 examples/sec)
=> 2021-11-02 05:09:35.277701: step 188300, loss = 0.100352, learning_rate = 0.000000 (2623.4 examples/sec)
=> 2021-11-02 05:09:55.956649: step 188400, loss = 0.037045, learning_rate = 0.000000 (2637.5 examples/sec)
=> 2021-11-02 05:10:15.653673: step 188500, loss = 0.054588, learning_rate = 0.000000 (2621.3 examples/sec)
=> 2021-11-02 05:10:35.372256: step 188600, loss = 0.042653, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 05:10:55.094599: step 188700, loss = 0.066282, learning_rate = 0.000000 (2618.1 examples/sec)
=> 2021-11-02 05:11:15.768406: step 188800, loss = 0.076889, learning_rate = 0.000000 (2629.9 examples/sec)
=> 2021-11-02 05:11:35.488311: step 188900, loss = 0.044897, learning_rate = 0.000000 (2618.4 examples/sec)
=> 2021-11-02 05:11:55.225893: step 189000, loss = 0.057435, learning_rate = 0.000000 (2616.1 examples/sec)
=> Model saved to file: ./logs/model-189000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953015, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 05:12:26.844778: step 189100, loss = 0.035810, learning_rate = 0.000000 (2625.8 examples/sec)
=> 2021-11-02 05:12:47.398605: step 189200, loss = 0.067246, learning_rate = 0.000000 (2645.0 examples/sec)
=> 2021-11-02 05:13:07.084679: step 189300, loss = 0.051852, learning_rate = 0.000000 (2623.3 examples/sec)
=> 2021-11-02 05:13:26.778080: step 189400, loss = 0.057805, learning_rate = 0.000000 (2622.0 examples/sec)
=> 2021-11-02 05:13:46.491716: step 189500, loss = 0.044240, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 05:14:06.204453: step 189600, loss = 0.043004, learning_rate = 0.000000 (2619.3 examples/sec)
=> 2021-11-02 05:14:26.969012: step 189700, loss = 0.050273, learning_rate = 0.000000 (2633.4 examples/sec)
=> 2021-11-02 05:14:46.691394: step 189800, loss = 0.042088, learning_rate = 0.000000 (2618.0 examples/sec)
=> 2021-11-02 05:15:06.420216: step 189900, loss = 0.068151, learning_rate = 0.000000 (2617.1 examples/sec)
=> 2021-11-02 05:15:26.154793: step 190000, loss = 0.071844, learning_rate = 0.000000 (2616.4 examples/sec)
=> Model saved to file: ./logs/model-190000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948653, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 05:15:58.524590: step 190100, loss = 0.049074, learning_rate = 0.000000 (2637.9 examples/sec)
=> 2021-11-02 05:16:18.177273: step 190200, loss = 0.070513, learning_rate = 0.000000 (2627.5 examples/sec)
=> 2021-11-02 05:16:37.827125: step 190300, loss = 0.045030, learning_rate = 0.000000 (2627.8 examples/sec)
=> 2021-11-02 05:16:57.524835: step 190400, loss = 0.053925, learning_rate = 0.000000 (2621.3 examples/sec)
=> 2021-11-02 05:17:18.147916: step 190500, loss = 0.071718, learning_rate = 0.000000 (2638.2 examples/sec)
=> 2021-11-02 05:17:37.851219: step 190600, loss = 0.054156, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-02 05:17:57.575307: step 190700, loss = 0.042803, learning_rate = 0.000000 (2617.7 examples/sec)
=> 2021-11-02 05:18:17.304751: step 190800, loss = 0.065176, learning_rate = 0.000000 (2617.1 examples/sec)
=> 2021-11-02 05:18:38.088129: step 190900, loss = 0.089456, learning_rate = 0.000000 (2637.0 examples/sec)
=> 2021-11-02 05:18:57.815281: step 191000, loss = 0.045056, learning_rate = 0.000000 (2617.3 examples/sec)
=> Model saved to file: ./logs/model-191000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952938, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 05:19:29.435542: step 191100, loss = 0.057893, learning_rate = 0.000000 (2624.4 examples/sec)
=> 2021-11-02 05:19:49.089882: step 191200, loss = 0.046087, learning_rate = 0.000000 (2627.1 examples/sec)
=> 2021-11-02 05:20:09.718835: step 191300, loss = 0.099768, learning_rate = 0.000000 (2635.9 examples/sec)
=> 2021-11-02 05:20:29.417862: step 191400, loss = 0.051532, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-02 05:20:49.129073: step 191500, loss = 0.038795, learning_rate = 0.000000 (2619.4 examples/sec)
=> 2021-11-02 05:21:08.856476: step 191600, loss = 0.095227, learning_rate = 0.000000 (2617.5 examples/sec)
=> 2021-11-02 05:21:29.668912: step 191700, loss = 0.048321, learning_rate = 0.000000 (2631.8 examples/sec)
=> 2021-11-02 05:21:49.400440: step 191800, loss = 0.034578, learning_rate = 0.000000 (2617.0 examples/sec)
=> 2021-11-02 05:22:09.131815: step 191900, loss = 0.055541, learning_rate = 0.000000 (2616.8 examples/sec)
=> 2021-11-02 05:22:28.871325: step 192000, loss = 0.041784, learning_rate = 0.000000 (2615.8 examples/sec)
=> Model saved to file: ./logs/model-192000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952326, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 05:23:01.302905: step 192100, loss = 0.044000, learning_rate = 0.000000 (2644.5 examples/sec)
=> 2021-11-02 05:23:20.961956: step 192200, loss = 0.041668, learning_rate = 0.000000 (2626.6 examples/sec)
=> 2021-11-02 05:23:40.594418: step 192300, loss = 0.052684, learning_rate = 0.000000 (2630.2 examples/sec)
=> 2021-11-02 05:24:00.247455: step 192400, loss = 0.025191, learning_rate = 0.000000 (2627.3 examples/sec)
=> 2021-11-02 05:24:19.953697: step 192500, loss = 0.043829, learning_rate = 0.000000 (2620.1 examples/sec)
=> 2021-11-02 05:24:40.639697: step 192600, loss = 0.055683, learning_rate = 0.000000 (2632.5 examples/sec)
=> 2021-11-02 05:25:00.352142: step 192700, loss = 0.055701, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 05:25:20.080070: step 192800, loss = 0.040777, learning_rate = 0.000000 (2617.4 examples/sec)
=> 2021-11-02 05:25:39.804206: step 192900, loss = 0.049014, learning_rate = 0.000000 (2617.7 examples/sec)
=> 2021-11-02 05:26:00.526388: step 193000, loss = 0.093038, learning_rate = 0.000000 (2634.4 examples/sec)
=> Model saved to file: ./logs/model-193000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948118, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 05:26:32.159971: step 193100, loss = 0.040411, learning_rate = 0.000000 (2623.7 examples/sec)
=> 2021-11-02 05:26:51.815477: step 193200, loss = 0.048873, learning_rate = 0.000000 (2627.0 examples/sec)
=> 2021-11-02 05:27:11.492125: step 193300, loss = 0.057376, learning_rate = 0.000000 (2624.3 examples/sec)
=> 2021-11-02 05:27:32.128586: step 193400, loss = 0.032547, learning_rate = 0.000000 (2631.3 examples/sec)
=> 2021-11-02 05:27:51.835656: step 193500, loss = 0.048619, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 05:28:11.527539: step 193600, loss = 0.092630, learning_rate = 0.000000 (2622.0 examples/sec)
=> 2021-11-02 05:28:31.242932: step 193700, loss = 0.044923, learning_rate = 0.000000 (2618.9 examples/sec)
=> 2021-11-02 05:28:52.062570: step 193800, loss = 0.055522, learning_rate = 0.000000 (2634.7 examples/sec)
=> 2021-11-02 05:29:11.782747: step 193900, loss = 0.099117, learning_rate = 0.000000 (2618.4 examples/sec)
=> 2021-11-02 05:29:31.509371: step 194000, loss = 0.065541, learning_rate = 0.000000 (2617.5 examples/sec)
=> Model saved to file: ./logs/model-194000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950719, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 05:30:03.014716: step 194100, loss = 0.056296, learning_rate = 0.000000 (2624.0 examples/sec)
=> 2021-11-02 05:30:23.594784: step 194200, loss = 0.057607, learning_rate = 0.000000 (2641.6 examples/sec)
=> 2021-11-02 05:30:43.271623: step 194300, loss = 0.070064, learning_rate = 0.000000 (2624.5 examples/sec)
=> 2021-11-02 05:31:02.987184: step 194400, loss = 0.047733, learning_rate = 0.000000 (2620.5 examples/sec)
=> 2021-11-02 05:31:22.708230: step 194500, loss = 0.035661, learning_rate = 0.000000 (2619.8 examples/sec)
=> 2021-11-02 05:31:43.381889: step 194600, loss = 0.062486, learning_rate = 0.000000 (2633.9 examples/sec)
=> 2021-11-02 05:32:03.099229: step 194700, loss = 0.036318, learning_rate = 0.000000 (2618.8 examples/sec)
=> 2021-11-02 05:32:22.818439: step 194800, loss = 0.052942, learning_rate = 0.000000 (2618.5 examples/sec)
=> 2021-11-02 05:32:42.553723: step 194900, loss = 0.051538, learning_rate = 0.000000 (2616.5 examples/sec)
=> 2021-11-02 05:33:03.393151: step 195000, loss = 0.051485, learning_rate = 0.000000 (2626.2 examples/sec)
=> Model saved to file: ./logs/model-195000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950490, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 05:33:34.806584: step 195100, loss = 0.090826, learning_rate = 0.000000 (2628.7 examples/sec)
=> 2021-11-02 05:33:54.451150: step 195200, loss = 0.087959, learning_rate = 0.000000 (2628.7 examples/sec)
=> 2021-11-02 05:34:14.145295: step 195300, loss = 0.045440, learning_rate = 0.000000 (2622.1 examples/sec)
=> 2021-11-02 05:34:33.843001: step 195400, loss = 0.052515, learning_rate = 0.000000 (2622.2 examples/sec)
=> 2021-11-02 05:34:54.459341: step 195500, loss = 0.063131, learning_rate = 0.000000 (2635.2 examples/sec)
=> 2021-11-02 05:35:14.175133: step 195600, loss = 0.082851, learning_rate = 0.000000 (2618.8 examples/sec)
=> 2021-11-02 05:35:33.880094: step 195700, loss = 0.074115, learning_rate = 0.000000 (2620.3 examples/sec)
=> 2021-11-02 05:35:53.602316: step 195800, loss = 0.044576, learning_rate = 0.000000 (2618.1 examples/sec)
=> 2021-11-02 05:36:14.264459: step 195900, loss = 0.059942, learning_rate = 0.000000 (2630.5 examples/sec)
=> 2021-11-02 05:36:33.992019: step 196000, loss = 0.052784, learning_rate = 0.000000 (2617.4 examples/sec)
=> Model saved to file: ./logs/model-196000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951944, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 05:37:05.478433: step 196100, loss = 0.069350, learning_rate = 0.000000 (2617.0 examples/sec)
=> 2021-11-02 05:37:25.131269: step 196200, loss = 0.063306, learning_rate = 0.000000 (2627.2 examples/sec)
=> 2021-11-02 05:37:45.701586: step 196300, loss = 0.036227, learning_rate = 0.000000 (2642.7 examples/sec)
=> 2021-11-02 05:38:05.446985: step 196400, loss = 0.067867, learning_rate = 0.000000 (2615.0 examples/sec)
=> 2021-11-02 05:38:25.161098: step 196500, loss = 0.054170, learning_rate = 0.000000 (2619.1 examples/sec)
=> 2021-11-02 05:38:44.876743: step 196600, loss = 0.051570, learning_rate = 0.000000 (2618.9 examples/sec)
=> 2021-11-02 05:39:05.770552: step 196700, loss = 0.040127, learning_rate = 0.000000 (2632.5 examples/sec)
=> 2021-11-02 05:39:25.485324: step 196800, loss = 0.069912, learning_rate = 0.000000 (2618.9 examples/sec)
=> 2021-11-02 05:39:45.198041: step 196900, loss = 0.041960, learning_rate = 0.000000 (2619.3 examples/sec)
=> 2021-11-02 05:40:04.931265: step 197000, loss = 0.033790, learning_rate = 0.000000 (2616.7 examples/sec)
=> Model saved to file: ./logs/model-197000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952632, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 05:40:37.312317: step 197100, loss = 0.065726, learning_rate = 0.000000 (2641.7 examples/sec)
=> 2021-11-02 05:40:56.986534: step 197200, loss = 0.029085, learning_rate = 0.000000 (2624.6 examples/sec)
=> 2021-11-02 05:41:16.701265: step 197300, loss = 0.042143, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 05:41:36.420429: step 197400, loss = 0.034306, learning_rate = 0.000000 (2618.5 examples/sec)
=> 2021-11-02 05:41:57.151683: step 197500, loss = 0.062512, learning_rate = 0.000000 (2633.8 examples/sec)
=> 2021-11-02 05:42:16.925935: step 197600, loss = 0.098557, learning_rate = 0.000000 (2611.4 examples/sec)
=> 2021-11-02 05:42:36.635615: step 197700, loss = 0.044216, learning_rate = 0.000000 (2619.9 examples/sec)
=> 2021-11-02 05:42:56.358341: step 197800, loss = 0.048089, learning_rate = 0.000000 (2617.9 examples/sec)
=> 2021-11-02 05:43:17.188486: step 197900, loss = 0.046637, learning_rate = 0.000000 (2625.0 examples/sec)
=> 2021-11-02 05:43:36.900011: step 198000, loss = 0.052995, learning_rate = 0.000000 (2619.5 examples/sec)
=> Model saved to file: ./logs/model-198000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950949, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 05:44:08.394621: step 198100, loss = 0.045699, learning_rate = 0.000000 (2627.4 examples/sec)
=> 2021-11-02 05:44:28.117507: step 198200, loss = 0.071733, learning_rate = 0.000000 (2618.1 examples/sec)
=> 2021-11-02 05:44:47.790020: step 198300, loss = 0.053667, learning_rate = 0.000000 (2625.1 examples/sec)
=> 2021-11-02 05:45:08.430487: step 198400, loss = 0.032016, learning_rate = 0.000000 (2632.9 examples/sec)
=> 2021-11-02 05:45:28.145924: step 198500, loss = 0.034416, learning_rate = 0.000000 (2618.8 examples/sec)
=> 2021-11-02 05:45:47.857588: step 198600, loss = 0.053605, learning_rate = 0.000000 (2619.7 examples/sec)
=> 2021-11-02 05:46:07.581675: step 198700, loss = 0.025782, learning_rate = 0.000000 (2617.8 examples/sec)
=> 2021-11-02 05:46:28.207092: step 198800, loss = 0.035551, learning_rate = 0.000000 (2644.5 examples/sec)
=> 2021-11-02 05:46:47.909229: step 198900, loss = 0.033878, learning_rate = 0.000000 (2620.7 examples/sec)
=> 2021-11-02 05:47:07.626318: step 199000, loss = 0.053036, learning_rate = 0.000000 (2619.1 examples/sec)
=> Model saved to file: ./logs/model-199000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952020, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 05:47:39.004780: step 199100, loss = 0.065985, learning_rate = 0.000000 (2627.7 examples/sec)
=> 2021-11-02 05:47:59.581353: step 199200, loss = 0.033912, learning_rate = 0.000000 (2641.3 examples/sec)
=> 2021-11-02 05:48:19.238072: step 199300, loss = 0.053932, learning_rate = 0.000000 (2626.8 examples/sec)
=> 2021-11-02 05:48:38.940509: step 199400, loss = 0.065957, learning_rate = 0.000000 (2620.9 examples/sec)
=> 2021-11-02 05:48:58.658071: step 199500, loss = 0.038813, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 05:49:19.332645: step 199600, loss = 0.049644, learning_rate = 0.000000 (2632.0 examples/sec)
=> 2021-11-02 05:49:39.058419: step 199700, loss = 0.057275, learning_rate = 0.000000 (2617.8 examples/sec)
=> 2021-11-02 05:49:58.770438: step 199800, loss = 0.085081, learning_rate = 0.000000 (2619.5 examples/sec)
=> 2021-11-02 05:50:18.498325: step 199900, loss = 0.045102, learning_rate = 0.000000 (2617.2 examples/sec)
=> 2021-11-02 05:50:39.136166: step 200000, loss = 0.043918, learning_rate = 0.000000 (2635.4 examples/sec)
=> Model saved to file: ./logs/model-200000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952785, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 05:51:10.535425: step 200100, loss = 0.064774, learning_rate = 0.000000 (2626.9 examples/sec)
=> 2021-11-02 05:51:30.179669: step 200200, loss = 0.034083, learning_rate = 0.000000 (2628.4 examples/sec)
=> 2021-11-02 05:51:49.874649: step 200300, loss = 0.051223, learning_rate = 0.000000 (2621.6 examples/sec)
=> 2021-11-02 05:52:10.699713: step 200400, loss = 0.032506, learning_rate = 0.000000 (2632.1 examples/sec)
=> 2021-11-02 05:52:30.413849: step 200500, loss = 0.021566, learning_rate = 0.000000 (2619.1 examples/sec)
=> 2021-11-02 05:52:50.119404: step 200600, loss = 0.037778, learning_rate = 0.000000 (2620.1 examples/sec)
=> 2021-11-02 05:53:09.834408: step 200700, loss = 0.051718, learning_rate = 0.000000 (2619.0 examples/sec)
=> 2021-11-02 05:53:30.480607: step 200800, loss = 0.059741, learning_rate = 0.000000 (2631.1 examples/sec)
=> 2021-11-02 05:53:50.206910: step 200900, loss = 0.055241, learning_rate = 0.000000 (2617.5 examples/sec)
=> 2021-11-02 05:54:09.944485: step 201000, loss = 0.038900, learning_rate = 0.000000 (2616.0 examples/sec)
=> Model saved to file: ./logs/model-201000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948730, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 05:54:41.282703: step 201100, loss = 0.055276, learning_rate = 0.000000 (2626.3 examples/sec)
=> 2021-11-02 05:55:00.967476: step 201200, loss = 0.032297, learning_rate = 0.000000 (2623.5 examples/sec)
=> 2021-11-02 05:55:21.599948: step 201300, loss = 0.041502, learning_rate = 0.000000 (2633.0 examples/sec)
=> 2021-11-02 05:55:41.304230: step 201400, loss = 0.037008, learning_rate = 0.000000 (2620.6 examples/sec)
=> 2021-11-02 05:56:01.026899: step 201500, loss = 0.060092, learning_rate = 0.000000 (2618.0 examples/sec)
=> 2021-11-02 05:56:20.748315: step 201600, loss = 0.041272, learning_rate = 0.000000 (2618.2 examples/sec)
=> 2021-11-02 05:56:41.387256: step 201700, loss = 0.051732, learning_rate = 0.000000 (2632.4 examples/sec)
=> 2021-11-02 05:57:01.107672: step 201800, loss = 0.038030, learning_rate = 0.000000 (2618.8 examples/sec)
=> 2021-11-02 05:57:20.838276: step 201900, loss = 0.038804, learning_rate = 0.000000 (2617.1 examples/sec)
=> 2021-11-02 05:57:40.576896: step 202000, loss = 0.030137, learning_rate = 0.000000 (2616.0 examples/sec)
=> Model saved to file: ./logs/model-202000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951485, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 05:58:12.959495: step 202100, loss = 0.029040, learning_rate = 0.000000 (2636.3 examples/sec)
=> 2021-11-02 05:58:32.631177: step 202200, loss = 0.043974, learning_rate = 0.000000 (2625.0 examples/sec)
=> 2021-11-02 05:58:52.440881: step 202300, loss = 0.047988, learning_rate = 0.000000 (2606.2 examples/sec)
=> 2021-11-02 05:59:12.147924: step 202400, loss = 0.050607, learning_rate = 0.000000 (2620.2 examples/sec)
=> 2021-11-02 05:59:32.816726: step 202500, loss = 0.035956, learning_rate = 0.000000 (2634.3 examples/sec)
=> 2021-11-02 05:59:52.596583: step 202600, loss = 0.037899, learning_rate = 0.000000 (2610.4 examples/sec)
=> 2021-11-02 06:00:12.331736: step 202700, loss = 0.026587, learning_rate = 0.000000 (2616.3 examples/sec)
=> 2021-11-02 06:00:32.057139: step 202800, loss = 0.042012, learning_rate = 0.000000 (2617.7 examples/sec)
=> 2021-11-02 06:00:52.711531: step 202900, loss = 0.053082, learning_rate = 0.000000 (2635.0 examples/sec)
=> 2021-11-02 06:01:12.437672: step 203000, loss = 0.057681, learning_rate = 0.000000 (2617.7 examples/sec)
=> Model saved to file: ./logs/model-203000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952632, best accuracy 0.953245
=> patience = 99
=> 2021-11-02 06:01:43.822185: step 203100, loss = 0.044762, learning_rate = 0.000000 (2622.9 examples/sec)
=> 2021-11-02 06:02:03.527563: step 203200, loss = 0.056960, learning_rate = 0.000000 (2620.3 examples/sec)
=> 2021-11-02 06:02:24.152844: step 203300, loss = 0.081100, learning_rate = 0.000000 (2633.9 examples/sec)
=> 2021-11-02 06:02:43.843991: step 203400, loss = 0.044142, learning_rate = 0.000000 (2622.1 examples/sec)
=> 2021-11-02 06:03:03.664941: step 203500, loss = 0.051147, learning_rate = 0.000000 (2605.1 examples/sec)
=> 2021-11-02 06:03:23.394389: step 203600, loss = 0.063257, learning_rate = 0.000000 (2617.0 examples/sec)
=> 2021-11-02 06:03:44.095959: step 203700, loss = 0.055706, learning_rate = 0.000000 (2634.5 examples/sec)
=> 2021-11-02 06:04:03.797030: step 203800, loss = 0.038162, learning_rate = 0.000000 (2620.7 examples/sec)
=> 2021-11-02 06:04:23.534490: step 203900, loss = 0.068290, learning_rate = 0.000000 (2616.3 examples/sec)
=> 2021-11-02 06:04:43.256515: step 204000, loss = 0.029200, learning_rate = 0.000000 (2618.1 examples/sec)
=> Model saved to file: ./logs/model-204000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953398, best accuracy 0.953245
=> Model saved to file: ./logs/model-204000.pth
=> patience = 100
=> 2021-11-02 06:05:15.350156: step 204100, loss = 0.049396, learning_rate = 0.000000 (2625.3 examples/sec)
=> 2021-11-02 06:05:36.026852: step 204200, loss = 0.027798, learning_rate = 0.000000 (2641.7 examples/sec)
=> 2021-11-02 06:05:55.680767: step 204300, loss = 0.047067, learning_rate = 0.000000 (2627.1 examples/sec)
=> 2021-11-02 06:06:15.370603: step 204400, loss = 0.036731, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-02 06:06:35.049670: step 204500, loss = 0.084149, learning_rate = 0.000000 (2623.8 examples/sec)
=> 2021-11-02 06:06:55.659276: step 204600, loss = 0.085105, learning_rate = 0.000000 (2637.1 examples/sec)
=> 2021-11-02 06:07:15.356116: step 204700, loss = 0.071760, learning_rate = 0.000000 (2621.6 examples/sec)
=> 2021-11-02 06:07:35.049366: step 204800, loss = 0.027756, learning_rate = 0.000000 (2621.9 examples/sec)
=> 2021-11-02 06:07:54.745596: step 204900, loss = 0.083039, learning_rate = 0.000000 (2621.5 examples/sec)
=> 2021-11-02 06:08:15.640392: step 205000, loss = 0.042713, learning_rate = 0.000000 (2620.5 examples/sec)
=> Model saved to file: ./logs/model-205000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954775, best accuracy 0.953398
=> Model saved to file: ./logs/model-205000.pth
=> patience = 100
=> 2021-11-02 06:08:47.530482: step 205100, loss = 0.034970, learning_rate = 0.000000 (2629.2 examples/sec)
=> 2021-11-02 06:09:07.174480: step 205200, loss = 0.050910, learning_rate = 0.000000 (2628.5 examples/sec)
=> 2021-11-02 06:09:26.869152: step 205300, loss = 0.050096, learning_rate = 0.000000 (2621.7 examples/sec)
=> 2021-11-02 06:09:47.652240: step 205400, loss = 0.103187, learning_rate = 0.000000 (2637.0 examples/sec)
=> 2021-11-02 06:10:07.354619: step 205500, loss = 0.019814, learning_rate = 0.000000 (2620.8 examples/sec)
=> 2021-11-02 06:10:27.054536: step 205600, loss = 0.044409, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-02 06:10:46.763221: step 205700, loss = 0.040447, learning_rate = 0.000000 (2619.9 examples/sec)
=> 2021-11-02 06:11:07.499506: step 205800, loss = 0.098076, learning_rate = 0.000000 (2635.1 examples/sec)
=> 2021-11-02 06:11:27.227140: step 205900, loss = 0.061907, learning_rate = 0.000000 (2617.4 examples/sec)
=> 2021-11-02 06:11:46.947159: step 206000, loss = 0.068776, learning_rate = 0.000000 (2618.2 examples/sec)
=> Model saved to file: ./logs/model-206000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952479, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 06:12:18.368323: step 206100, loss = 0.033578, learning_rate = 0.000000 (2627.2 examples/sec)
=> 2021-11-02 06:12:39.078652: step 206200, loss = 0.035982, learning_rate = 0.000000 (2639.2 examples/sec)
=> 2021-11-02 06:12:58.733053: step 206300, loss = 0.038287, learning_rate = 0.000000 (2627.2 examples/sec)
=> 2021-11-02 06:13:18.406721: step 206400, loss = 0.047773, learning_rate = 0.000000 (2624.5 examples/sec)
=> 2021-11-02 06:13:38.097603: step 206500, loss = 0.037805, learning_rate = 0.000000 (2622.3 examples/sec)
=> 2021-11-02 06:13:58.741108: step 206600, loss = 0.034244, learning_rate = 0.000000 (2636.7 examples/sec)
=> 2021-11-02 06:14:18.432785: step 206700, loss = 0.044251, learning_rate = 0.000000 (2622.2 examples/sec)
=> 2021-11-02 06:14:38.143147: step 206800, loss = 0.062162, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 06:14:57.853496: step 206900, loss = 0.053280, learning_rate = 0.000000 (2619.5 examples/sec)
=> 2021-11-02 06:15:17.568304: step 207000, loss = 0.047044, learning_rate = 0.000000 (2619.7 examples/sec)
=> Model saved to file: ./logs/model-207000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951638, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 06:15:50.184132: step 207100, loss = 0.060823, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 06:16:09.838499: step 207200, loss = 0.024006, learning_rate = 0.000000 (2627.2 examples/sec)
=> 2021-11-02 06:16:29.520955: step 207300, loss = 0.050572, learning_rate = 0.000000 (2623.4 examples/sec)
=> 2021-11-02 06:16:49.194873: step 207400, loss = 0.027713, learning_rate = 0.000000 (2624.6 examples/sec)
=> 2021-11-02 06:17:09.801693: step 207500, loss = 0.053724, learning_rate = 0.000000 (2638.0 examples/sec)
=> 2021-11-02 06:17:29.480815: step 207600, loss = 0.049935, learning_rate = 0.000000 (2623.8 examples/sec)
=> 2021-11-02 06:17:49.181914: step 207700, loss = 0.051261, learning_rate = 0.000000 (2621.0 examples/sec)
=> 2021-11-02 06:18:08.890645: step 207800, loss = 0.044855, learning_rate = 0.000000 (2619.9 examples/sec)
=> 2021-11-02 06:18:29.505759: step 207900, loss = 0.057073, learning_rate = 0.000000 (2635.1 examples/sec)
=> 2021-11-02 06:18:49.207159: step 208000, loss = 0.036203, learning_rate = 0.000000 (2620.8 examples/sec)
=> Model saved to file: ./logs/model-208000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952403, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 06:19:20.692853: step 208100, loss = 0.029409, learning_rate = 0.000000 (2624.6 examples/sec)
=> 2021-11-02 06:19:40.345345: step 208200, loss = 0.032954, learning_rate = 0.000000 (2627.4 examples/sec)
=> 2021-11-02 06:20:00.921712: step 208300, loss = 0.048604, learning_rate = 0.000000 (2640.1 examples/sec)
=> 2021-11-02 06:20:20.599812: step 208400, loss = 0.075225, learning_rate = 0.000000 (2623.9 examples/sec)
=> 2021-11-02 06:20:40.278332: step 208500, loss = 0.064908, learning_rate = 0.000000 (2624.1 examples/sec)
=> 2021-11-02 06:20:59.991543: step 208600, loss = 0.052630, learning_rate = 0.000000 (2619.3 examples/sec)
=> 2021-11-02 06:21:20.598161: step 208700, loss = 0.063690, learning_rate = 0.000000 (2641.7 examples/sec)
=> 2021-11-02 06:21:40.285563: step 208800, loss = 0.062344, learning_rate = 0.000000 (2622.4 examples/sec)
=> 2021-11-02 06:21:59.980807: step 208900, loss = 0.079692, learning_rate = 0.000000 (2621.6 examples/sec)
=> 2021-11-02 06:22:19.682475: step 209000, loss = 0.037739, learning_rate = 0.000000 (2620.8 examples/sec)
=> Model saved to file: ./logs/model-209000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949801, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 06:22:52.241034: step 209100, loss = 0.047189, learning_rate = 0.000000 (2634.7 examples/sec)
=> 2021-11-02 06:23:11.898398: step 209200, loss = 0.025022, learning_rate = 0.000000 (2626.5 examples/sec)
=> 2021-11-02 06:23:31.553602: step 209300, loss = 0.052580, learning_rate = 0.000000 (2626.9 examples/sec)
=> 2021-11-02 06:23:51.227792: step 209400, loss = 0.083631, learning_rate = 0.000000 (2624.5 examples/sec)
=> 2021-11-02 06:24:11.970164: step 209500, loss = 0.023536, learning_rate = 0.000000 (2631.3 examples/sec)
=> 2021-11-02 06:24:31.659592: step 209600, loss = 0.064723, learning_rate = 0.000000 (2622.8 examples/sec)
=> 2021-11-02 06:24:51.349766: step 209700, loss = 0.071519, learning_rate = 0.000000 (2622.2 examples/sec)
=> 2021-11-02 06:25:11.062060: step 209800, loss = 0.109532, learning_rate = 0.000000 (2619.5 examples/sec)
=> 2021-11-02 06:25:31.698341: step 209900, loss = 0.034840, learning_rate = 0.000000 (2634.2 examples/sec)
=> 2021-11-02 06:25:51.403994: step 210000, loss = 0.048572, learning_rate = 0.000000 (2620.2 examples/sec)
=> Model saved to file: ./logs/model-210000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951638, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 06:26:22.954644: step 210100, loss = 0.036904, learning_rate = 0.000000 (2628.7 examples/sec)
=> 2021-11-02 06:26:42.597998: step 210200, loss = 0.029111, learning_rate = 0.000000 (2628.3 examples/sec)
=> 2021-11-02 06:27:02.266194: step 210300, loss = 0.105194, learning_rate = 0.000000 (2625.3 examples/sec)
=> 2021-11-02 06:27:23.017379: step 210400, loss = 0.043186, learning_rate = 0.000000 (2638.9 examples/sec)
=> 2021-11-02 06:27:42.692085: step 210500, loss = 0.052321, learning_rate = 0.000000 (2624.3 examples/sec)
=> 2021-11-02 06:28:02.378408: step 210600, loss = 0.041016, learning_rate = 0.000000 (2622.8 examples/sec)
=> 2021-11-02 06:28:22.073188: step 210700, loss = 0.055252, learning_rate = 0.000000 (2621.6 examples/sec)
=> 2021-11-02 06:28:42.781765: step 210800, loss = 0.044144, learning_rate = 0.000000 (2637.3 examples/sec)
=> 2021-11-02 06:29:02.489168: step 210900, loss = 0.076780, learning_rate = 0.000000 (2620.1 examples/sec)
=> 2021-11-02 06:29:22.206599: step 211000, loss = 0.035412, learning_rate = 0.000000 (2618.9 examples/sec)
=> Model saved to file: ./logs/model-211000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951255, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 06:29:53.582332: step 211100, loss = 0.055015, learning_rate = 0.000000 (2626.7 examples/sec)
=> 2021-11-02 06:30:14.324775: step 211200, loss = 0.071611, learning_rate = 0.000000 (2644.7 examples/sec)
=> 2021-11-02 06:30:33.977240: step 211300, loss = 0.042763, learning_rate = 0.000000 (2627.4 examples/sec)
=> 2021-11-02 06:30:53.656334: step 211400, loss = 0.042209, learning_rate = 0.000000 (2623.7 examples/sec)
=> 2021-11-02 06:31:13.345155: step 211500, loss = 0.035258, learning_rate = 0.000000 (2622.7 examples/sec)
=> 2021-11-02 06:31:33.975009: step 211600, loss = 0.063525, learning_rate = 0.000000 (2638.9 examples/sec)
=> 2021-11-02 06:31:53.662995: step 211700, loss = 0.054836, learning_rate = 0.000000 (2622.6 examples/sec)
=> 2021-11-02 06:32:13.320497: step 211800, loss = 0.042215, learning_rate = 0.000000 (2626.8 examples/sec)
=> 2021-11-02 06:32:32.976899: step 211900, loss = 0.051241, learning_rate = 0.000000 (2626.7 examples/sec)
=> 2021-11-02 06:32:53.535380: step 212000, loss = 0.051586, learning_rate = 0.000000 (2643.2 examples/sec)
=> Model saved to file: ./logs/model-212000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952556, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 06:33:25.134989: step 212100, loss = 0.043163, learning_rate = 0.000000 (2627.6 examples/sec)
=> 2021-11-02 06:33:44.781754: step 212200, loss = 0.037710, learning_rate = 0.000000 (2628.2 examples/sec)
=> 2021-11-02 06:34:04.448518: step 212300, loss = 0.048381, learning_rate = 0.000000 (2625.5 examples/sec)
=> 2021-11-02 06:34:25.163088: step 212400, loss = 0.039572, learning_rate = 0.000000 (2640.9 examples/sec)
=> 2021-11-02 06:34:44.836885: step 212500, loss = 0.029452, learning_rate = 0.000000 (2624.5 examples/sec)
=> 2021-11-02 06:35:04.522393: step 212600, loss = 0.061675, learning_rate = 0.000000 (2622.9 examples/sec)
=> 2021-11-02 06:35:24.211631: step 212700, loss = 0.019645, learning_rate = 0.000000 (2622.6 examples/sec)
=> 2021-11-02 06:35:44.812547: step 212800, loss = 0.068854, learning_rate = 0.000000 (2637.0 examples/sec)
=> 2021-11-02 06:36:04.513698: step 212900, loss = 0.072561, learning_rate = 0.000000 (2620.8 examples/sec)
=> 2021-11-02 06:36:24.228381: step 213000, loss = 0.055945, learning_rate = 0.000000 (2619.1 examples/sec)
=> Model saved to file: ./logs/model-213000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952862, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 06:36:55.666284: step 213100, loss = 0.054557, learning_rate = 0.000000 (2626.1 examples/sec)
=> 2021-11-02 06:37:15.320899: step 213200, loss = 0.046329, learning_rate = 0.000000 (2627.2 examples/sec)
=> 2021-11-02 06:37:35.921764: step 213300, loss = 0.051977, learning_rate = 0.000000 (2641.7 examples/sec)
=> 2021-11-02 06:37:55.568116: step 213400, loss = 0.053898, learning_rate = 0.000000 (2628.0 examples/sec)
=> 2021-11-02 06:38:15.221970: step 213500, loss = 0.059410, learning_rate = 0.000000 (2627.2 examples/sec)
=> 2021-11-02 06:38:34.905679: step 213600, loss = 0.039112, learning_rate = 0.000000 (2623.1 examples/sec)
=> 2021-11-02 06:38:55.475485: step 213700, loss = 0.041535, learning_rate = 0.000000 (2641.6 examples/sec)
=> 2021-11-02 06:39:15.166808: step 213800, loss = 0.030881, learning_rate = 0.000000 (2622.4 examples/sec)
=> 2021-11-02 06:39:34.894815: step 213900, loss = 0.060055, learning_rate = 0.000000 (2617.3 examples/sec)
=> 2021-11-02 06:39:54.617553: step 214000, loss = 0.043232, learning_rate = 0.000000 (2618.1 examples/sec)
=> Model saved to file: ./logs/model-214000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950184, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 06:40:27.009146: step 214100, loss = 0.049352, learning_rate = 0.000000 (2640.3 examples/sec)
=> 2021-11-02 06:40:46.647085: step 214200, loss = 0.036070, learning_rate = 0.000000 (2629.3 examples/sec)
=> 2021-11-02 06:41:06.300484: step 214300, loss = 0.054262, learning_rate = 0.000000 (2627.2 examples/sec)
=> 2021-11-02 06:41:25.980891: step 214400, loss = 0.038824, learning_rate = 0.000000 (2623.7 examples/sec)
=> 2021-11-02 06:41:46.692388: step 214500, loss = 0.087896, learning_rate = 0.000000 (2638.7 examples/sec)
=> 2021-11-02 06:42:06.469442: step 214600, loss = 0.037836, learning_rate = 0.000000 (2610.9 examples/sec)
=> 2021-11-02 06:42:26.192821: step 214700, loss = 0.043138, learning_rate = 0.000000 (2617.9 examples/sec)
=> 2021-11-02 06:42:45.908991: step 214800, loss = 0.042004, learning_rate = 0.000000 (2618.9 examples/sec)
=> 2021-11-02 06:43:06.529176: step 214900, loss = 0.037117, learning_rate = 0.000000 (2635.2 examples/sec)
=> 2021-11-02 06:43:26.250476: step 215000, loss = 0.037652, learning_rate = 0.000000 (2618.2 examples/sec)
=> Model saved to file: ./logs/model-215000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953245, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 06:43:57.581905: step 215100, loss = 0.019370, learning_rate = 0.000000 (2627.3 examples/sec)
=> 2021-11-02 06:44:17.231455: step 215200, loss = 0.034753, learning_rate = 0.000000 (2627.8 examples/sec)
=> 2021-11-02 06:44:38.049661: step 215300, loss = 0.050468, learning_rate = 0.000000 (2639.5 examples/sec)
=> 2021-11-02 06:44:57.722214: step 215400, loss = 0.055029, learning_rate = 0.000000 (2624.7 examples/sec)
=> 2021-11-02 06:45:17.417129: step 215500, loss = 0.051244, learning_rate = 0.000000 (2621.8 examples/sec)
=> 2021-11-02 06:45:37.122213: step 215600, loss = 0.038927, learning_rate = 0.000000 (2620.3 examples/sec)
=> 2021-11-02 06:45:57.794862: step 215700, loss = 0.035535, learning_rate = 0.000000 (2633.3 examples/sec)
=> 2021-11-02 06:46:17.516871: step 215800, loss = 0.053388, learning_rate = 0.000000 (2618.2 examples/sec)
=> 2021-11-02 06:46:37.246950: step 215900, loss = 0.036930, learning_rate = 0.000000 (2617.1 examples/sec)
=> 2021-11-02 06:46:56.976833: step 216000, loss = 0.063640, learning_rate = 0.000000 (2617.3 examples/sec)
=> Model saved to file: ./logs/model-216000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952938, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 06:47:28.622948: step 216100, loss = 0.055956, learning_rate = 0.000000 (2627.0 examples/sec)
=> 2021-11-02 06:47:49.306918: step 216200, loss = 0.039316, learning_rate = 0.000000 (2644.7 examples/sec)
=> 2021-11-02 06:48:08.963304: step 216300, loss = 0.064835, learning_rate = 0.000000 (2626.8 examples/sec)
=> 2021-11-02 06:48:28.642763: step 216400, loss = 0.075251, learning_rate = 0.000000 (2623.9 examples/sec)
=> 2021-11-02 06:48:48.363888: step 216500, loss = 0.062998, learning_rate = 0.000000 (2618.3 examples/sec)
=> 2021-11-02 06:49:09.005264: step 216600, loss = 0.051526, learning_rate = 0.000000 (2634.8 examples/sec)
=> 2021-11-02 06:49:28.706461: step 216700, loss = 0.047472, learning_rate = 0.000000 (2620.9 examples/sec)
=> 2021-11-02 06:49:48.419996: step 216800, loss = 0.045435, learning_rate = 0.000000 (2619.1 examples/sec)
=> 2021-11-02 06:50:08.142543: step 216900, loss = 0.042254, learning_rate = 0.000000 (2617.9 examples/sec)
=> 2021-11-02 06:50:28.835834: step 217000, loss = 0.050115, learning_rate = 0.000000 (2634.4 examples/sec)
=> Model saved to file: ./logs/model-217000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951408, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 06:51:00.364233: step 217100, loss = 0.070293, learning_rate = 0.000000 (2625.2 examples/sec)
=> 2021-11-02 06:51:20.067366: step 217200, loss = 0.083171, learning_rate = 0.000000 (2620.6 examples/sec)
=> 2021-11-02 06:51:39.741044: step 217300, loss = 0.027906, learning_rate = 0.000000 (2624.7 examples/sec)
=> 2021-11-02 06:52:00.524016: step 217400, loss = 0.081045, learning_rate = 0.000000 (2635.0 examples/sec)
=> 2021-11-02 06:52:20.247607: step 217500, loss = 0.051021, learning_rate = 0.000000 (2617.9 examples/sec)
=> 2021-11-02 06:52:39.944510: step 217600, loss = 0.022813, learning_rate = 0.000000 (2621.4 examples/sec)
=> 2021-11-02 06:52:59.657878: step 217700, loss = 0.018836, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 06:53:20.306331: step 217800, loss = 0.052523, learning_rate = 0.000000 (2633.7 examples/sec)
=> 2021-11-02 06:53:40.017035: step 217900, loss = 0.038932, learning_rate = 0.000000 (2619.5 examples/sec)
=> 2021-11-02 06:53:59.747367: step 218000, loss = 0.054231, learning_rate = 0.000000 (2616.9 examples/sec)
=> Model saved to file: ./logs/model-218000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951714, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 06:54:31.426626: step 218100, loss = 0.032886, learning_rate = 0.000000 (2626.4 examples/sec)
=> 2021-11-02 06:54:52.213666: step 218200, loss = 0.040665, learning_rate = 0.000000 (2641.2 examples/sec)
=> 2021-11-02 06:55:11.907160: step 218300, loss = 0.034615, learning_rate = 0.000000 (2622.0 examples/sec)
=> 2021-11-02 06:55:31.618104: step 218400, loss = 0.054369, learning_rate = 0.000000 (2619.8 examples/sec)
=> 2021-11-02 06:55:51.326835: step 218500, loss = 0.057950, learning_rate = 0.000000 (2619.9 examples/sec)
=> 2021-11-02 06:56:12.088370: step 218600, loss = 0.054273, learning_rate = 0.000000 (2634.2 examples/sec)
=> 2021-11-02 06:56:31.797968: step 218700, loss = 0.029023, learning_rate = 0.000000 (2620.1 examples/sec)
=> 2021-11-02 06:56:51.509073: step 218800, loss = 0.033250, learning_rate = 0.000000 (2619.5 examples/sec)
=> 2021-11-02 06:57:11.232445: step 218900, loss = 0.028394, learning_rate = 0.000000 (2618.0 examples/sec)
=> 2021-11-02 06:57:30.983853: step 219000, loss = 0.044045, learning_rate = 0.000000 (2615.0 examples/sec)
=> Model saved to file: ./logs/model-219000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951714, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 06:58:03.397146: step 219100, loss = 0.018985, learning_rate = 0.000000 (2636.2 examples/sec)
=> 2021-11-02 06:58:23.063458: step 219200, loss = 0.023975, learning_rate = 0.000000 (2625.7 examples/sec)
=> 2021-11-02 06:58:42.716995: step 219300, loss = 0.046817, learning_rate = 0.000000 (2627.2 examples/sec)
=> 2021-11-02 06:59:02.412960: step 219400, loss = 0.053079, learning_rate = 0.000000 (2621.8 examples/sec)
=> 2021-11-02 06:59:23.150964: step 219500, loss = 0.054139, learning_rate = 0.000000 (2632.6 examples/sec)
=> 2021-11-02 06:59:42.891588: step 219600, loss = 0.042820, learning_rate = 0.000000 (2615.6 examples/sec)
=> 2021-11-02 07:00:02.617909: step 219700, loss = 0.043441, learning_rate = 0.000000 (2617.5 examples/sec)
=> 2021-11-02 07:00:22.348207: step 219800, loss = 0.055287, learning_rate = 0.000000 (2617.2 examples/sec)
=> 2021-11-02 07:00:43.129090: step 219900, loss = 0.040539, learning_rate = 0.000000 (2627.5 examples/sec)
=> 2021-11-02 07:01:02.817105: step 220000, loss = 0.045687, learning_rate = 0.000000 (2622.8 examples/sec)
=> Model saved to file: ./logs/model-220000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952173, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 07:01:34.230670: step 220100, loss = 0.045111, learning_rate = 0.000000 (2633.4 examples/sec)
=> 2021-11-02 07:01:53.826109: step 220200, loss = 0.055976, learning_rate = 0.000000 (2634.9 examples/sec)
=> 2021-11-02 07:02:14.396961: step 220300, loss = 0.052632, learning_rate = 0.000000 (2642.9 examples/sec)
=> 2021-11-02 07:02:34.033331: step 220400, loss = 0.061039, learning_rate = 0.000000 (2629.6 examples/sec)
=> 2021-11-02 07:02:53.684123: step 220500, loss = 0.029608, learning_rate = 0.000000 (2627.5 examples/sec)
=> 2021-11-02 07:03:13.342718: step 220600, loss = 0.023560, learning_rate = 0.000000 (2626.6 examples/sec)
=> 2021-11-02 07:03:33.960799: step 220700, loss = 0.038798, learning_rate = 0.000000 (2636.7 examples/sec)
=> 2021-11-02 07:03:53.638864: step 220800, loss = 0.043044, learning_rate = 0.000000 (2623.8 examples/sec)
=> 2021-11-02 07:04:13.327267: step 220900, loss = 0.041935, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-02 07:04:33.018998: step 221000, loss = 0.064003, learning_rate = 0.000000 (2622.0 examples/sec)
=> Model saved to file: ./logs/model-221000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950031, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 07:05:05.400617: step 221100, loss = 0.020799, learning_rate = 0.000000 (2642.0 examples/sec)
=> 2021-11-02 07:05:25.034663: step 221200, loss = 0.027577, learning_rate = 0.000000 (2629.9 examples/sec)
=> 2021-11-02 07:05:44.691922: step 221300, loss = 0.027379, learning_rate = 0.000000 (2626.8 examples/sec)
=> 2021-11-02 07:06:04.362164: step 221400, loss = 0.073385, learning_rate = 0.000000 (2625.2 examples/sec)
=> 2021-11-02 07:06:24.954493: step 221500, loss = 0.045677, learning_rate = 0.000000 (2638.7 examples/sec)
=> 2021-11-02 07:06:44.647976: step 221600, loss = 0.038710, learning_rate = 0.000000 (2622.0 examples/sec)
=> 2021-11-02 07:07:04.337233: step 221700, loss = 0.045154, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-02 07:07:24.037414: step 221800, loss = 0.050539, learning_rate = 0.000000 (2621.0 examples/sec)
=> 2021-11-02 07:07:43.751477: step 221900, loss = 0.043261, learning_rate = 0.000000 (2619.9 examples/sec)
=> 2021-11-02 07:08:04.429631: step 222000, loss = 0.045210, learning_rate = 0.000000 (2637.1 examples/sec)
=> Model saved to file: ./logs/model-222000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951791, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 07:08:35.929053: step 222100, loss = 0.039575, learning_rate = 0.000000 (2625.4 examples/sec)
=> 2021-11-02 07:08:55.587637: step 222200, loss = 0.035641, learning_rate = 0.000000 (2626.6 examples/sec)
=> 2021-11-02 07:09:15.259044: step 222300, loss = 0.023126, learning_rate = 0.000000 (2624.8 examples/sec)
=> 2021-11-02 07:09:36.024204: step 222400, loss = 0.026471, learning_rate = 0.000000 (2646.0 examples/sec)
=> 2021-11-02 07:09:55.723084: step 222500, loss = 0.048140, learning_rate = 0.000000 (2621.0 examples/sec)
=> 2021-11-02 07:10:15.431851: step 222600, loss = 0.028969, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 07:10:35.130505: step 222700, loss = 0.020600, learning_rate = 0.000000 (2620.9 examples/sec)
=> 2021-11-02 07:10:55.770922: step 222800, loss = 0.031191, learning_rate = 0.000000 (2632.0 examples/sec)
=> 2021-11-02 07:11:15.449623: step 222900, loss = 0.019775, learning_rate = 0.000000 (2624.0 examples/sec)
=> 2021-11-02 07:11:35.092050: step 223000, loss = 0.032642, learning_rate = 0.000000 (2628.6 examples/sec)
=> Model saved to file: ./logs/model-223000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952250, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 07:12:06.504524: step 223100, loss = 0.051874, learning_rate = 0.000000 (2627.1 examples/sec)
=> 2021-11-02 07:12:27.045258: step 223200, loss = 0.033328, learning_rate = 0.000000 (2645.3 examples/sec)
=> 2021-11-02 07:12:46.698420: step 223300, loss = 0.038756, learning_rate = 0.000000 (2627.3 examples/sec)
=> 2021-11-02 07:13:06.377489: step 223400, loss = 0.037581, learning_rate = 0.000000 (2624.0 examples/sec)
=> 2021-11-02 07:13:26.054636: step 223500, loss = 0.043633, learning_rate = 0.000000 (2624.0 examples/sec)
=> 2021-11-02 07:13:46.669656: step 223600, loss = 0.055370, learning_rate = 0.000000 (2634.8 examples/sec)
=> 2021-11-02 07:14:06.391656: step 223700, loss = 0.032670, learning_rate = 0.000000 (2618.1 examples/sec)
=> 2021-11-02 07:14:26.123733: step 223800, loss = 0.022220, learning_rate = 0.000000 (2616.8 examples/sec)
=> 2021-11-02 07:14:45.863485: step 223900, loss = 0.020748, learning_rate = 0.000000 (2615.9 examples/sec)
=> 2021-11-02 07:15:06.563818: step 224000, loss = 0.026140, learning_rate = 0.000000 (2631.3 examples/sec)
=> Model saved to file: ./logs/model-224000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952326, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 07:15:37.974981: step 224100, loss = 0.049099, learning_rate = 0.000000 (2626.9 examples/sec)
=> 2021-11-02 07:15:57.608801: step 224200, loss = 0.043989, learning_rate = 0.000000 (2629.8 examples/sec)
=> 2021-11-02 07:16:17.272478: step 224300, loss = 0.043052, learning_rate = 0.000000 (2625.9 examples/sec)
=> 2021-11-02 07:16:38.035266: step 224400, loss = 0.036949, learning_rate = 0.000000 (2639.3 examples/sec)
=> 2021-11-02 07:16:57.722716: step 224500, loss = 0.048687, learning_rate = 0.000000 (2623.0 examples/sec)
=> 2021-11-02 07:17:17.395413: step 224600, loss = 0.033344, learning_rate = 0.000000 (2624.6 examples/sec)
=> 2021-11-02 07:17:37.093353: step 224700, loss = 0.045893, learning_rate = 0.000000 (2621.3 examples/sec)
=> 2021-11-02 07:17:56.787638: step 224800, loss = 0.081773, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-02 07:18:17.590483: step 224900, loss = 0.055190, learning_rate = 0.000000 (2635.6 examples/sec)
=> 2021-11-02 07:18:37.302814: step 225000, loss = 0.026064, learning_rate = 0.000000 (2619.4 examples/sec)
=> Model saved to file: ./logs/model-225000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951178, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 07:19:08.622548: step 225100, loss = 0.066676, learning_rate = 0.000000 (2628.2 examples/sec)
=> 2021-11-02 07:19:28.274970: step 225200, loss = 0.052190, learning_rate = 0.000000 (2627.6 examples/sec)
=> 2021-11-02 07:19:48.859084: step 225300, loss = 0.028503, learning_rate = 0.000000 (2656.9 examples/sec)
=> 2021-11-02 07:20:08.554119: step 225400, loss = 0.036311, learning_rate = 0.000000 (2621.7 examples/sec)
=> 2021-11-02 07:20:28.265043: step 225500, loss = 0.058927, learning_rate = 0.000000 (2619.8 examples/sec)
=> 2021-11-02 07:20:47.961248: step 225600, loss = 0.024476, learning_rate = 0.000000 (2621.4 examples/sec)
=> 2021-11-02 07:21:08.630048: step 225700, loss = 0.049348, learning_rate = 0.000000 (2630.3 examples/sec)
=> 2021-11-02 07:21:28.317124: step 225800, loss = 0.028431, learning_rate = 0.000000 (2623.0 examples/sec)
=> 2021-11-02 07:21:47.996269: step 225900, loss = 0.049792, learning_rate = 0.000000 (2623.7 examples/sec)
=> 2021-11-02 07:22:07.677143: step 226000, loss = 0.059166, learning_rate = 0.000000 (2623.8 examples/sec)
=> Model saved to file: ./logs/model-226000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952020, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 07:22:40.065498: step 226100, loss = 0.027840, learning_rate = 0.000000 (2642.3 examples/sec)
=> 2021-11-02 07:22:59.679994: step 226200, loss = 0.028068, learning_rate = 0.000000 (2632.5 examples/sec)
=> 2021-11-02 07:23:19.304105: step 226300, loss = 0.033203, learning_rate = 0.000000 (2631.3 examples/sec)
=> 2021-11-02 07:23:38.947417: step 226400, loss = 0.048212, learning_rate = 0.000000 (2628.5 examples/sec)
=> 2021-11-02 07:23:59.497721: step 226500, loss = 0.051685, learning_rate = 0.000000 (2644.2 examples/sec)
=> 2021-11-02 07:24:19.186370: step 226600, loss = 0.041752, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-02 07:24:38.900110: step 226700, loss = 0.038959, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 07:24:58.603014: step 226800, loss = 0.042709, learning_rate = 0.000000 (2620.7 examples/sec)
=> 2021-11-02 07:25:19.327236: step 226900, loss = 0.046651, learning_rate = 0.000000 (2632.1 examples/sec)
=> 2021-11-02 07:25:39.041932: step 227000, loss = 0.018200, learning_rate = 0.000000 (2618.9 examples/sec)
=> Model saved to file: ./logs/model-227000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951025, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 07:26:10.536214: step 227100, loss = 0.046123, learning_rate = 0.000000 (2626.8 examples/sec)
=> 2021-11-02 07:26:30.200516: step 227200, loss = 0.043731, learning_rate = 0.000000 (2625.8 examples/sec)
=> 2021-11-02 07:26:51.065766: step 227300, loss = 0.059181, learning_rate = 0.000000 (2631.8 examples/sec)
=> 2021-11-02 07:27:10.763034: step 227400, loss = 0.056116, learning_rate = 0.000000 (2621.5 examples/sec)
=> 2021-11-02 07:27:30.436765: step 227500, loss = 0.052105, learning_rate = 0.000000 (2624.5 examples/sec)
=> 2021-11-02 07:27:50.135521: step 227600, loss = 0.025604, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-02 07:28:09.839881: step 227700, loss = 0.052175, learning_rate = 0.000000 (2621.0 examples/sec)
=> 2021-11-02 07:28:30.785752: step 227800, loss = 0.034902, learning_rate = 0.000000 (2614.7 examples/sec)
=> 2021-11-02 07:28:50.493334: step 227900, loss = 0.027030, learning_rate = 0.000000 (2620.2 examples/sec)
=> 2021-11-02 07:29:10.224005: step 228000, loss = 0.051561, learning_rate = 0.000000 (2617.1 examples/sec)
=> Model saved to file: ./logs/model-228000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951255, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 07:29:41.496643: step 228100, loss = 0.032894, learning_rate = 0.000000 (2625.2 examples/sec)
=> 2021-11-02 07:30:02.310827: step 228200, loss = 0.039432, learning_rate = 0.000000 (2640.9 examples/sec)
=> 2021-11-02 07:30:22.011676: step 228300, loss = 0.049582, learning_rate = 0.000000 (2621.1 examples/sec)
=> 2021-11-02 07:30:41.718933: step 228400, loss = 0.029475, learning_rate = 0.000000 (2620.1 examples/sec)
=> 2021-11-02 07:31:01.438616: step 228500, loss = 0.042757, learning_rate = 0.000000 (2618.5 examples/sec)
=> 2021-11-02 07:31:22.127530: step 228600, loss = 0.050611, learning_rate = 0.000000 (2628.6 examples/sec)
=> 2021-11-02 07:31:41.847795: step 228700, loss = 0.023691, learning_rate = 0.000000 (2618.3 examples/sec)
=> 2021-11-02 07:32:01.575662: step 228800, loss = 0.074429, learning_rate = 0.000000 (2617.8 examples/sec)
=> 2021-11-02 07:32:21.300131: step 228900, loss = 0.040179, learning_rate = 0.000000 (2617.8 examples/sec)
=> 2021-11-02 07:32:41.959333: step 229000, loss = 0.025491, learning_rate = 0.000000 (2630.9 examples/sec)
=> Model saved to file: ./logs/model-229000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953321, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 07:33:13.400330: step 229100, loss = 0.027351, learning_rate = 0.000000 (2625.9 examples/sec)
=> 2021-11-02 07:33:33.060837: step 229200, loss = 0.058439, learning_rate = 0.000000 (2626.2 examples/sec)
=> 2021-11-02 07:33:52.763435: step 229300, loss = 0.032900, learning_rate = 0.000000 (2620.6 examples/sec)
=> 2021-11-02 07:34:13.483731: step 229400, loss = 0.036275, learning_rate = 0.000000 (2636.4 examples/sec)
=> 2021-11-02 07:34:33.188929: step 229500, loss = 0.081407, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-02 07:34:52.903269: step 229600, loss = 0.031382, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 07:35:12.622587: step 229700, loss = 0.062220, learning_rate = 0.000000 (2618.4 examples/sec)
=> 2021-11-02 07:35:33.249542: step 229800, loss = 0.055791, learning_rate = 0.000000 (2635.7 examples/sec)
=> 2021-11-02 07:35:52.979709: step 229900, loss = 0.031788, learning_rate = 0.000000 (2616.8 examples/sec)
=> 2021-11-02 07:36:12.714209: step 230000, loss = 0.045709, learning_rate = 0.000000 (2617.0 examples/sec)
=> Model saved to file: ./logs/model-230000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953015, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 07:36:44.119807: step 230100, loss = 0.038553, learning_rate = 0.000000 (2626.4 examples/sec)
=> 2021-11-02 07:37:04.782699: step 230200, loss = 0.038520, learning_rate = 0.000000 (2639.0 examples/sec)
=> 2021-11-02 07:37:24.485945: step 230300, loss = 0.039763, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-02 07:37:44.189731: step 230400, loss = 0.049366, learning_rate = 0.000000 (2620.5 examples/sec)
=> 2021-11-02 07:38:04.009870: step 230500, loss = 0.072325, learning_rate = 0.000000 (2604.8 examples/sec)
=> 2021-11-02 07:38:24.633562: step 230600, loss = 0.051924, learning_rate = 0.000000 (2636.4 examples/sec)
=> 2021-11-02 07:38:44.357473: step 230700, loss = 0.074100, learning_rate = 0.000000 (2618.1 examples/sec)
=> 2021-11-02 07:39:04.070798: step 230800, loss = 0.049065, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 07:39:23.816919: step 230900, loss = 0.054602, learning_rate = 0.000000 (2614.9 examples/sec)
=> 2021-11-02 07:39:43.546361: step 231000, loss = 0.046156, learning_rate = 0.000000 (2617.1 examples/sec)
=> Model saved to file: ./logs/model-231000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949495, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 07:40:16.015948: step 231100, loss = 0.041185, learning_rate = 0.000000 (2639.9 examples/sec)
=> 2021-11-02 07:40:35.647091: step 231200, loss = 0.032249, learning_rate = 0.000000 (2630.4 examples/sec)
=> 2021-11-02 07:40:55.299704: step 231300, loss = 0.034223, learning_rate = 0.000000 (2627.3 examples/sec)
=> 2021-11-02 07:41:14.990348: step 231400, loss = 0.027368, learning_rate = 0.000000 (2622.4 examples/sec)
=> 2021-11-02 07:41:35.600572: step 231500, loss = 0.044923, learning_rate = 0.000000 (2638.0 examples/sec)
=> 2021-11-02 07:41:55.292725: step 231600, loss = 0.054236, learning_rate = 0.000000 (2622.4 examples/sec)
=> 2021-11-02 07:42:15.015820: step 231700, loss = 0.038887, learning_rate = 0.000000 (2618.2 examples/sec)
=> 2021-11-02 07:42:34.737148: step 231800, loss = 0.071150, learning_rate = 0.000000 (2618.4 examples/sec)
=> 2021-11-02 07:42:55.360615: step 231900, loss = 0.015501, learning_rate = 0.000000 (2635.7 examples/sec)
=> 2021-11-02 07:43:15.079387: step 232000, loss = 0.040666, learning_rate = 0.000000 (2618.7 examples/sec)
=> Model saved to file: ./logs/model-232000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950643, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 07:43:46.649252: step 232100, loss = 0.048286, learning_rate = 0.000000 (2627.4 examples/sec)
=> 2021-11-02 07:44:06.290901: step 232200, loss = 0.027576, learning_rate = 0.000000 (2628.6 examples/sec)
=> 2021-11-02 07:44:26.982648: step 232300, loss = 0.061805, learning_rate = 0.000000 (2635.8 examples/sec)
=> 2021-11-02 07:44:46.640786: step 232400, loss = 0.040379, learning_rate = 0.000000 (2626.6 examples/sec)
=> 2021-11-02 07:45:06.303808: step 232500, loss = 0.045961, learning_rate = 0.000000 (2625.9 examples/sec)
=> 2021-11-02 07:45:25.982156: step 232600, loss = 0.027382, learning_rate = 0.000000 (2624.0 examples/sec)
=> 2021-11-02 07:45:46.609301: step 232700, loss = 0.027476, learning_rate = 0.000000 (2635.7 examples/sec)
=> 2021-11-02 07:46:06.316970: step 232800, loss = 0.058753, learning_rate = 0.000000 (2620.1 examples/sec)
=> 2021-11-02 07:46:26.017472: step 232900, loss = 0.042757, learning_rate = 0.000000 (2620.9 examples/sec)
=> 2021-11-02 07:46:45.707199: step 233000, loss = 0.033021, learning_rate = 0.000000 (2622.5 examples/sec)
=> Model saved to file: ./logs/model-233000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952479, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 07:47:18.180746: step 233100, loss = 0.050955, learning_rate = 0.000000 (2643.7 examples/sec)
=> 2021-11-02 07:47:37.834939: step 233200, loss = 0.028291, learning_rate = 0.000000 (2627.1 examples/sec)
=> 2021-11-02 07:47:57.503999: step 233300, loss = 0.029204, learning_rate = 0.000000 (2625.1 examples/sec)
=> 2021-11-02 07:48:17.181260: step 233400, loss = 0.052562, learning_rate = 0.000000 (2624.1 examples/sec)
=> 2021-11-02 07:48:37.809556: step 233500, loss = 0.077752, learning_rate = 0.000000 (2638.1 examples/sec)
=> 2021-11-02 07:48:57.491723: step 233600, loss = 0.053102, learning_rate = 0.000000 (2623.5 examples/sec)
=> 2021-11-02 07:49:17.154688: step 233700, loss = 0.054010, learning_rate = 0.000000 (2626.0 examples/sec)
=> 2021-11-02 07:49:36.821671: step 233800, loss = 0.040652, learning_rate = 0.000000 (2625.5 examples/sec)
=> 2021-11-02 07:49:56.504456: step 233900, loss = 0.044178, learning_rate = 0.000000 (2623.3 examples/sec)
=> 2021-11-02 07:50:17.123439: step 234000, loss = 0.023798, learning_rate = 0.000000 (2635.3 examples/sec)
=> Model saved to file: ./logs/model-234000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952479, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 07:50:48.729006: step 234100, loss = 0.022480, learning_rate = 0.000000 (2616.8 examples/sec)
=> 2021-11-02 07:51:08.373231: step 234200, loss = 0.039047, learning_rate = 0.000000 (2628.4 examples/sec)
=> 2021-11-02 07:51:28.025515: step 234300, loss = 0.032358, learning_rate = 0.000000 (2627.4 examples/sec)
=> 2021-11-02 07:51:48.627982: step 234400, loss = 0.017971, learning_rate = 0.000000 (2640.4 examples/sec)
=> 2021-11-02 07:52:08.319413: step 234500, loss = 0.059697, learning_rate = 0.000000 (2622.1 examples/sec)
=> 2021-11-02 07:52:28.017675: step 234600, loss = 0.029096, learning_rate = 0.000000 (2621.3 examples/sec)
=> 2021-11-02 07:52:47.744715: step 234700, loss = 0.034688, learning_rate = 0.000000 (2617.4 examples/sec)
=> 2021-11-02 07:53:08.446388: step 234800, loss = 0.037572, learning_rate = 0.000000 (2646.5 examples/sec)
=> 2021-11-02 07:53:28.141550: step 234900, loss = 0.040460, learning_rate = 0.000000 (2621.6 examples/sec)
=> 2021-11-02 07:53:47.892091: step 235000, loss = 0.056025, learning_rate = 0.000000 (2614.2 examples/sec)
=> Model saved to file: ./logs/model-235000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951255, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 07:54:19.339461: step 235100, loss = 0.041457, learning_rate = 0.000000 (2622.9 examples/sec)
=> 2021-11-02 07:54:39.911565: step 235200, loss = 0.046869, learning_rate = 0.000000 (2641.8 examples/sec)
=> 2021-11-02 07:54:59.575977: step 235300, loss = 0.042897, learning_rate = 0.000000 (2625.8 examples/sec)
=> 2021-11-02 07:55:19.213646: step 235400, loss = 0.017983, learning_rate = 0.000000 (2629.4 examples/sec)
=> 2021-11-02 07:55:38.876093: step 235500, loss = 0.030970, learning_rate = 0.000000 (2626.1 examples/sec)
=> 2021-11-02 07:55:59.471568: step 235600, loss = 0.039691, learning_rate = 0.000000 (2638.5 examples/sec)
=> 2021-11-02 07:56:19.177110: step 235700, loss = 0.021297, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-02 07:56:38.867500: step 235800, loss = 0.040691, learning_rate = 0.000000 (2622.3 examples/sec)
=> 2021-11-02 07:56:58.579021: step 235900, loss = 0.046135, learning_rate = 0.000000 (2619.4 examples/sec)
=> 2021-11-02 07:57:19.227557: step 236000, loss = 0.021544, learning_rate = 0.000000 (2632.4 examples/sec)
=> Model saved to file: ./logs/model-236000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949648, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 07:57:50.695740: step 236100, loss = 0.048389, learning_rate = 0.000000 (2626.0 examples/sec)
=> 2021-11-02 07:58:10.326867: step 236200, loss = 0.034354, learning_rate = 0.000000 (2630.4 examples/sec)
=> 2021-11-02 07:58:29.964764: step 236300, loss = 0.059288, learning_rate = 0.000000 (2629.4 examples/sec)
=> 2021-11-02 07:58:50.790413: step 236400, loss = 0.035338, learning_rate = 0.000000 (2642.0 examples/sec)
=> 2021-11-02 07:59:10.533144: step 236500, loss = 0.065706, learning_rate = 0.000000 (2615.3 examples/sec)
=> 2021-11-02 07:59:30.168901: step 236600, loss = 0.055827, learning_rate = 0.000000 (2629.6 examples/sec)
=> 2021-11-02 07:59:49.819198: step 236700, loss = 0.028007, learning_rate = 0.000000 (2627.6 examples/sec)
=> 2021-11-02 08:00:09.490705: step 236800, loss = 0.038193, learning_rate = 0.000000 (2625.5 examples/sec)
=> 2021-11-02 08:00:30.082015: step 236900, loss = 0.036123, learning_rate = 0.000000 (2638.4 examples/sec)
=> 2021-11-02 08:00:49.733032: step 237000, loss = 0.045960, learning_rate = 0.000000 (2627.5 examples/sec)
=> Model saved to file: ./logs/model-237000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951867, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 08:01:21.285610: step 237100, loss = 0.031908, learning_rate = 0.000000 (2626.9 examples/sec)
=> 2021-11-02 08:01:40.905208: step 237200, loss = 0.027196, learning_rate = 0.000000 (2631.7 examples/sec)
=> 2021-11-02 08:02:01.455548: step 237300, loss = 0.035363, learning_rate = 0.000000 (2645.8 examples/sec)
=> 2021-11-02 08:02:21.194616: step 237400, loss = 0.081442, learning_rate = 0.000000 (2615.9 examples/sec)
=> 2021-11-02 08:02:40.848948: step 237500, loss = 0.045984, learning_rate = 0.000000 (2627.1 examples/sec)
=> 2021-11-02 08:03:00.523956: step 237600, loss = 0.040734, learning_rate = 0.000000 (2624.4 examples/sec)
=> 2021-11-02 08:03:21.123155: step 237700, loss = 0.043287, learning_rate = 0.000000 (2639.0 examples/sec)
=> 2021-11-02 08:03:40.814123: step 237800, loss = 0.039242, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-02 08:04:00.516386: step 237900, loss = 0.035156, learning_rate = 0.000000 (2620.9 examples/sec)
=> 2021-11-02 08:04:20.292631: step 238000, loss = 0.019664, learning_rate = 0.000000 (2611.1 examples/sec)
=> Model saved to file: ./logs/model-238000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951178, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 08:04:52.806124: step 238100, loss = 0.035679, learning_rate = 0.000000 (2640.1 examples/sec)
=> 2021-11-02 08:05:12.420449: step 238200, loss = 0.035653, learning_rate = 0.000000 (2632.5 examples/sec)
=> 2021-11-02 08:05:32.035056: step 238300, loss = 0.051140, learning_rate = 0.000000 (2632.4 examples/sec)
=> 2021-11-02 08:05:51.675175: step 238400, loss = 0.030394, learning_rate = 0.000000 (2629.0 examples/sec)
=> 2021-11-02 08:06:12.423173: step 238500, loss = 0.027308, learning_rate = 0.000000 (2643.7 examples/sec)
=> 2021-11-02 08:06:32.078807: step 238600, loss = 0.055466, learning_rate = 0.000000 (2627.0 examples/sec)
=> 2021-11-02 08:06:51.716030: step 238700, loss = 0.050966, learning_rate = 0.000000 (2629.3 examples/sec)
=> 2021-11-02 08:07:11.368876: step 238800, loss = 0.031122, learning_rate = 0.000000 (2627.3 examples/sec)
=> 2021-11-02 08:07:32.039070: step 238900, loss = 0.035721, learning_rate = 0.000000 (2641.2 examples/sec)
=> 2021-11-02 08:07:51.717639: step 239000, loss = 0.027252, learning_rate = 0.000000 (2623.9 examples/sec)
=> Model saved to file: ./logs/model-239000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951561, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 08:08:23.230021: step 239100, loss = 0.071987, learning_rate = 0.000000 (2626.2 examples/sec)
=> 2021-11-02 08:08:42.937731: step 239200, loss = 0.033817, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 08:09:03.508329: step 239300, loss = 0.035637, learning_rate = 0.000000 (2644.7 examples/sec)
=> 2021-11-02 08:09:23.196579: step 239400, loss = 0.045194, learning_rate = 0.000000 (2622.6 examples/sec)
=> 2021-11-02 08:09:42.877408: step 239500, loss = 0.030166, learning_rate = 0.000000 (2623.6 examples/sec)
=> 2021-11-02 08:10:02.590058: step 239600, loss = 0.026345, learning_rate = 0.000000 (2619.4 examples/sec)
=> 2021-11-02 08:10:22.313781: step 239700, loss = 0.065777, learning_rate = 0.000000 (2618.7 examples/sec)
=> 2021-11-02 08:10:42.939088: step 239800, loss = 0.024471, learning_rate = 0.000000 (2638.3 examples/sec)
=> 2021-11-02 08:11:02.643082: step 239900, loss = 0.023304, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-02 08:11:22.376397: step 240000, loss = 0.031841, learning_rate = 0.000000 (2616.7 examples/sec)
=> Model saved to file: ./logs/model-240000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952020, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 08:11:53.847981: step 240100, loss = 0.025081, learning_rate = 0.000000 (2623.3 examples/sec)
=> 2021-11-02 08:12:14.402779: step 240200, loss = 0.052337, learning_rate = 0.000000 (2643.6 examples/sec)
=> 2021-11-02 08:12:34.036305: step 240300, loss = 0.052423, learning_rate = 0.000000 (2630.0 examples/sec)
=> 2021-11-02 08:12:53.693478: step 240400, loss = 0.044343, learning_rate = 0.000000 (2626.7 examples/sec)
=> 2021-11-02 08:13:13.391705: step 240500, loss = 0.064815, learning_rate = 0.000000 (2621.5 examples/sec)
=> 2021-11-02 08:13:34.004922: step 240600, loss = 0.036565, learning_rate = 0.000000 (2635.8 examples/sec)
=> 2021-11-02 08:13:53.723545: step 240700, loss = 0.029617, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 08:14:13.474745: step 240800, loss = 0.026927, learning_rate = 0.000000 (2614.2 examples/sec)
=> 2021-11-02 08:14:33.227862: step 240900, loss = 0.037272, learning_rate = 0.000000 (2613.9 examples/sec)
=> 2021-11-02 08:14:53.888590: step 241000, loss = 0.059617, learning_rate = 0.000000 (2629.9 examples/sec)
=> Model saved to file: ./logs/model-241000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948730, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 08:15:25.310655: step 241100, loss = 0.019498, learning_rate = 0.000000 (2618.5 examples/sec)
=> 2021-11-02 08:15:44.984175: step 241200, loss = 0.058948, learning_rate = 0.000000 (2624.7 examples/sec)
=> 2021-11-02 08:16:04.684892: step 241300, loss = 0.075926, learning_rate = 0.000000 (2620.9 examples/sec)
=> 2021-11-02 08:16:25.306798: step 241400, loss = 0.030681, learning_rate = 0.000000 (2635.8 examples/sec)
=> 2021-11-02 08:16:45.021071: step 241500, loss = 0.044317, learning_rate = 0.000000 (2619.1 examples/sec)
=> 2021-11-02 08:17:04.752549: step 241600, loss = 0.024326, learning_rate = 0.000000 (2616.9 examples/sec)
=> 2021-11-02 08:17:24.590623: step 241700, loss = 0.094370, learning_rate = 0.000000 (2602.6 examples/sec)
=> 2021-11-02 08:17:45.461302: step 241800, loss = 0.036465, learning_rate = 0.000000 (2630.8 examples/sec)
=> 2021-11-02 08:18:05.215189: step 241900, loss = 0.024960, learning_rate = 0.000000 (2614.0 examples/sec)
=> 2021-11-02 08:18:24.992683: step 242000, loss = 0.022016, learning_rate = 0.000000 (2610.9 examples/sec)
=> Model saved to file: ./logs/model-242000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949189, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 08:18:56.684222: step 242100, loss = 0.045014, learning_rate = 0.000000 (2622.3 examples/sec)
=> 2021-11-02 08:19:17.392955: step 242200, loss = 0.036855, learning_rate = 0.000000 (2640.2 examples/sec)
=> 2021-11-02 08:19:37.047659: step 242300, loss = 0.022536, learning_rate = 0.000000 (2627.7 examples/sec)
=> 2021-11-02 08:19:56.721522: step 242400, loss = 0.041939, learning_rate = 0.000000 (2624.3 examples/sec)
=> 2021-11-02 08:20:16.409078: step 242500, loss = 0.034185, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-02 08:20:36.213916: step 242600, loss = 0.063547, learning_rate = 0.000000 (2607.9 examples/sec)
=> 2021-11-02 08:20:56.847128: step 242700, loss = 0.015454, learning_rate = 0.000000 (2633.1 examples/sec)
=> 2021-11-02 08:21:16.582554: step 242800, loss = 0.030036, learning_rate = 0.000000 (2616.5 examples/sec)
=> 2021-11-02 08:21:36.327934: step 242900, loss = 0.032300, learning_rate = 0.000000 (2614.9 examples/sec)
=> 2021-11-02 08:21:56.079469: step 243000, loss = 0.033212, learning_rate = 0.000000 (2614.1 examples/sec)
=> Model saved to file: ./logs/model-243000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951561, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 08:22:28.546448: step 243100, loss = 0.029333, learning_rate = 0.000000 (2636.9 examples/sec)
=> 2021-11-02 08:22:48.219657: step 243200, loss = 0.036593, learning_rate = 0.000000 (2625.0 examples/sec)
=> 2021-11-02 08:23:07.922037: step 243300, loss = 0.032805, learning_rate = 0.000000 (2620.8 examples/sec)
=> 2021-11-02 08:23:27.631957: step 243400, loss = 0.035453, learning_rate = 0.000000 (2619.6 examples/sec)
=> 2021-11-02 08:23:48.258209: step 243500, loss = 0.042512, learning_rate = 0.000000 (2632.6 examples/sec)
=> 2021-11-02 08:24:08.002453: step 243600, loss = 0.037662, learning_rate = 0.000000 (2615.5 examples/sec)
=> 2021-11-02 08:24:27.752485: step 243700, loss = 0.034154, learning_rate = 0.000000 (2614.6 examples/sec)
=> 2021-11-02 08:24:47.491112: step 243800, loss = 0.031714, learning_rate = 0.000000 (2615.9 examples/sec)
=> 2021-11-02 08:25:08.287920: step 243900, loss = 0.052260, learning_rate = 0.000000 (2629.1 examples/sec)
=> 2021-11-02 08:25:28.078757: step 244000, loss = 0.042096, learning_rate = 0.000000 (2608.9 examples/sec)
=> Model saved to file: ./logs/model-244000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950184, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 08:25:59.601142: step 244100, loss = 0.065655, learning_rate = 0.000000 (2622.7 examples/sec)
=> 2021-11-02 08:26:19.260393: step 244200, loss = 0.038972, learning_rate = 0.000000 (2626.7 examples/sec)
=> 2021-11-02 08:26:39.801887: step 244300, loss = 0.039993, learning_rate = 0.000000 (2644.9 examples/sec)
=> 2021-11-02 08:26:59.477881: step 244400, loss = 0.043291, learning_rate = 0.000000 (2624.0 examples/sec)
=> 2021-11-02 08:27:19.197455: step 244500, loss = 0.024746, learning_rate = 0.000000 (2618.3 examples/sec)
=> 2021-11-02 08:27:38.936994: step 244600, loss = 0.028772, learning_rate = 0.000000 (2615.6 examples/sec)
=> 2021-11-02 08:27:59.609188: step 244700, loss = 0.023930, learning_rate = 0.000000 (2629.1 examples/sec)
=> 2021-11-02 08:28:19.415041: step 244800, loss = 0.039098, learning_rate = 0.000000 (2606.9 examples/sec)
=> 2021-11-02 08:28:39.141512: step 244900, loss = 0.048090, learning_rate = 0.000000 (2617.5 examples/sec)
=> 2021-11-02 08:28:58.859295: step 245000, loss = 0.030533, learning_rate = 0.000000 (2618.4 examples/sec)
=> Model saved to file: ./logs/model-245000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952403, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 08:29:31.269784: step 245100, loss = 0.044589, learning_rate = 0.000000 (2638.3 examples/sec)
=> 2021-11-02 08:29:50.904326: step 245200, loss = 0.022051, learning_rate = 0.000000 (2629.9 examples/sec)
=> 2021-11-02 08:30:10.564338: step 245300, loss = 0.041141, learning_rate = 0.000000 (2626.7 examples/sec)
=> 2021-11-02 08:30:30.244179: step 245400, loss = 0.052213, learning_rate = 0.000000 (2623.8 examples/sec)
=> 2021-11-02 08:30:49.949953: step 245500, loss = 0.047689, learning_rate = 0.000000 (2620.5 examples/sec)
=> 2021-11-02 08:31:10.546764: step 245600, loss = 0.043342, learning_rate = 0.000000 (2635.8 examples/sec)
=> 2021-11-02 08:31:30.266807: step 245700, loss = 0.033353, learning_rate = 0.000000 (2618.3 examples/sec)
=> 2021-11-02 08:31:50.003792: step 245800, loss = 0.044849, learning_rate = 0.000000 (2616.2 examples/sec)
=> 2021-11-02 08:32:09.742283: step 245900, loss = 0.073007, learning_rate = 0.000000 (2616.1 examples/sec)
=> 2021-11-02 08:32:30.397101: step 246000, loss = 0.025978, learning_rate = 0.000000 (2638.5 examples/sec)
=> Model saved to file: ./logs/model-246000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951485, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 08:33:02.085967: step 246100, loss = 0.029164, learning_rate = 0.000000 (2624.5 examples/sec)
=> 2021-11-02 08:33:21.758316: step 246200, loss = 0.051267, learning_rate = 0.000000 (2624.7 examples/sec)
=> 2021-11-02 08:33:41.474014: step 246300, loss = 0.020019, learning_rate = 0.000000 (2619.0 examples/sec)
=> 2021-11-02 08:34:02.119117: step 246400, loss = 0.031757, learning_rate = 0.000000 (2631.5 examples/sec)
=> 2021-11-02 08:34:21.867539: step 246500, loss = 0.028430, learning_rate = 0.000000 (2614.6 examples/sec)
=> 2021-11-02 08:34:41.600346: step 246600, loss = 0.035055, learning_rate = 0.000000 (2616.6 examples/sec)
=> 2021-11-02 08:35:01.391572: step 246700, loss = 0.040975, learning_rate = 0.000000 (2608.9 examples/sec)
=> 2021-11-02 08:35:22.130195: step 246800, loss = 0.026139, learning_rate = 0.000000 (2630.7 examples/sec)
=> 2021-11-02 08:35:41.852303: step 246900, loss = 0.048093, learning_rate = 0.000000 (2618.0 examples/sec)
=> 2021-11-02 08:36:01.588317: step 247000, loss = 0.023177, learning_rate = 0.000000 (2616.1 examples/sec)
=> Model saved to file: ./logs/model-247000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952709, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 08:36:33.144291: step 247100, loss = 0.018365, learning_rate = 0.000000 (2624.0 examples/sec)
=> 2021-11-02 08:36:53.883970: step 247200, loss = 0.042838, learning_rate = 0.000000 (2639.6 examples/sec)
=> 2021-11-02 08:37:13.544776: step 247300, loss = 0.058203, learning_rate = 0.000000 (2626.3 examples/sec)
=> 2021-11-02 08:37:33.247919: step 247400, loss = 0.053023, learning_rate = 0.000000 (2620.5 examples/sec)
=> 2021-11-02 08:37:52.969047: step 247500, loss = 0.029993, learning_rate = 0.000000 (2618.2 examples/sec)
=> 2021-11-02 08:38:13.744559: step 247600, loss = 0.025049, learning_rate = 0.000000 (2628.2 examples/sec)
=> 2021-11-02 08:38:33.483732: step 247700, loss = 0.036907, learning_rate = 0.000000 (2615.9 examples/sec)
=> 2021-11-02 08:38:53.224257: step 247800, loss = 0.045486, learning_rate = 0.000000 (2615.8 examples/sec)
=> 2021-11-02 08:39:12.994122: step 247900, loss = 0.025668, learning_rate = 0.000000 (2611.7 examples/sec)
=> 2021-11-02 08:39:33.673830: step 248000, loss = 0.033564, learning_rate = 0.000000 (2626.5 examples/sec)
=> Model saved to file: ./logs/model-248000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953092, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 08:40:05.025976: step 248100, loss = 0.057261, learning_rate = 0.000000 (2624.5 examples/sec)
=> 2021-11-02 08:40:24.665808: step 248200, loss = 0.039366, learning_rate = 0.000000 (2629.0 examples/sec)
=> 2021-11-02 08:40:44.322623: step 248300, loss = 0.057063, learning_rate = 0.000000 (2626.8 examples/sec)
=> 2021-11-02 08:41:03.992678: step 248400, loss = 0.037042, learning_rate = 0.000000 (2625.2 examples/sec)
=> 2021-11-02 08:41:24.895289: step 248500, loss = 0.019375, learning_rate = 0.000000 (2615.7 examples/sec)
=> 2021-11-02 08:41:44.629286: step 248600, loss = 0.024302, learning_rate = 0.000000 (2616.3 examples/sec)
=> 2021-11-02 08:42:04.378336: step 248700, loss = 0.024116, learning_rate = 0.000000 (2614.4 examples/sec)
=> 2021-11-02 08:42:24.124999: step 248800, loss = 0.028725, learning_rate = 0.000000 (2614.9 examples/sec)
=> 2021-11-02 08:42:44.793574: step 248900, loss = 0.048133, learning_rate = 0.000000 (2628.7 examples/sec)
=> 2021-11-02 08:43:04.525904: step 249000, loss = 0.016502, learning_rate = 0.000000 (2616.6 examples/sec)
=> Model saved to file: ./logs/model-249000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948194, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 08:43:35.966162: step 249100, loss = 0.035605, learning_rate = 0.000000 (2626.5 examples/sec)
=> 2021-11-02 08:43:55.728550: step 249200, loss = 0.024247, learning_rate = 0.000000 (2612.5 examples/sec)
=> 2021-11-02 08:44:16.348509: step 249300, loss = 0.064288, learning_rate = 0.000000 (2636.6 examples/sec)
=> 2021-11-02 08:44:36.034467: step 249400, loss = 0.046971, learning_rate = 0.000000 (2622.7 examples/sec)
=> 2021-11-02 08:44:55.762042: step 249500, loss = 0.022331, learning_rate = 0.000000 (2617.3 examples/sec)
=> 2021-11-02 08:45:15.488123: step 249600, loss = 0.031394, learning_rate = 0.000000 (2617.5 examples/sec)
=> 2021-11-02 08:45:36.248167: step 249700, loss = 0.028469, learning_rate = 0.000000 (2630.0 examples/sec)
=> 2021-11-02 08:45:55.952634: step 249800, loss = 0.086658, learning_rate = 0.000000 (2620.5 examples/sec)
=> 2021-11-02 08:46:15.654224: step 249900, loss = 0.026784, learning_rate = 0.000000 (2620.9 examples/sec)
=> 2021-11-02 08:46:35.373465: step 250000, loss = 0.038866, learning_rate = 0.000000 (2618.4 examples/sec)
=> Model saved to file: ./logs/model-250000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952556, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 08:47:07.930563: step 250100, loss = 0.022140, learning_rate = 0.000000 (2636.7 examples/sec)
=> 2021-11-02 08:47:27.548497: step 250200, loss = 0.041614, learning_rate = 0.000000 (2632.1 examples/sec)
=> 2021-11-02 08:47:47.158770: step 250300, loss = 0.036237, learning_rate = 0.000000 (2633.2 examples/sec)
=> 2021-11-02 08:48:06.790856: step 250400, loss = 0.051926, learning_rate = 0.000000 (2630.3 examples/sec)
=> 2021-11-02 08:48:27.326963: step 250500, loss = 0.042715, learning_rate = 0.000000 (2647.4 examples/sec)
=> 2021-11-02 08:48:46.981458: step 250600, loss = 0.041206, learning_rate = 0.000000 (2627.0 examples/sec)
=> 2021-11-02 08:49:06.678120: step 250700, loss = 0.041007, learning_rate = 0.000000 (2621.5 examples/sec)
=> 2021-11-02 08:49:26.403155: step 250800, loss = 0.047862, learning_rate = 0.000000 (2617.6 examples/sec)
=> 2021-11-02 08:49:47.074631: step 250900, loss = 0.022373, learning_rate = 0.000000 (2633.6 examples/sec)
=> 2021-11-02 08:50:06.799762: step 251000, loss = 0.012532, learning_rate = 0.000000 (2617.6 examples/sec)
=> Model saved to file: ./logs/model-251000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951944, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 08:50:38.339584: step 251100, loss = 0.060017, learning_rate = 0.000000 (2623.3 examples/sec)
=> 2021-11-02 08:50:57.990861: step 251200, loss = 0.036981, learning_rate = 0.000000 (2627.5 examples/sec)
=> 2021-11-02 08:51:18.598948: step 251300, loss = 0.044238, learning_rate = 0.000000 (2636.2 examples/sec)
=> 2021-11-02 08:51:38.331430: step 251400, loss = 0.068723, learning_rate = 0.000000 (2616.6 examples/sec)
=> 2021-11-02 08:51:58.015511: step 251500, loss = 0.018218, learning_rate = 0.000000 (2623.3 examples/sec)
=> 2021-11-02 08:52:17.700530: step 251600, loss = 0.034383, learning_rate = 0.000000 (2623.1 examples/sec)
=> 2021-11-02 08:52:37.410158: step 251700, loss = 0.045280, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 08:52:58.029730: step 251800, loss = 0.051590, learning_rate = 0.000000 (2633.4 examples/sec)
=> 2021-11-02 08:53:17.779089: step 251900, loss = 0.027161, learning_rate = 0.000000 (2614.6 examples/sec)
=> 2021-11-02 08:53:37.511081: step 252000, loss = 0.016034, learning_rate = 0.000000 (2617.0 examples/sec)
=> Model saved to file: ./logs/model-252000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952173, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 08:54:09.060188: step 252100, loss = 0.045801, learning_rate = 0.000000 (2625.1 examples/sec)
=> 2021-11-02 08:54:29.679147: step 252200, loss = 0.054878, learning_rate = 0.000000 (2637.8 examples/sec)
=> 2021-11-02 08:54:49.385606: step 252300, loss = 0.032412, learning_rate = 0.000000 (2620.2 examples/sec)
=> 2021-11-02 08:55:09.097801: step 252400, loss = 0.037612, learning_rate = 0.000000 (2619.5 examples/sec)
=> 2021-11-02 08:55:28.830637: step 252500, loss = 0.053606, learning_rate = 0.000000 (2616.7 examples/sec)
=> 2021-11-02 08:55:49.659055: step 252600, loss = 0.039910, learning_rate = 0.000000 (2624.8 examples/sec)
=> 2021-11-02 08:56:09.407557: step 252700, loss = 0.031491, learning_rate = 0.000000 (2614.7 examples/sec)
=> 2021-11-02 08:56:29.150865: step 252800, loss = 0.018278, learning_rate = 0.000000 (2615.3 examples/sec)
=> 2021-11-02 08:56:48.900008: step 252900, loss = 0.021976, learning_rate = 0.000000 (2614.4 examples/sec)
=> 2021-11-02 08:57:09.602665: step 253000, loss = 0.035239, learning_rate = 0.000000 (2626.8 examples/sec)
=> Model saved to file: ./logs/model-253000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951255, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 08:57:41.039429: step 253100, loss = 0.028935, learning_rate = 0.000000 (2622.1 examples/sec)
=> 2021-11-02 08:58:00.732075: step 253200, loss = 0.033356, learning_rate = 0.000000 (2622.0 examples/sec)
=> 2021-11-02 08:58:20.448038: step 253300, loss = 0.032903, learning_rate = 0.000000 (2618.9 examples/sec)
=> 2021-11-02 08:58:41.088772: step 253400, loss = 0.030560, learning_rate = 0.000000 (2632.1 examples/sec)
=> 2021-11-02 08:59:00.833067: step 253500, loss = 0.033250, learning_rate = 0.000000 (2615.2 examples/sec)
=> 2021-11-02 08:59:20.562482: step 253600, loss = 0.032296, learning_rate = 0.000000 (2617.4 examples/sec)
=> 2021-11-02 08:59:40.300118: step 253700, loss = 0.054457, learning_rate = 0.000000 (2616.1 examples/sec)
=> 2021-11-02 09:00:01.163789: step 253800, loss = 0.028818, learning_rate = 0.000000 (2629.7 examples/sec)
=> 2021-11-02 09:00:20.900303: step 253900, loss = 0.029642, learning_rate = 0.000000 (2616.1 examples/sec)
=> 2021-11-02 09:00:40.655973: step 254000, loss = 0.030524, learning_rate = 0.000000 (2613.7 examples/sec)
=> Model saved to file: ./logs/model-254000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953627, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 09:01:12.169027: step 254100, loss = 0.071060, learning_rate = 0.000000 (2619.6 examples/sec)
=> 2021-11-02 09:01:32.860686: step 254200, loss = 0.015874, learning_rate = 0.000000 (2633.4 examples/sec)
=> 2021-11-02 09:01:52.594854: step 254300, loss = 0.081805, learning_rate = 0.000000 (2617.2 examples/sec)
=> 2021-11-02 09:02:12.470153: step 254400, loss = 0.029370, learning_rate = 0.000000 (2597.8 examples/sec)
=> 2021-11-02 09:02:32.217147: step 254500, loss = 0.034372, learning_rate = 0.000000 (2614.8 examples/sec)
=> 2021-11-02 09:02:51.965876: step 254600, loss = 0.043443, learning_rate = 0.000000 (2614.6 examples/sec)
=> 2021-11-02 09:03:12.670058: step 254700, loss = 0.050144, learning_rate = 0.000000 (2630.7 examples/sec)
=> 2021-11-02 09:03:32.371990: step 254800, loss = 0.044827, learning_rate = 0.000000 (2620.9 examples/sec)
=> 2021-11-02 09:03:52.059829: step 254900, loss = 0.046367, learning_rate = 0.000000 (2622.6 examples/sec)
=> 2021-11-02 09:04:11.787132: step 255000, loss = 0.063532, learning_rate = 0.000000 (2617.5 examples/sec)
=> Model saved to file: ./logs/model-255000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951561, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 09:04:44.155387: step 255100, loss = 0.044986, learning_rate = 0.000000 (2633.6 examples/sec)
=> 2021-11-02 09:05:03.823609: step 255200, loss = 0.029830, learning_rate = 0.000000 (2625.3 examples/sec)
=> 2021-11-02 09:05:23.542085: step 255300, loss = 0.033237, learning_rate = 0.000000 (2618.5 examples/sec)
=> 2021-11-02 09:05:43.299308: step 255400, loss = 0.009739, learning_rate = 0.000000 (2613.3 examples/sec)
=> 2021-11-02 09:06:03.956281: step 255500, loss = 0.031018, learning_rate = 0.000000 (2634.7 examples/sec)
=> 2021-11-02 09:06:23.689215: step 255600, loss = 0.043826, learning_rate = 0.000000 (2616.8 examples/sec)
=> 2021-11-02 09:06:43.426919: step 255700, loss = 0.037433, learning_rate = 0.000000 (2616.1 examples/sec)
=> 2021-11-02 09:07:03.160984: step 255800, loss = 0.030366, learning_rate = 0.000000 (2616.4 examples/sec)
=> 2021-11-02 09:07:23.988194: step 255900, loss = 0.034608, learning_rate = 0.000000 (2633.4 examples/sec)
=> 2021-11-02 09:07:43.717736: step 256000, loss = 0.033056, learning_rate = 0.000000 (2617.3 examples/sec)
=> Model saved to file: ./logs/model-256000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953857, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 09:08:15.358030: step 256100, loss = 0.053625, learning_rate = 0.000000 (2622.8 examples/sec)
=> 2021-11-02 09:08:35.015587: step 256200, loss = 0.026726, learning_rate = 0.000000 (2626.7 examples/sec)
=> 2021-11-02 09:08:55.716628: step 256300, loss = 0.083124, learning_rate = 0.000000 (2633.5 examples/sec)
=> 2021-11-02 09:09:15.440407: step 256400, loss = 0.043503, learning_rate = 0.000000 (2618.2 examples/sec)
=> 2021-11-02 09:09:35.135877: step 256500, loss = 0.016337, learning_rate = 0.000000 (2621.6 examples/sec)
=> 2021-11-02 09:09:54.847091: step 256600, loss = 0.042713, learning_rate = 0.000000 (2619.5 examples/sec)
=> 2021-11-02 09:10:15.528787: step 256700, loss = 0.057139, learning_rate = 0.000000 (2630.0 examples/sec)
=> 2021-11-02 09:10:35.245505: step 256800, loss = 0.021322, learning_rate = 0.000000 (2618.8 examples/sec)
=> 2021-11-02 09:10:54.935153: step 256900, loss = 0.049060, learning_rate = 0.000000 (2622.3 examples/sec)
=> 2021-11-02 09:11:14.652448: step 257000, loss = 0.036186, learning_rate = 0.000000 (2618.7 examples/sec)
=> Model saved to file: ./logs/model-257000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952556, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 09:11:46.800893: step 257100, loss = 0.032042, learning_rate = 0.000000 (2644.7 examples/sec)
=> 2021-11-02 09:12:06.452953: step 257200, loss = 0.026912, learning_rate = 0.000000 (2627.8 examples/sec)
=> 2021-11-02 09:12:26.155082: step 257300, loss = 0.024178, learning_rate = 0.000000 (2620.7 examples/sec)
=> 2021-11-02 09:12:45.881049: step 257400, loss = 0.029548, learning_rate = 0.000000 (2617.4 examples/sec)
=> 2021-11-02 09:13:05.604918: step 257500, loss = 0.038589, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 09:13:26.266459: step 257600, loss = 0.030706, learning_rate = 0.000000 (2632.7 examples/sec)
=> 2021-11-02 09:13:45.993869: step 257700, loss = 0.035185, learning_rate = 0.000000 (2617.4 examples/sec)
=> 2021-11-02 09:14:05.789554: step 257800, loss = 0.039160, learning_rate = 0.000000 (2608.2 examples/sec)
=> 2021-11-02 09:14:25.528240: step 257900, loss = 0.026411, learning_rate = 0.000000 (2616.0 examples/sec)
=> 2021-11-02 09:14:46.259129: step 258000, loss = 0.034331, learning_rate = 0.000000 (2631.0 examples/sec)
=> Model saved to file: ./logs/model-258000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951561, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 09:15:17.765468: step 258100, loss = 0.092624, learning_rate = 0.000000 (2623.3 examples/sec)
=> 2021-11-02 09:15:37.477227: step 258200, loss = 0.045761, learning_rate = 0.000000 (2619.4 examples/sec)
=> 2021-11-02 09:15:57.174692: step 258300, loss = 0.024193, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-02 09:16:17.831211: step 258400, loss = 0.050286, learning_rate = 0.000000 (2631.4 examples/sec)
=> 2021-11-02 09:16:37.558085: step 258500, loss = 0.053721, learning_rate = 0.000000 (2617.5 examples/sec)
=> 2021-11-02 09:16:57.293801: step 258600, loss = 0.032792, learning_rate = 0.000000 (2616.2 examples/sec)
=> 2021-11-02 09:17:17.019463: step 258700, loss = 0.020653, learning_rate = 0.000000 (2617.7 examples/sec)
=> 2021-11-02 09:17:37.681789: step 258800, loss = 0.018745, learning_rate = 0.000000 (2628.7 examples/sec)
=> 2021-11-02 09:17:57.429438: step 258900, loss = 0.026577, learning_rate = 0.000000 (2615.0 examples/sec)
=> 2021-11-02 09:18:17.159512: step 259000, loss = 0.068784, learning_rate = 0.000000 (2616.8 examples/sec)
=> Model saved to file: ./logs/model-259000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947582, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 09:18:48.725312: step 259100, loss = 0.029104, learning_rate = 0.000000 (2613.7 examples/sec)
=> 2021-11-02 09:19:09.305703: step 259200, loss = 0.038893, learning_rate = 0.000000 (2642.0 examples/sec)
=> 2021-11-02 09:19:28.962674: step 259300, loss = 0.030538, learning_rate = 0.000000 (2626.7 examples/sec)
=> 2021-11-02 09:19:48.664543: step 259400, loss = 0.042387, learning_rate = 0.000000 (2620.9 examples/sec)
=> 2021-11-02 09:20:08.476118: step 259500, loss = 0.046954, learning_rate = 0.000000 (2606.4 examples/sec)
=> 2021-11-02 09:20:29.124790: step 259600, loss = 0.062309, learning_rate = 0.000000 (2630.0 examples/sec)
=> 2021-11-02 09:20:48.850913: step 259700, loss = 0.038415, learning_rate = 0.000000 (2617.6 examples/sec)
=> 2021-11-02 09:21:08.591728: step 259800, loss = 0.044336, learning_rate = 0.000000 (2615.7 examples/sec)
=> 2021-11-02 09:21:28.328252: step 259900, loss = 0.033361, learning_rate = 0.000000 (2616.2 examples/sec)
=> 2021-11-02 09:21:49.160933: step 260000, loss = 0.029716, learning_rate = 0.000000 (2628.6 examples/sec)
=> Model saved to file: ./logs/model-260000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951102, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 09:22:20.706984: step 260100, loss = 0.025601, learning_rate = 0.000000 (2623.8 examples/sec)
=> 2021-11-02 09:22:40.359215: step 260200, loss = 0.039403, learning_rate = 0.000000 (2627.4 examples/sec)
=> 2021-11-02 09:23:00.062161: step 260300, loss = 0.020107, learning_rate = 0.000000 (2620.5 examples/sec)
=> 2021-11-02 09:23:19.833245: step 260400, loss = 0.045158, learning_rate = 0.000000 (2612.5 examples/sec)
=> 2021-11-02 09:23:40.548968: step 260500, loss = 0.068178, learning_rate = 0.000000 (2631.0 examples/sec)
=> 2021-11-02 09:24:00.273421: step 260600, loss = 0.053776, learning_rate = 0.000000 (2617.8 examples/sec)
=> 2021-11-02 09:24:20.022165: step 260700, loss = 0.015632, learning_rate = 0.000000 (2614.8 examples/sec)
=> 2021-11-02 09:24:39.766448: step 260800, loss = 0.039908, learning_rate = 0.000000 (2615.1 examples/sec)
=> 2021-11-02 09:25:00.515597: step 260900, loss = 0.016059, learning_rate = 0.000000 (2634.8 examples/sec)
=> 2021-11-02 09:25:20.262470: step 261000, loss = 0.043314, learning_rate = 0.000000 (2614.8 examples/sec)
=> Model saved to file: ./logs/model-261000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953245, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 09:25:51.531340: step 261100, loss = 0.025648, learning_rate = 0.000000 (2626.3 examples/sec)
=> 2021-11-02 09:26:11.210178: step 261200, loss = 0.046531, learning_rate = 0.000000 (2624.0 examples/sec)
=> 2021-11-02 09:26:31.843769: step 261300, loss = 0.018946, learning_rate = 0.000000 (2632.1 examples/sec)
=> 2021-11-02 09:26:51.536430: step 261400, loss = 0.030719, learning_rate = 0.000000 (2622.1 examples/sec)
=> 2021-11-02 09:27:11.240427: step 261500, loss = 0.064361, learning_rate = 0.000000 (2620.6 examples/sec)
=> 2021-11-02 09:27:30.958886: step 261600, loss = 0.038861, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 09:27:51.583086: step 261700, loss = 0.034305, learning_rate = 0.000000 (2636.4 examples/sec)
=> 2021-11-02 09:28:11.304403: step 261800, loss = 0.023627, learning_rate = 0.000000 (2618.2 examples/sec)
=> 2021-11-02 09:28:31.030157: step 261900, loss = 0.049303, learning_rate = 0.000000 (2617.7 examples/sec)
=> 2021-11-02 09:28:50.749356: step 262000, loss = 0.038117, learning_rate = 0.000000 (2618.7 examples/sec)
=> Model saved to file: ./logs/model-262000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950719, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 09:29:23.200609: step 262100, loss = 0.012357, learning_rate = 0.000000 (2638.6 examples/sec)
=> 2021-11-02 09:29:42.847716: step 262200, loss = 0.054236, learning_rate = 0.000000 (2628.0 examples/sec)
=> 2021-11-02 09:30:02.542554: step 262300, loss = 0.016801, learning_rate = 0.000000 (2621.7 examples/sec)
=> 2021-11-02 09:30:22.250991: step 262400, loss = 0.029883, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 09:30:42.954931: step 262500, loss = 0.058527, learning_rate = 0.000000 (2624.9 examples/sec)
=> 2021-11-02 09:31:02.683607: step 262600, loss = 0.015289, learning_rate = 0.000000 (2617.7 examples/sec)
=> 2021-11-02 09:31:22.420488: step 262700, loss = 0.028177, learning_rate = 0.000000 (2616.3 examples/sec)
=> 2021-11-02 09:31:42.145048: step 262800, loss = 0.026086, learning_rate = 0.000000 (2617.6 examples/sec)
=> 2021-11-02 09:32:02.884566: step 262900, loss = 0.074875, learning_rate = 0.000000 (2629.7 examples/sec)
=> 2021-11-02 09:32:22.604740: step 263000, loss = 0.027120, learning_rate = 0.000000 (2618.7 examples/sec)
=> Model saved to file: ./logs/model-263000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951485, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 09:32:54.060587: step 263100, loss = 0.025610, learning_rate = 0.000000 (2626.0 examples/sec)
=> 2021-11-02 09:33:13.738534: step 263200, loss = 0.018932, learning_rate = 0.000000 (2624.0 examples/sec)
=> 2021-11-02 09:33:33.407432: step 263300, loss = 0.027458, learning_rate = 0.000000 (2625.8 examples/sec)
=> 2021-11-02 09:33:54.026243: step 263400, loss = 0.051883, learning_rate = 0.000000 (2635.4 examples/sec)
=> 2021-11-02 09:34:13.751972: step 263500, loss = 0.028020, learning_rate = 0.000000 (2618.1 examples/sec)
=> 2021-11-02 09:34:33.473031: step 263600, loss = 0.027485, learning_rate = 0.000000 (2618.2 examples/sec)
=> 2021-11-02 09:34:53.206080: step 263700, loss = 0.023307, learning_rate = 0.000000 (2616.5 examples/sec)
=> 2021-11-02 09:35:13.959378: step 263800, loss = 0.041599, learning_rate = 0.000000 (2629.6 examples/sec)
=> 2021-11-02 09:35:33.696257: step 263900, loss = 0.022812, learning_rate = 0.000000 (2616.1 examples/sec)
=> 2021-11-02 09:35:53.440684: step 264000, loss = 0.036446, learning_rate = 0.000000 (2615.1 examples/sec)
=> Model saved to file: ./logs/model-264000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949495, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 09:36:24.996769: step 264100, loss = 0.027194, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 09:36:45.558594: step 264200, loss = 0.027751, learning_rate = 0.000000 (2643.2 examples/sec)
=> 2021-11-02 09:37:05.191049: step 264300, loss = 0.055228, learning_rate = 0.000000 (2630.2 examples/sec)
=> 2021-11-02 09:37:24.844723: step 264400, loss = 0.044742, learning_rate = 0.000000 (2627.3 examples/sec)
=> 2021-11-02 09:37:44.517183: step 264500, loss = 0.045870, learning_rate = 0.000000 (2624.5 examples/sec)
=> 2021-11-02 09:38:05.164787: step 264600, loss = 0.016318, learning_rate = 0.000000 (2639.3 examples/sec)
=> 2021-11-02 09:38:24.864979: step 264700, loss = 0.036167, learning_rate = 0.000000 (2621.1 examples/sec)
=> 2021-11-02 09:38:44.578737: step 264800, loss = 0.016123, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 09:39:04.288489: step 264900, loss = 0.022071, learning_rate = 0.000000 (2619.9 examples/sec)
=> 2021-11-02 09:39:25.040424: step 265000, loss = 0.028093, learning_rate = 0.000000 (2633.7 examples/sec)
=> Model saved to file: ./logs/model-265000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950796, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 09:39:56.464895: step 265100, loss = 0.029458, learning_rate = 0.000000 (2624.6 examples/sec)
=> 2021-11-02 09:40:16.102788: step 265200, loss = 0.038678, learning_rate = 0.000000 (2629.3 examples/sec)
=> 2021-11-02 09:40:35.747712: step 265300, loss = 0.019006, learning_rate = 0.000000 (2628.3 examples/sec)
=> 2021-11-02 09:40:56.340237: step 265400, loss = 0.041060, learning_rate = 0.000000 (2642.4 examples/sec)
=> 2021-11-02 09:41:16.028145: step 265500, loss = 0.030061, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-02 09:41:35.698976: step 265600, loss = 0.036581, learning_rate = 0.000000 (2624.9 examples/sec)
=> 2021-11-02 09:41:55.397922: step 265700, loss = 0.032341, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-02 09:42:16.002618: step 265800, loss = 0.032461, learning_rate = 0.000000 (2638.9 examples/sec)
=> 2021-11-02 09:42:35.703361: step 265900, loss = 0.028501, learning_rate = 0.000000 (2620.9 examples/sec)
=> 2021-11-02 09:42:55.421113: step 266000, loss = 0.037652, learning_rate = 0.000000 (2618.5 examples/sec)
=> Model saved to file: ./logs/model-266000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950413, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 09:43:26.934042: step 266100, loss = 0.030233, learning_rate = 0.000000 (2623.9 examples/sec)
=> 2021-11-02 09:43:46.603278: step 266200, loss = 0.046589, learning_rate = 0.000000 (2625.8 examples/sec)
=> 2021-11-02 09:44:07.382338: step 266300, loss = 0.014548, learning_rate = 0.000000 (2638.3 examples/sec)
=> 2021-11-02 09:44:27.073844: step 266400, loss = 0.040352, learning_rate = 0.000000 (2622.2 examples/sec)
=> 2021-11-02 09:44:46.762871: step 266500, loss = 0.042817, learning_rate = 0.000000 (2622.6 examples/sec)
=> 2021-11-02 09:45:06.477983: step 266600, loss = 0.022976, learning_rate = 0.000000 (2619.0 examples/sec)
=> 2021-11-02 09:45:27.084589: step 266700, loss = 0.044660, learning_rate = 0.000000 (2635.8 examples/sec)
=> 2021-11-02 09:45:46.806660: step 266800, loss = 0.050937, learning_rate = 0.000000 (2618.0 examples/sec)
=> 2021-11-02 09:46:06.539016: step 266900, loss = 0.031739, learning_rate = 0.000000 (2616.8 examples/sec)
=> 2021-11-02 09:46:26.289383: step 267000, loss = 0.072120, learning_rate = 0.000000 (2614.4 examples/sec)
=> Model saved to file: ./logs/model-267000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947352, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 09:46:58.779675: step 267100, loss = 0.015204, learning_rate = 0.000000 (2637.2 examples/sec)
=> 2021-11-02 09:47:18.439914: step 267200, loss = 0.057702, learning_rate = 0.000000 (2626.4 examples/sec)
=> 2021-11-02 09:47:38.102194: step 267300, loss = 0.047483, learning_rate = 0.000000 (2626.1 examples/sec)
=> 2021-11-02 09:47:57.770773: step 267400, loss = 0.042561, learning_rate = 0.000000 (2625.0 examples/sec)
=> 2021-11-02 09:48:18.452894: step 267500, loss = 0.028235, learning_rate = 0.000000 (2626.5 examples/sec)
=> 2021-11-02 09:48:38.165003: step 267600, loss = 0.038086, learning_rate = 0.000000 (2619.3 examples/sec)
=> 2021-11-02 09:48:57.863151: step 267700, loss = 0.046447, learning_rate = 0.000000 (2621.3 examples/sec)
=> 2021-11-02 09:49:17.589297: step 267800, loss = 0.037033, learning_rate = 0.000000 (2617.6 examples/sec)
=> 2021-11-02 09:49:38.259938: step 267900, loss = 0.039113, learning_rate = 0.000000 (2628.6 examples/sec)
=> 2021-11-02 09:49:57.972009: step 268000, loss = 0.023552, learning_rate = 0.000000 (2619.3 examples/sec)
=> Model saved to file: ./logs/model-268000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952097, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 09:50:29.603597: step 268100, loss = 0.017830, learning_rate = 0.000000 (2623.5 examples/sec)
=> 2021-11-02 09:50:49.240313: step 268200, loss = 0.023899, learning_rate = 0.000000 (2629.3 examples/sec)
=> 2021-11-02 09:51:09.921748: step 268300, loss = 0.037294, learning_rate = 0.000000 (2639.3 examples/sec)
=> 2021-11-02 09:51:29.600307: step 268400, loss = 0.037994, learning_rate = 0.000000 (2623.9 examples/sec)
=> 2021-11-02 09:51:49.281529: step 268500, loss = 0.030504, learning_rate = 0.000000 (2623.5 examples/sec)
=> 2021-11-02 09:52:08.979048: step 268600, loss = 0.032371, learning_rate = 0.000000 (2621.3 examples/sec)
=> 2021-11-02 09:52:29.644500: step 268700, loss = 0.031096, learning_rate = 0.000000 (2632.8 examples/sec)
=> 2021-11-02 09:52:49.349862: step 268800, loss = 0.029235, learning_rate = 0.000000 (2620.2 examples/sec)
=> 2021-11-02 09:53:09.083927: step 268900, loss = 0.055261, learning_rate = 0.000000 (2616.7 examples/sec)
=> 2021-11-02 09:53:28.804440: step 269000, loss = 0.031644, learning_rate = 0.000000 (2618.2 examples/sec)
=> Model saved to file: ./logs/model-269000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952862, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 09:54:00.293062: step 269100, loss = 0.037653, learning_rate = 0.000000 (2626.0 examples/sec)
=> 2021-11-02 09:54:20.970229: step 269200, loss = 0.042781, learning_rate = 0.000000 (2626.8 examples/sec)
=> 2021-11-02 09:54:40.609660: step 269300, loss = 0.073715, learning_rate = 0.000000 (2629.1 examples/sec)
=> 2021-11-02 09:55:00.248803: step 269400, loss = 0.029616, learning_rate = 0.000000 (2629.2 examples/sec)
=> 2021-11-02 09:55:19.900752: step 269500, loss = 0.034219, learning_rate = 0.000000 (2627.6 examples/sec)
=> 2021-11-02 09:55:40.498405: step 269600, loss = 0.054915, learning_rate = 0.000000 (2660.0 examples/sec)
=> 2021-11-02 09:56:00.172868: step 269700, loss = 0.023617, learning_rate = 0.000000 (2624.3 examples/sec)
=> 2021-11-02 09:56:19.871569: step 269800, loss = 0.017107, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-02 09:56:39.570107: step 269900, loss = 0.014137, learning_rate = 0.000000 (2621.1 examples/sec)
=> 2021-11-02 09:57:00.208090: step 270000, loss = 0.054625, learning_rate = 0.000000 (2634.1 examples/sec)
=> Model saved to file: ./logs/model-270000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.943832, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 09:57:31.918478: step 270100, loss = 0.069121, learning_rate = 0.000000 (2625.2 examples/sec)
=> 2021-11-02 09:57:51.577224: step 270200, loss = 0.017830, learning_rate = 0.000000 (2626.7 examples/sec)
=> 2021-11-02 09:58:11.241986: step 270300, loss = 0.040748, learning_rate = 0.000000 (2625.8 examples/sec)
=> 2021-11-02 09:58:32.089258: step 270400, loss = 0.048986, learning_rate = 0.000000 (2631.4 examples/sec)
=> 2021-11-02 09:58:51.768851: step 270500, loss = 0.051595, learning_rate = 0.000000 (2623.6 examples/sec)
=> 2021-11-02 09:59:11.462058: step 270600, loss = 0.042256, learning_rate = 0.000000 (2622.1 examples/sec)
=> 2021-11-02 09:59:31.354319: step 270700, loss = 0.043632, learning_rate = 0.000000 (2595.4 examples/sec)
=> 2021-11-02 09:59:52.182676: step 270800, loss = 0.025023, learning_rate = 0.000000 (2637.1 examples/sec)
=> 2021-11-02 10:00:11.861788: step 270900, loss = 0.024693, learning_rate = 0.000000 (2623.9 examples/sec)
=> 2021-11-02 10:00:31.541582: step 271000, loss = 0.040263, learning_rate = 0.000000 (2623.9 examples/sec)
=> Model saved to file: ./logs/model-271000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949265, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 10:01:03.023004: step 271100, loss = 0.033561, learning_rate = 0.000000 (2625.1 examples/sec)
=> 2021-11-02 10:01:23.585237: step 271200, loss = 0.023749, learning_rate = 0.000000 (2640.7 examples/sec)
=> 2021-11-02 10:01:43.195841: step 271300, loss = 0.025888, learning_rate = 0.000000 (2632.7 examples/sec)
=> 2021-11-02 10:02:02.820636: step 271400, loss = 0.043339, learning_rate = 0.000000 (2631.5 examples/sec)
=> 2021-11-02 10:02:22.459576: step 271500, loss = 0.029771, learning_rate = 0.000000 (2629.1 examples/sec)
=> 2021-11-02 10:02:43.069535: step 271600, loss = 0.033929, learning_rate = 0.000000 (2636.9 examples/sec)
=> 2021-11-02 10:03:02.728424: step 271700, loss = 0.025841, learning_rate = 0.000000 (2626.7 examples/sec)
=> 2021-11-02 10:03:22.416938: step 271800, loss = 0.022274, learning_rate = 0.000000 (2622.7 examples/sec)
=> 2021-11-02 10:03:42.150849: step 271900, loss = 0.031574, learning_rate = 0.000000 (2616.7 examples/sec)
=> 2021-11-02 10:04:02.799248: step 272000, loss = 0.023011, learning_rate = 0.000000 (2631.9 examples/sec)
=> Model saved to file: ./logs/model-272000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950643, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 10:04:34.354760: step 272100, loss = 0.042588, learning_rate = 0.000000 (2625.1 examples/sec)
=> 2021-11-02 10:04:54.005925: step 272200, loss = 0.032958, learning_rate = 0.000000 (2627.6 examples/sec)
=> 2021-11-02 10:05:13.689611: step 272300, loss = 0.022759, learning_rate = 0.000000 (2623.3 examples/sec)
=> 2021-11-02 10:05:33.368703: step 272400, loss = 0.041077, learning_rate = 0.000000 (2623.7 examples/sec)
=> 2021-11-02 10:05:54.032500: step 272500, loss = 0.018288, learning_rate = 0.000000 (2633.0 examples/sec)
=> 2021-11-02 10:06:13.742603: step 272600, loss = 0.024756, learning_rate = 0.000000 (2619.9 examples/sec)
=> 2021-11-02 10:06:33.463100: step 272700, loss = 0.034885, learning_rate = 0.000000 (2618.4 examples/sec)
=> 2021-11-02 10:06:53.175121: step 272800, loss = 0.025543, learning_rate = 0.000000 (2619.5 examples/sec)
=> 2021-11-02 10:07:13.822647: step 272900, loss = 0.011144, learning_rate = 0.000000 (2648.8 examples/sec)
=> 2021-11-02 10:07:33.550330: step 273000, loss = 0.039530, learning_rate = 0.000000 (2617.3 examples/sec)
=> Model saved to file: ./logs/model-273000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952097, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 10:08:04.992789: step 273100, loss = 0.027425, learning_rate = 0.000000 (2624.5 examples/sec)
=> 2021-11-02 10:08:24.656758: step 273200, loss = 0.044858, learning_rate = 0.000000 (2626.0 examples/sec)
=> 2021-11-02 10:08:45.308143: step 273300, loss = 0.038279, learning_rate = 0.000000 (2637.6 examples/sec)
=> 2021-11-02 10:09:05.002305: step 273400, loss = 0.032406, learning_rate = 0.000000 (2621.7 examples/sec)
=> 2021-11-02 10:09:24.716115: step 273500, loss = 0.014169, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 10:09:44.440894: step 273600, loss = 0.039152, learning_rate = 0.000000 (2617.6 examples/sec)
=> 2021-11-02 10:10:05.189550: step 273700, loss = 0.047279, learning_rate = 0.000000 (2632.9 examples/sec)
=> 2021-11-02 10:10:24.923337: step 273800, loss = 0.017900, learning_rate = 0.000000 (2617.1 examples/sec)
=> 2021-11-02 10:10:44.656285: step 273900, loss = 0.033066, learning_rate = 0.000000 (2616.6 examples/sec)
=> 2021-11-02 10:11:04.394324: step 274000, loss = 0.051202, learning_rate = 0.000000 (2615.6 examples/sec)
=> Model saved to file: ./logs/model-274000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950337, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 10:11:37.131644: step 274100, loss = 0.041036, learning_rate = 0.000000 (2633.9 examples/sec)
=> 2021-11-02 10:11:56.787550: step 274200, loss = 0.015731, learning_rate = 0.000000 (2627.0 examples/sec)
=> 2021-11-02 10:12:16.445808: step 274300, loss = 0.023119, learning_rate = 0.000000 (2626.7 examples/sec)
=> 2021-11-02 10:12:36.162606: step 274400, loss = 0.030854, learning_rate = 0.000000 (2618.9 examples/sec)
=> 2021-11-02 10:12:56.830147: step 274500, loss = 0.028550, learning_rate = 0.000000 (2631.9 examples/sec)
=> 2021-11-02 10:13:16.544119: step 274600, loss = 0.037789, learning_rate = 0.000000 (2619.3 examples/sec)
=> 2021-11-02 10:13:36.326753: step 274700, loss = 0.036330, learning_rate = 0.000000 (2610.1 examples/sec)
=> 2021-11-02 10:13:56.067973: step 274800, loss = 0.025735, learning_rate = 0.000000 (2615.7 examples/sec)
=> 2021-11-02 10:14:16.760844: step 274900, loss = 0.035331, learning_rate = 0.000000 (2630.3 examples/sec)
=> 2021-11-02 10:14:36.502200: step 275000, loss = 0.051207, learning_rate = 0.000000 (2616.5 examples/sec)
=> Model saved to file: ./logs/model-275000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953474, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 10:15:07.990200: step 275100, loss = 0.077587, learning_rate = 0.000000 (2624.6 examples/sec)
=> 2021-11-02 10:15:27.622342: step 275200, loss = 0.017091, learning_rate = 0.000000 (2629.9 examples/sec)
=> 2021-11-02 10:15:47.282306: step 275300, loss = 0.030750, learning_rate = 0.000000 (2626.3 examples/sec)
=> 2021-11-02 10:16:07.850506: step 275400, loss = 0.020288, learning_rate = 0.000000 (2640.9 examples/sec)
=> 2021-11-02 10:16:27.559103: step 275500, loss = 0.030350, learning_rate = 0.000000 (2619.9 examples/sec)
=> 2021-11-02 10:16:47.284603: step 275600, loss = 0.043226, learning_rate = 0.000000 (2617.6 examples/sec)
=> 2021-11-02 10:17:07.012846: step 275700, loss = 0.039388, learning_rate = 0.000000 (2617.3 examples/sec)
=> 2021-11-02 10:17:27.775064: step 275800, loss = 0.055095, learning_rate = 0.000000 (2631.3 examples/sec)
=> 2021-11-02 10:17:47.490786: step 275900, loss = 0.027621, learning_rate = 0.000000 (2618.9 examples/sec)
=> 2021-11-02 10:18:07.210660: step 276000, loss = 0.037363, learning_rate = 0.000000 (2618.3 examples/sec)
=> Model saved to file: ./logs/model-276000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951714, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 10:18:38.628520: step 276100, loss = 0.032836, learning_rate = 0.000000 (2625.6 examples/sec)
=> 2021-11-02 10:18:59.202110: step 276200, loss = 0.020608, learning_rate = 0.000000 (2642.7 examples/sec)
=> 2021-11-02 10:19:18.854914: step 276300, loss = 0.029350, learning_rate = 0.000000 (2627.6 examples/sec)
=> 2021-11-02 10:19:38.514396: step 276400, loss = 0.035213, learning_rate = 0.000000 (2626.4 examples/sec)
=> 2021-11-02 10:19:58.221102: step 276500, loss = 0.059528, learning_rate = 0.000000 (2620.2 examples/sec)
=> 2021-11-02 10:20:18.994852: step 276600, loss = 0.024086, learning_rate = 0.000000 (2630.2 examples/sec)
=> 2021-11-02 10:20:38.712643: step 276700, loss = 0.018685, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 10:20:58.436786: step 276800, loss = 0.021468, learning_rate = 0.000000 (2617.9 examples/sec)
=> 2021-11-02 10:21:18.183466: step 276900, loss = 0.023838, learning_rate = 0.000000 (2614.8 examples/sec)
=> 2021-11-02 10:21:38.828200: step 277000, loss = 0.020783, learning_rate = 0.000000 (2645.2 examples/sec)
=> Model saved to file: ./logs/model-277000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952938, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 10:22:10.342018: step 277100, loss = 0.024618, learning_rate = 0.000000 (2623.9 examples/sec)
=> 2021-11-02 10:22:29.997990: step 277200, loss = 0.040971, learning_rate = 0.000000 (2626.9 examples/sec)
=> 2021-11-02 10:22:49.637999: step 277300, loss = 0.044637, learning_rate = 0.000000 (2629.0 examples/sec)
=> 2021-11-02 10:23:10.245415: step 277400, loss = 0.028856, learning_rate = 0.000000 (2639.2 examples/sec)
=> 2021-11-02 10:23:29.986171: step 277500, loss = 0.018643, learning_rate = 0.000000 (2615.3 examples/sec)
=> 2021-11-02 10:23:49.668646: step 277600, loss = 0.031039, learning_rate = 0.000000 (2623.2 examples/sec)
=> 2021-11-02 10:24:09.384986: step 277700, loss = 0.038260, learning_rate = 0.000000 (2618.7 examples/sec)
=> 2021-11-02 10:24:30.066264: step 277800, loss = 0.056645, learning_rate = 0.000000 (2630.3 examples/sec)
=> 2021-11-02 10:24:49.785439: step 277900, loss = 0.027212, learning_rate = 0.000000 (2617.9 examples/sec)
=> 2021-11-02 10:25:09.518846: step 278000, loss = 0.039398, learning_rate = 0.000000 (2616.6 examples/sec)
=> Model saved to file: ./logs/model-278000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953627, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 10:25:40.957709: step 278100, loss = 0.037207, learning_rate = 0.000000 (2627.1 examples/sec)
=> 2021-11-02 10:26:00.611273: step 278200, loss = 0.042963, learning_rate = 0.000000 (2627.8 examples/sec)
=> 2021-11-02 10:26:21.213464: step 278300, loss = 0.026115, learning_rate = 0.000000 (2640.8 examples/sec)
=> 2021-11-02 10:26:40.880573: step 278400, loss = 0.029761, learning_rate = 0.000000 (2625.7 examples/sec)
=> 2021-11-02 10:27:00.584707: step 278500, loss = 0.035993, learning_rate = 0.000000 (2620.6 examples/sec)
=> 2021-11-02 10:27:20.304716: step 278600, loss = 0.041640, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 10:27:41.003568: step 278700, loss = 0.049907, learning_rate = 0.000000 (2634.4 examples/sec)
=> 2021-11-02 10:28:00.684932: step 278800, loss = 0.021577, learning_rate = 0.000000 (2623.5 examples/sec)
=> 2021-11-02 10:28:20.371561: step 278900, loss = 0.026699, learning_rate = 0.000000 (2622.8 examples/sec)
=> 2021-11-02 10:28:40.075230: step 279000, loss = 0.021757, learning_rate = 0.000000 (2620.5 examples/sec)
=> Model saved to file: ./logs/model-279000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953933, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 10:29:12.644975: step 279100, loss = 0.020110, learning_rate = 0.000000 (2640.5 examples/sec)
=> 2021-11-02 10:29:32.307939: step 279200, loss = 0.024509, learning_rate = 0.000000 (2626.4 examples/sec)
=> 2021-11-02 10:29:52.011843: step 279300, loss = 0.035231, learning_rate = 0.000000 (2621.5 examples/sec)
=> 2021-11-02 10:30:11.748538: step 279400, loss = 0.031320, learning_rate = 0.000000 (2617.3 examples/sec)
=> 2021-11-02 10:30:32.550981: step 279500, loss = 0.023817, learning_rate = 0.000000 (2629.7 examples/sec)
=> 2021-11-02 10:30:52.298557: step 279600, loss = 0.044389, learning_rate = 0.000000 (2615.7 examples/sec)
=> 2021-11-02 10:31:12.042808: step 279700, loss = 0.014669, learning_rate = 0.000000 (2617.0 examples/sec)
=> 2021-11-02 10:31:31.799063: step 279800, loss = 0.027127, learning_rate = 0.000000 (2614.2 examples/sec)
=> 2021-11-02 10:31:52.647870: step 279900, loss = 0.017287, learning_rate = 0.000000 (2628.4 examples/sec)
=> 2021-11-02 10:32:12.449039: step 280000, loss = 0.021010, learning_rate = 0.000000 (2608.7 examples/sec)
=> Model saved to file: ./logs/model-280000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952862, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 10:32:44.368112: step 280100, loss = 0.061924, learning_rate = 0.000000 (2620.5 examples/sec)
=> 2021-11-02 10:33:04.078071: step 280200, loss = 0.021707, learning_rate = 0.000000 (2620.6 examples/sec)
=> 2021-11-02 10:33:24.816929: step 280300, loss = 0.043210, learning_rate = 0.000000 (2629.3 examples/sec)
=> 2021-11-02 10:33:44.545593: step 280400, loss = 0.037799, learning_rate = 0.000000 (2618.0 examples/sec)
=> 2021-11-02 10:34:04.268906: step 280500, loss = 0.024419, learning_rate = 0.000000 (2619.5 examples/sec)
=> 2021-11-02 10:34:23.996556: step 280600, loss = 0.035926, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 10:34:44.763408: step 280700, loss = 0.032220, learning_rate = 0.000000 (2628.5 examples/sec)
=> 2021-11-02 10:35:04.488510: step 280800, loss = 0.042727, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 10:35:24.220512: step 280900, loss = 0.057114, learning_rate = 0.000000 (2617.8 examples/sec)
=> 2021-11-02 10:35:43.961187: step 281000, loss = 0.054886, learning_rate = 0.000000 (2616.6 examples/sec)
=> Model saved to file: ./logs/model-281000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949571, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 10:36:16.069615: step 281100, loss = 0.058546, learning_rate = 0.000000 (2622.6 examples/sec)
=> 2021-11-02 10:36:36.779594: step 281200, loss = 0.038575, learning_rate = 0.000000 (2635.7 examples/sec)
=> 2021-11-02 10:36:56.480419: step 281300, loss = 0.024853, learning_rate = 0.000000 (2622.2 examples/sec)
=> 2021-11-02 10:37:16.171680: step 281400, loss = 0.019450, learning_rate = 0.000000 (2623.6 examples/sec)
=> 2021-11-02 10:37:35.887523: step 281500, loss = 0.036302, learning_rate = 0.000000 (2620.2 examples/sec)
=> 2021-11-02 10:37:56.709057: step 281600, loss = 0.017615, learning_rate = 0.000000 (2633.7 examples/sec)
=> 2021-11-02 10:38:16.424736: step 281700, loss = 0.015464, learning_rate = 0.000000 (2619.7 examples/sec)
=> 2021-11-02 10:38:36.150466: step 281800, loss = 0.013133, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 10:38:55.979261: step 281900, loss = 0.057961, learning_rate = 0.000000 (2605.6 examples/sec)
=> 2021-11-02 10:39:16.855017: step 282000, loss = 0.029592, learning_rate = 0.000000 (2625.7 examples/sec)
=> Model saved to file: ./logs/model-282000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950719, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 10:39:48.907947: step 282100, loss = 0.030722, learning_rate = 0.000000 (2619.9 examples/sec)
=> 2021-11-02 10:40:08.605396: step 282200, loss = 0.019194, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-02 10:40:28.309364: step 282300, loss = 0.027619, learning_rate = 0.000000 (2621.3 examples/sec)
=> 2021-11-02 10:40:49.069669: step 282400, loss = 0.016139, learning_rate = 0.000000 (2637.5 examples/sec)
=> 2021-11-02 10:41:08.804749: step 282500, loss = 0.051860, learning_rate = 0.000000 (2618.4 examples/sec)
=> 2021-11-02 10:41:28.535397: step 282600, loss = 0.057866, learning_rate = 0.000000 (2618.0 examples/sec)
=> 2021-11-02 10:41:48.260926: step 282700, loss = 0.036938, learning_rate = 0.000000 (2618.8 examples/sec)
=> 2021-11-02 10:42:09.070693: step 282800, loss = 0.038639, learning_rate = 0.000000 (2634.4 examples/sec)
=> 2021-11-02 10:42:28.858960: step 282900, loss = 0.044035, learning_rate = 0.000000 (2610.8 examples/sec)
=> 2021-11-02 10:42:48.586952: step 283000, loss = 0.026322, learning_rate = 0.000000 (2618.6 examples/sec)
=> Model saved to file: ./logs/model-283000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951255, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 10:43:20.918930: step 283100, loss = 0.035523, learning_rate = 0.000000 (2620.9 examples/sec)
=> 2021-11-02 10:43:41.560405: step 283200, loss = 0.020304, learning_rate = 0.000000 (2639.9 examples/sec)
=> 2021-11-02 10:44:01.253065: step 283300, loss = 0.045012, learning_rate = 0.000000 (2623.0 examples/sec)
=> 2021-11-02 10:44:20.931373: step 283400, loss = 0.019018, learning_rate = 0.000000 (2625.5 examples/sec)
=> 2021-11-02 10:44:40.642663: step 283500, loss = 0.043335, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-02 10:45:01.356075: step 283600, loss = 0.059287, learning_rate = 0.000000 (2634.3 examples/sec)
=> 2021-11-02 10:45:21.044076: step 283700, loss = 0.023101, learning_rate = 0.000000 (2623.6 examples/sec)
=> 2021-11-02 10:45:40.762949: step 283800, loss = 0.016298, learning_rate = 0.000000 (2619.7 examples/sec)
=> 2021-11-02 10:46:00.476283: step 283900, loss = 0.023936, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-02 10:46:20.207741: step 284000, loss = 0.041839, learning_rate = 0.000000 (2618.4 examples/sec)
=> Model saved to file: ./logs/model-284000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951102, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 10:46:53.316624: step 284100, loss = 0.036191, learning_rate = 0.000000 (2631.5 examples/sec)
=> 2021-11-02 10:47:13.018931: step 284200, loss = 0.021440, learning_rate = 0.000000 (2621.7 examples/sec)
=> 2021-11-02 10:47:32.715061: step 284300, loss = 0.054741, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-02 10:47:52.414673: step 284400, loss = 0.027212, learning_rate = 0.000000 (2622.1 examples/sec)
=> 2021-11-02 10:48:13.404193: step 284500, loss = 0.015299, learning_rate = 0.000000 (2633.4 examples/sec)
=> 2021-11-02 10:48:33.131082: step 284600, loss = 0.019907, learning_rate = 0.000000 (2618.4 examples/sec)
=> 2021-11-02 10:48:52.854769: step 284700, loss = 0.010552, learning_rate = 0.000000 (2619.0 examples/sec)
=> 2021-11-02 10:49:12.596269: step 284800, loss = 0.016856, learning_rate = 0.000000 (2617.0 examples/sec)
=> 2021-11-02 10:49:33.347153: step 284900, loss = 0.036021, learning_rate = 0.000000 (2633.1 examples/sec)
=> 2021-11-02 10:49:53.078985: step 285000, loss = 0.023426, learning_rate = 0.000000 (2618.2 examples/sec)
=> Model saved to file: ./logs/model-285000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949954, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 10:50:25.106944: step 285100, loss = 0.025968, learning_rate = 0.000000 (2623.6 examples/sec)
=> 2021-11-02 10:50:44.800337: step 285200, loss = 0.049175, learning_rate = 0.000000 (2623.0 examples/sec)
=> 2021-11-02 10:51:05.566398: step 285300, loss = 0.026475, learning_rate = 0.000000 (2633.4 examples/sec)
=> 2021-11-02 10:51:25.270334: step 285400, loss = 0.035672, learning_rate = 0.000000 (2622.1 examples/sec)
=> 2021-11-02 10:51:44.986322: step 285500, loss = 0.019295, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 10:52:04.709381: step 285600, loss = 0.047815, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 10:52:25.528703: step 285700, loss = 0.030021, learning_rate = 0.000000 (2634.5 examples/sec)
=> 2021-11-02 10:52:45.262592: step 285800, loss = 0.042108, learning_rate = 0.000000 (2617.6 examples/sec)
=> 2021-11-02 10:53:04.988197: step 285900, loss = 0.014369, learning_rate = 0.000000 (2618.8 examples/sec)
=> 2021-11-02 10:53:24.708706: step 286000, loss = 0.017565, learning_rate = 0.000000 (2619.2 examples/sec)
=> Model saved to file: ./logs/model-286000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951485, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 10:53:57.946543: step 286100, loss = 0.029616, learning_rate = 0.000000 (2636.7 examples/sec)
=> 2021-11-02 10:54:17.633046: step 286200, loss = 0.042274, learning_rate = 0.000000 (2624.1 examples/sec)
=> 2021-11-02 10:54:37.333773: step 286300, loss = 0.034646, learning_rate = 0.000000 (2622.3 examples/sec)
=> 2021-11-02 10:54:57.050473: step 286400, loss = 0.045775, learning_rate = 0.000000 (2619.9 examples/sec)
=> 2021-11-02 10:55:17.889222: step 286500, loss = 0.025954, learning_rate = 0.000000 (2627.5 examples/sec)
=> 2021-11-02 10:55:37.613750: step 286600, loss = 0.020471, learning_rate = 0.000000 (2619.3 examples/sec)
=> 2021-11-02 10:55:57.351576: step 286700, loss = 0.026321, learning_rate = 0.000000 (2617.6 examples/sec)
=> 2021-11-02 10:56:17.109436: step 286800, loss = 0.013116, learning_rate = 0.000000 (2614.2 examples/sec)
=> 2021-11-02 10:56:36.854414: step 286900, loss = 0.041016, learning_rate = 0.000000 (2616.3 examples/sec)
=> 2021-11-02 10:56:57.650079: step 287000, loss = 0.017375, learning_rate = 0.000000 (2624.2 examples/sec)
=> Model saved to file: ./logs/model-287000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950260, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 10:57:29.781607: step 287100, loss = 0.034745, learning_rate = 0.000000 (2620.7 examples/sec)
=> 2021-11-02 10:57:49.474361: step 287200, loss = 0.032672, learning_rate = 0.000000 (2622.8 examples/sec)
=> 2021-11-02 10:58:09.182484: step 287300, loss = 0.033613, learning_rate = 0.000000 (2621.6 examples/sec)
=> 2021-11-02 10:58:30.082361: step 287400, loss = 0.046025, learning_rate = 0.000000 (2633.8 examples/sec)
=> 2021-11-02 10:58:49.801057: step 287500, loss = 0.047747, learning_rate = 0.000000 (2619.7 examples/sec)
=> 2021-11-02 10:59:09.542704: step 287600, loss = 0.063069, learning_rate = 0.000000 (2616.7 examples/sec)
=> 2021-11-02 10:59:29.416187: step 287700, loss = 0.044218, learning_rate = 0.000000 (2599.1 examples/sec)
=> 2021-11-02 10:59:50.236205: step 287800, loss = 0.038863, learning_rate = 0.000000 (2626.3 examples/sec)
=> 2021-11-02 11:00:09.963536: step 287900, loss = 0.048155, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 11:00:29.665342: step 288000, loss = 0.042429, learning_rate = 0.000000 (2622.6 examples/sec)
=> Model saved to file: ./logs/model-288000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950184, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 11:01:01.786820: step 288100, loss = 0.032857, learning_rate = 0.000000 (2626.6 examples/sec)
=> 2021-11-02 11:01:22.537054: step 288200, loss = 0.020419, learning_rate = 0.000000 (2640.6 examples/sec)
=> 2021-11-02 11:01:42.211787: step 288300, loss = 0.025255, learning_rate = 0.000000 (2625.8 examples/sec)
=> 2021-11-02 11:02:01.868078: step 288400, loss = 0.059974, learning_rate = 0.000000 (2628.6 examples/sec)
=> 2021-11-02 11:02:21.544186: step 288500, loss = 0.050824, learning_rate = 0.000000 (2625.2 examples/sec)
=> 2021-11-02 11:02:42.268878: step 288600, loss = 0.021766, learning_rate = 0.000000 (2634.6 examples/sec)
=> 2021-11-02 11:03:02.008000: step 288700, loss = 0.047915, learning_rate = 0.000000 (2616.8 examples/sec)
=> 2021-11-02 11:03:21.708072: step 288800, loss = 0.065274, learning_rate = 0.000000 (2622.1 examples/sec)
=> 2021-11-02 11:03:41.417558: step 288900, loss = 0.074336, learning_rate = 0.000000 (2620.7 examples/sec)
=> 2021-11-02 11:04:02.257110: step 289000, loss = 0.030790, learning_rate = 0.000000 (2635.0 examples/sec)
=> Model saved to file: ./logs/model-289000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.948730, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 11:04:34.303302: step 289100, loss = 0.025536, learning_rate = 0.000000 (2623.0 examples/sec)
=> 2021-11-02 11:04:53.989523: step 289200, loss = 0.015346, learning_rate = 0.000000 (2623.8 examples/sec)
=> 2021-11-02 11:05:13.680817: step 289300, loss = 0.027591, learning_rate = 0.000000 (2623.3 examples/sec)
=> 2021-11-02 11:05:34.479494: step 289400, loss = 0.012446, learning_rate = 0.000000 (2634.9 examples/sec)
=> 2021-11-02 11:05:54.198980: step 289500, loss = 0.063032, learning_rate = 0.000000 (2619.9 examples/sec)
=> 2021-11-02 11:06:13.922223: step 289600, loss = 0.023459, learning_rate = 0.000000 (2619.5 examples/sec)
=> 2021-11-02 11:06:33.666425: step 289700, loss = 0.042056, learning_rate = 0.000000 (2616.5 examples/sec)
=> 2021-11-02 11:06:53.393018: step 289800, loss = 0.023326, learning_rate = 0.000000 (2619.3 examples/sec)
=> 2021-11-02 11:07:14.361311: step 289900, loss = 0.021633, learning_rate = 0.000000 (2615.2 examples/sec)
=> 2021-11-02 11:07:34.049537: step 290000, loss = 0.040650, learning_rate = 0.000000 (2624.0 examples/sec)
=> Model saved to file: ./logs/model-290000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949878, best accuracy 0.954775
=> patience = 99
=> 2021-11-02 11:08:05.941072: step 290100, loss = 0.059922, learning_rate = 0.000000 (2631.5 examples/sec)
=> 2021-11-02 11:08:25.603459: step 290200, loss = 0.028690, learning_rate = 0.000000 (2627.2 examples/sec)
=> 2021-11-02 11:08:46.502811: step 290300, loss = 0.019707, learning_rate = 0.000000 (2617.7 examples/sec)
=> 2021-11-02 11:09:06.195146: step 290400, loss = 0.025011, learning_rate = 0.000000 (2622.9 examples/sec)
=> 2021-11-02 11:09:25.910936: step 290500, loss = 0.034288, learning_rate = 0.000000 (2620.3 examples/sec)
=> 2021-11-02 11:09:45.628654: step 290600, loss = 0.020113, learning_rate = 0.000000 (2619.9 examples/sec)
=> 2021-11-02 11:10:06.402928: step 290700, loss = 0.031962, learning_rate = 0.000000 (2637.6 examples/sec)
=> 2021-11-02 11:10:26.119003: step 290800, loss = 0.033438, learning_rate = 0.000000 (2619.7 examples/sec)
=> 2021-11-02 11:10:45.866746: step 290900, loss = 0.044175, learning_rate = 0.000000 (2615.8 examples/sec)
=> 2021-11-02 11:11:05.644822: step 291000, loss = 0.019221, learning_rate = 0.000000 (2612.5 examples/sec)
=> Model saved to file: ./logs/model-291000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.955005, best accuracy 0.954775
=> Model saved to file: ./logs/model-291000.pth
=> patience = 100
=> 2021-11-02 11:11:39.352071: step 291100, loss = 0.039863, learning_rate = 0.000000 (2632.3 examples/sec)
=> 2021-11-02 11:11:59.091427: step 291200, loss = 0.015161, learning_rate = 0.000000 (2617.2 examples/sec)
=> 2021-11-02 11:12:18.826427: step 291300, loss = 0.085901, learning_rate = 0.000000 (2617.5 examples/sec)
=> 2021-11-02 11:12:38.549943: step 291400, loss = 0.049631, learning_rate = 0.000000 (2619.1 examples/sec)
=> 2021-11-02 11:12:59.397536: step 291500, loss = 0.023889, learning_rate = 0.000000 (2627.4 examples/sec)
=> 2021-11-02 11:13:19.148256: step 291600, loss = 0.050607, learning_rate = 0.000000 (2615.5 examples/sec)
=> 2021-11-02 11:13:38.903687: step 291700, loss = 0.038242, learning_rate = 0.000000 (2615.0 examples/sec)
=> 2021-11-02 11:13:58.664138: step 291800, loss = 0.009362, learning_rate = 0.000000 (2613.7 examples/sec)
=> 2021-11-02 11:14:19.572732: step 291900, loss = 0.032609, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-02 11:14:39.355383: step 292000, loss = 0.043261, learning_rate = 0.000000 (2610.8 examples/sec)
=> Model saved to file: ./logs/model-292000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954010, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 11:15:11.342984: step 292100, loss = 0.026613, learning_rate = 0.000000 (2625.1 examples/sec)
=> 2021-11-02 11:15:31.018842: step 292200, loss = 0.031253, learning_rate = 0.000000 (2625.3 examples/sec)
=> 2021-11-02 11:15:51.890063: step 292300, loss = 0.034825, learning_rate = 0.000000 (2641.5 examples/sec)
=> 2021-11-02 11:16:11.599008: step 292400, loss = 0.031013, learning_rate = 0.000000 (2620.8 examples/sec)
=> 2021-11-02 11:16:31.281132: step 292500, loss = 0.020161, learning_rate = 0.000000 (2624.4 examples/sec)
=> 2021-11-02 11:16:51.055159: step 292600, loss = 0.025525, learning_rate = 0.000000 (2611.9 examples/sec)
=> 2021-11-02 11:17:11.860257: step 292700, loss = 0.046998, learning_rate = 0.000000 (2633.2 examples/sec)
=> 2021-11-02 11:17:31.563197: step 292800, loss = 0.015044, learning_rate = 0.000000 (2620.6 examples/sec)
=> 2021-11-02 11:17:51.277284: step 292900, loss = 0.017585, learning_rate = 0.000000 (2619.0 examples/sec)
=> 2021-11-02 11:18:11.009463: step 293000, loss = 0.025555, learning_rate = 0.000000 (2616.9 examples/sec)
=> Model saved to file: ./logs/model-293000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952403, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 11:18:42.459572: step 293100, loss = 0.042250, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-02 11:19:03.012991: step 293200, loss = 0.051230, learning_rate = 0.000000 (2645.9 examples/sec)
=> 2021-11-02 11:19:22.665301: step 293300, loss = 0.022759, learning_rate = 0.000000 (2627.6 examples/sec)
=> 2021-11-02 11:19:42.348903: step 293400, loss = 0.031876, learning_rate = 0.000000 (2622.9 examples/sec)
=> 2021-11-02 11:20:02.059013: step 293500, loss = 0.038985, learning_rate = 0.000000 (2619.6 examples/sec)
=> 2021-11-02 11:20:22.706362: step 293600, loss = 0.025971, learning_rate = 0.000000 (2644.1 examples/sec)
=> 2021-11-02 11:20:42.428010: step 293700, loss = 0.025867, learning_rate = 0.000000 (2618.1 examples/sec)
=> 2021-11-02 11:21:02.149715: step 293800, loss = 0.035513, learning_rate = 0.000000 (2618.1 examples/sec)
=> 2021-11-02 11:21:21.868577: step 293900, loss = 0.024596, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 11:21:42.519054: step 294000, loss = 0.019711, learning_rate = 0.000000 (2629.2 examples/sec)
=> Model saved to file: ./logs/model-294000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954392, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 11:22:13.864304: step 294100, loss = 0.046695, learning_rate = 0.000000 (2623.6 examples/sec)
=> 2021-11-02 11:22:33.496922: step 294200, loss = 0.051533, learning_rate = 0.000000 (2629.9 examples/sec)
=> 2021-11-02 11:22:53.164955: step 294300, loss = 0.010677, learning_rate = 0.000000 (2625.2 examples/sec)
=> 2021-11-02 11:23:13.885682: step 294400, loss = 0.049447, learning_rate = 0.000000 (2631.4 examples/sec)
=> 2021-11-02 11:23:33.584955: step 294500, loss = 0.041249, learning_rate = 0.000000 (2621.1 examples/sec)
=> 2021-11-02 11:23:53.302792: step 294600, loss = 0.051615, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 11:24:13.088340: step 294700, loss = 0.014620, learning_rate = 0.000000 (2610.9 examples/sec)
=> 2021-11-02 11:24:33.897538: step 294800, loss = 0.018765, learning_rate = 0.000000 (2625.2 examples/sec)
=> 2021-11-02 11:24:53.646683: step 294900, loss = 0.042098, learning_rate = 0.000000 (2615.4 examples/sec)
=> 2021-11-02 11:25:13.382693: step 295000, loss = 0.027399, learning_rate = 0.000000 (2617.1 examples/sec)
=> Model saved to file: ./logs/model-295000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952403, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 11:25:45.687190: step 295100, loss = 0.036393, learning_rate = 0.000000 (2623.4 examples/sec)
=> 2021-11-02 11:26:06.357466: step 295200, loss = 0.018648, learning_rate = 0.000000 (2645.4 examples/sec)
=> 2021-11-02 11:26:26.055208: step 295300, loss = 0.029495, learning_rate = 0.000000 (2621.4 examples/sec)
=> 2021-11-02 11:26:45.756412: step 295400, loss = 0.015501, learning_rate = 0.000000 (2620.9 examples/sec)
=> 2021-11-02 11:27:05.474158: step 295500, loss = 0.057086, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 11:27:26.198517: step 295600, loss = 0.039216, learning_rate = 0.000000 (2635.4 examples/sec)
=> 2021-11-02 11:27:45.905244: step 295700, loss = 0.024899, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 11:28:05.594409: step 295800, loss = 0.032445, learning_rate = 0.000000 (2622.4 examples/sec)
=> 2021-11-02 11:28:25.290402: step 295900, loss = 0.069422, learning_rate = 0.000000 (2621.5 examples/sec)
=> 2021-11-02 11:28:45.029821: step 296000, loss = 0.081718, learning_rate = 0.000000 (2616.3 examples/sec)
=> Model saved to file: ./logs/model-296000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952250, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 11:29:17.503452: step 296100, loss = 0.051325, learning_rate = 0.000000 (2640.6 examples/sec)
=> 2021-11-02 11:29:37.153813: step 296200, loss = 0.009721, learning_rate = 0.000000 (2627.9 examples/sec)
=> 2021-11-02 11:29:56.827741: step 296300, loss = 0.034913, learning_rate = 0.000000 (2624.6 examples/sec)
=> 2021-11-02 11:30:16.493502: step 296400, loss = 0.019635, learning_rate = 0.000000 (2625.8 examples/sec)
=> 2021-11-02 11:30:37.080606: step 296500, loss = 0.016965, learning_rate = 0.000000 (2639.3 examples/sec)
=> 2021-11-02 11:30:56.790881: step 296600, loss = 0.027102, learning_rate = 0.000000 (2619.7 examples/sec)
=> 2021-11-02 11:31:16.518670: step 296700, loss = 0.026937, learning_rate = 0.000000 (2617.4 examples/sec)
=> 2021-11-02 11:31:36.289463: step 296800, loss = 0.027145, learning_rate = 0.000000 (2613.3 examples/sec)
=> 2021-11-02 11:31:57.156630: step 296900, loss = 0.029845, learning_rate = 0.000000 (2628.0 examples/sec)
=> 2021-11-02 11:32:16.910770: step 297000, loss = 0.032045, learning_rate = 0.000000 (2614.8 examples/sec)
=> Model saved to file: ./logs/model-297000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953627, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 11:32:48.750835: step 297100, loss = 0.037831, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 11:33:08.439874: step 297200, loss = 0.071894, learning_rate = 0.000000 (2623.4 examples/sec)
=> 2021-11-02 11:33:29.255654: step 297300, loss = 0.026704, learning_rate = 0.000000 (2632.1 examples/sec)
=> 2021-11-02 11:33:48.980266: step 297400, loss = 0.030703, learning_rate = 0.000000 (2618.7 examples/sec)
=> 2021-11-02 11:34:08.730011: step 297500, loss = 0.023845, learning_rate = 0.000000 (2615.7 examples/sec)
=> 2021-11-02 11:34:28.486555: step 297600, loss = 0.033345, learning_rate = 0.000000 (2614.6 examples/sec)
=> 2021-11-02 11:34:49.301836: step 297700, loss = 0.037982, learning_rate = 0.000000 (2623.2 examples/sec)
=> 2021-11-02 11:35:09.077700: step 297800, loss = 0.049716, learning_rate = 0.000000 (2611.9 examples/sec)
=> 2021-11-02 11:35:28.851544: step 297900, loss = 0.038347, learning_rate = 0.000000 (2612.3 examples/sec)
=> 2021-11-02 11:35:48.645818: step 298000, loss = 0.017208, learning_rate = 0.000000 (2609.5 examples/sec)
=> Model saved to file: ./logs/model-298000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954392, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 11:36:21.671845: step 298100, loss = 0.034257, learning_rate = 0.000000 (2625.5 examples/sec)
=> 2021-11-02 11:36:41.377622: step 298200, loss = 0.030399, learning_rate = 0.000000 (2621.0 examples/sec)
=> 2021-11-02 11:37:01.090018: step 298300, loss = 0.058351, learning_rate = 0.000000 (2620.3 examples/sec)
=> 2021-11-02 11:37:20.830382: step 298400, loss = 0.018035, learning_rate = 0.000000 (2616.8 examples/sec)
=> 2021-11-02 11:37:41.599001: step 298500, loss = 0.021084, learning_rate = 0.000000 (2626.2 examples/sec)
=> 2021-11-02 11:38:01.364825: step 298600, loss = 0.047145, learning_rate = 0.000000 (2613.4 examples/sec)
=> 2021-11-02 11:38:21.120686: step 298700, loss = 0.027571, learning_rate = 0.000000 (2614.6 examples/sec)
=> 2021-11-02 11:38:40.884446: step 298800, loss = 0.034557, learning_rate = 0.000000 (2613.6 examples/sec)
=> 2021-11-02 11:39:00.663347: step 298900, loss = 0.024869, learning_rate = 0.000000 (2612.4 examples/sec)
=> 2021-11-02 11:39:21.474011: step 299000, loss = 0.028761, learning_rate = 0.000000 (2622.8 examples/sec)
=> Model saved to file: ./logs/model-299000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952709, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 11:39:53.255001: step 299100, loss = 0.041413, learning_rate = 0.000000 (2621.0 examples/sec)
=> 2021-11-02 11:40:12.981420: step 299200, loss = 0.016867, learning_rate = 0.000000 (2618.5 examples/sec)
=> 2021-11-02 11:40:32.713452: step 299300, loss = 0.030432, learning_rate = 0.000000 (2617.7 examples/sec)
=> 2021-11-02 11:40:53.563623: step 299400, loss = 0.027376, learning_rate = 0.000000 (2631.7 examples/sec)
=> 2021-11-02 11:41:13.286046: step 299500, loss = 0.022524, learning_rate = 0.000000 (2618.9 examples/sec)
=> 2021-11-02 11:41:33.224205: step 299600, loss = 0.027805, learning_rate = 0.000000 (2590.5 examples/sec)
=> 2021-11-02 11:41:52.977507: step 299700, loss = 0.025792, learning_rate = 0.000000 (2615.1 examples/sec)
=> 2021-11-02 11:42:13.950689: step 299800, loss = 0.019445, learning_rate = 0.000000 (2628.0 examples/sec)
=> 2021-11-02 11:42:33.692629: step 299900, loss = 0.028724, learning_rate = 0.000000 (2616.3 examples/sec)
=> 2021-11-02 11:42:53.414803: step 300000, loss = 0.013206, learning_rate = 0.000000 (2618.2 examples/sec)
=> Model saved to file: ./logs/model-300000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953015, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 11:43:24.960921: step 300100, loss = 0.009544, learning_rate = 0.000000 (2624.5 examples/sec)
=> 2021-11-02 11:43:45.701684: step 300200, loss = 0.036087, learning_rate = 0.000000 (2636.5 examples/sec)
=> 2021-11-02 11:44:05.412631: step 300300, loss = 0.067647, learning_rate = 0.000000 (2620.2 examples/sec)
=> 2021-11-02 11:44:25.113145: step 300400, loss = 0.022795, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-02 11:44:44.855437: step 300500, loss = 0.033095, learning_rate = 0.000000 (2616.2 examples/sec)
=> 2021-11-02 11:45:05.700497: step 300600, loss = 0.015085, learning_rate = 0.000000 (2634.3 examples/sec)
=> 2021-11-02 11:45:25.418671: step 300700, loss = 0.019882, learning_rate = 0.000000 (2618.8 examples/sec)
=> 2021-11-02 11:45:45.154632: step 300800, loss = 0.033123, learning_rate = 0.000000 (2616.8 examples/sec)
=> 2021-11-02 11:46:04.901013: step 300900, loss = 0.019721, learning_rate = 0.000000 (2615.5 examples/sec)
=> 2021-11-02 11:46:25.657645: step 301000, loss = 0.039411, learning_rate = 0.000000 (2630.7 examples/sec)
=> Model saved to file: ./logs/model-301000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952403, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 11:46:57.152591: step 301100, loss = 0.020303, learning_rate = 0.000000 (2620.7 examples/sec)
=> 2021-11-02 11:47:16.795064: step 301200, loss = 0.065061, learning_rate = 0.000000 (2628.8 examples/sec)
=> 2021-11-02 11:47:36.460446: step 301300, loss = 0.015120, learning_rate = 0.000000 (2626.1 examples/sec)
=> 2021-11-02 11:47:57.098448: step 301400, loss = 0.014509, learning_rate = 0.000000 (2637.9 examples/sec)
=> 2021-11-02 11:48:16.796445: step 301500, loss = 0.018651, learning_rate = 0.000000 (2621.3 examples/sec)
=> 2021-11-02 11:48:36.484909: step 301600, loss = 0.017294, learning_rate = 0.000000 (2622.7 examples/sec)
=> 2021-11-02 11:48:56.272850: step 301700, loss = 0.013892, learning_rate = 0.000000 (2611.3 examples/sec)
=> 2021-11-02 11:49:16.007503: step 301800, loss = 0.035617, learning_rate = 0.000000 (2619.0 examples/sec)
=> 2021-11-02 11:49:36.799257: step 301900, loss = 0.053218, learning_rate = 0.000000 (2631.6 examples/sec)
=> 2021-11-02 11:49:56.471107: step 302000, loss = 0.030161, learning_rate = 0.000000 (2624.8 examples/sec)
=> Model saved to file: ./logs/model-302000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951102, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 11:50:27.923569: step 302100, loss = 0.027702, learning_rate = 0.000000 (2625.2 examples/sec)
=> 2021-11-02 11:50:47.582424: step 302200, loss = 0.022888, learning_rate = 0.000000 (2626.6 examples/sec)
=> 2021-11-02 11:51:08.155954: step 302300, loss = 0.023701, learning_rate = 0.000000 (2641.8 examples/sec)
=> 2021-11-02 11:51:27.859814: step 302400, loss = 0.027958, learning_rate = 0.000000 (2620.9 examples/sec)
=> 2021-11-02 11:51:47.582683: step 302500, loss = 0.025611, learning_rate = 0.000000 (2618.2 examples/sec)
=> 2021-11-02 11:52:07.349082: step 302600, loss = 0.025850, learning_rate = 0.000000 (2612.5 examples/sec)
=> 2021-11-02 11:52:28.151365: step 302700, loss = 0.031681, learning_rate = 0.000000 (2622.8 examples/sec)
=> 2021-11-02 11:52:47.858672: step 302800, loss = 0.026765, learning_rate = 0.000000 (2619.9 examples/sec)
=> 2021-11-02 11:53:07.577371: step 302900, loss = 0.063068, learning_rate = 0.000000 (2619.0 examples/sec)
=> 2021-11-02 11:53:27.322255: step 303000, loss = 0.031549, learning_rate = 0.000000 (2615.6 examples/sec)
=> Model saved to file: ./logs/model-303000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952097, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 11:54:00.067676: step 303100, loss = 0.037750, learning_rate = 0.000000 (2634.1 examples/sec)
=> 2021-11-02 11:54:19.737940: step 303200, loss = 0.024960, learning_rate = 0.000000 (2625.2 examples/sec)
=> 2021-11-02 11:54:39.516736: step 303300, loss = 0.039782, learning_rate = 0.000000 (2610.5 examples/sec)
=> 2021-11-02 11:54:59.187679: step 303400, loss = 0.031019, learning_rate = 0.000000 (2624.8 examples/sec)
=> 2021-11-02 11:55:19.865687: step 303500, loss = 0.026439, learning_rate = 0.000000 (2635.6 examples/sec)
=> 2021-11-02 11:55:39.564149: step 303600, loss = 0.040993, learning_rate = 0.000000 (2621.3 examples/sec)
=> 2021-11-02 11:55:59.290133: step 303700, loss = 0.030969, learning_rate = 0.000000 (2618.1 examples/sec)
=> 2021-11-02 11:56:19.030483: step 303800, loss = 0.023051, learning_rate = 0.000000 (2616.0 examples/sec)
=> 2021-11-02 11:56:39.961733: step 303900, loss = 0.034541, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 11:56:59.695851: step 304000, loss = 0.050958, learning_rate = 0.000000 (2617.1 examples/sec)
=> Model saved to file: ./logs/model-304000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950413, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 11:57:31.149342: step 304100, loss = 0.052117, learning_rate = 0.000000 (2625.2 examples/sec)
=> 2021-11-02 11:57:50.881063: step 304200, loss = 0.025783, learning_rate = 0.000000 (2616.9 examples/sec)
=> 2021-11-02 11:58:11.691983: step 304300, loss = 0.025589, learning_rate = 0.000000 (2634.5 examples/sec)
=> 2021-11-02 11:58:31.429343: step 304400, loss = 0.015372, learning_rate = 0.000000 (2617.0 examples/sec)
=> 2021-11-02 11:58:51.161883: step 304500, loss = 0.046492, learning_rate = 0.000000 (2617.3 examples/sec)
=> 2021-11-02 11:59:10.930163: step 304600, loss = 0.034511, learning_rate = 0.000000 (2613.0 examples/sec)
=> 2021-11-02 11:59:30.702899: step 304700, loss = 0.017543, learning_rate = 0.000000 (2612.9 examples/sec)
=> 2021-11-02 11:59:51.460528: step 304800, loss = 0.047143, learning_rate = 0.000000 (2623.7 examples/sec)
=> 2021-11-02 12:00:11.226376: step 304900, loss = 0.037525, learning_rate = 0.000000 (2613.3 examples/sec)
=> 2021-11-02 12:00:30.982047: step 305000, loss = 0.039411, learning_rate = 0.000000 (2614.4 examples/sec)
=> Model saved to file: ./logs/model-305000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951638, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 12:01:02.715842: step 305100, loss = 0.033643, learning_rate = 0.000000 (2619.6 examples/sec)
=> 2021-11-02 12:01:23.637724: step 305200, loss = 0.014761, learning_rate = 0.000000 (2638.9 examples/sec)
=> 2021-11-02 12:01:43.312002: step 305300, loss = 0.017869, learning_rate = 0.000000 (2625.1 examples/sec)
=> 2021-11-02 12:02:03.021442: step 305400, loss = 0.035584, learning_rate = 0.000000 (2620.6 examples/sec)
=> 2021-11-02 12:02:22.730487: step 305500, loss = 0.015701, learning_rate = 0.000000 (2620.7 examples/sec)
=> 2021-11-02 12:02:43.537385: step 305600, loss = 0.026043, learning_rate = 0.000000 (2628.1 examples/sec)
=> 2021-11-02 12:03:03.237573: step 305700, loss = 0.028650, learning_rate = 0.000000 (2621.9 examples/sec)
=> 2021-11-02 12:03:22.940088: step 305800, loss = 0.020454, learning_rate = 0.000000 (2621.5 examples/sec)
=> 2021-11-02 12:03:42.651456: step 305900, loss = 0.045062, learning_rate = 0.000000 (2620.2 examples/sec)
=> 2021-11-02 12:04:03.431021: step 306000, loss = 0.047639, learning_rate = 0.000000 (2628.0 examples/sec)
=> Model saved to file: ./logs/model-306000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951638, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 12:04:35.283961: step 306100, loss = 0.017577, learning_rate = 0.000000 (2622.7 examples/sec)
=> 2021-11-02 12:04:54.986980: step 306200, loss = 0.039324, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-02 12:05:14.704441: step 306300, loss = 0.033233, learning_rate = 0.000000 (2619.5 examples/sec)
=> 2021-11-02 12:05:35.506654: step 306400, loss = 0.057254, learning_rate = 0.000000 (2630.4 examples/sec)
=> 2021-11-02 12:05:55.230999: step 306500, loss = 0.036073, learning_rate = 0.000000 (2618.7 examples/sec)
=> 2021-11-02 12:06:14.972928: step 306600, loss = 0.041206, learning_rate = 0.000000 (2616.2 examples/sec)
=> 2021-11-02 12:06:34.749928: step 306700, loss = 0.021391, learning_rate = 0.000000 (2611.5 examples/sec)
=> 2021-11-02 12:06:55.515151: step 306800, loss = 0.036829, learning_rate = 0.000000 (2624.1 examples/sec)
=> 2021-11-02 12:07:15.274018: step 306900, loss = 0.019135, learning_rate = 0.000000 (2613.9 examples/sec)
=> 2021-11-02 12:07:35.056640: step 307000, loss = 0.058825, learning_rate = 0.000000 (2610.8 examples/sec)
=> Model saved to file: ./logs/model-307000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.946434, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 12:08:06.786205: step 307100, loss = 0.035381, learning_rate = 0.000000 (2619.1 examples/sec)
=> 2021-11-02 12:08:27.556996: step 307200, loss = 0.028412, learning_rate = 0.000000 (2636.3 examples/sec)
=> 2021-11-02 12:08:47.271696: step 307300, loss = 0.010777, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 12:09:06.985104: step 307400, loss = 0.027267, learning_rate = 0.000000 (2619.9 examples/sec)
=> 2021-11-02 12:09:26.723444: step 307500, loss = 0.032186, learning_rate = 0.000000 (2616.8 examples/sec)
=> 2021-11-02 12:09:46.516705: step 307600, loss = 0.050302, learning_rate = 0.000000 (2610.0 examples/sec)
=> 2021-11-02 12:10:07.320111: step 307700, loss = 0.018175, learning_rate = 0.000000 (2625.9 examples/sec)
=> 2021-11-02 12:10:27.042373: step 307800, loss = 0.024187, learning_rate = 0.000000 (2619.0 examples/sec)
=> 2021-11-02 12:10:46.774381: step 307900, loss = 0.024566, learning_rate = 0.000000 (2617.6 examples/sec)
=> 2021-11-02 12:11:06.503507: step 308000, loss = 0.046147, learning_rate = 0.000000 (2618.0 examples/sec)
=> Model saved to file: ./logs/model-308000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953780, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 12:11:39.159276: step 308100, loss = 0.039133, learning_rate = 0.000000 (2636.8 examples/sec)
=> 2021-11-02 12:11:58.854521: step 308200, loss = 0.030636, learning_rate = 0.000000 (2622.4 examples/sec)
=> 2021-11-02 12:12:18.564451: step 308300, loss = 0.017585, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-02 12:12:38.311562: step 308400, loss = 0.022785, learning_rate = 0.000000 (2615.5 examples/sec)
=> 2021-11-02 12:12:59.158272: step 308500, loss = 0.020083, learning_rate = 0.000000 (2624.0 examples/sec)
=> 2021-11-02 12:13:18.936871: step 308600, loss = 0.034015, learning_rate = 0.000000 (2611.1 examples/sec)
=> 2021-11-02 12:13:38.710745: step 308700, loss = 0.020936, learning_rate = 0.000000 (2611.8 examples/sec)
=> 2021-11-02 12:13:58.483998: step 308800, loss = 0.032442, learning_rate = 0.000000 (2612.0 examples/sec)
=> 2021-11-02 12:14:19.289727: step 308900, loss = 0.047505, learning_rate = 0.000000 (2622.8 examples/sec)
=> 2021-11-02 12:14:39.082663: step 309000, loss = 0.019491, learning_rate = 0.000000 (2609.2 examples/sec)
=> Model saved to file: ./logs/model-309000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951944, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 12:15:10.745699: step 309100, loss = 0.020591, learning_rate = 0.000000 (2620.5 examples/sec)
=> 2021-11-02 12:15:30.421990: step 309200, loss = 0.052068, learning_rate = 0.000000 (2624.8 examples/sec)
=> 2021-11-02 12:15:51.185724: step 309300, loss = 0.036153, learning_rate = 0.000000 (2639.6 examples/sec)
=> 2021-11-02 12:16:10.915519: step 309400, loss = 0.033167, learning_rate = 0.000000 (2618.1 examples/sec)
=> 2021-11-02 12:16:30.680496: step 309500, loss = 0.023283, learning_rate = 0.000000 (2613.1 examples/sec)
=> 2021-11-02 12:16:50.436482: step 309600, loss = 0.036108, learning_rate = 0.000000 (2614.2 examples/sec)
=> 2021-11-02 12:17:11.376948: step 309700, loss = 0.024964, learning_rate = 0.000000 (2620.2 examples/sec)
=> 2021-11-02 12:17:31.170626: step 309800, loss = 0.021950, learning_rate = 0.000000 (2609.4 examples/sec)
=> 2021-11-02 12:17:50.940436: step 309900, loss = 0.036077, learning_rate = 0.000000 (2612.5 examples/sec)
=> 2021-11-02 12:18:10.721825: step 310000, loss = 0.084004, learning_rate = 0.000000 (2611.1 examples/sec)
=> Model saved to file: ./logs/model-310000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950184, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 12:18:43.481498: step 310100, loss = 0.016589, learning_rate = 0.000000 (2636.8 examples/sec)
=> 2021-11-02 12:19:03.207879: step 310200, loss = 0.027636, learning_rate = 0.000000 (2618.4 examples/sec)
=> 2021-11-02 12:19:22.972899: step 310300, loss = 0.025152, learning_rate = 0.000000 (2613.3 examples/sec)
=> 2021-11-02 12:19:42.747952: step 310400, loss = 0.025577, learning_rate = 0.000000 (2611.7 examples/sec)
=> 2021-11-02 12:20:02.513614: step 310500, loss = 0.045880, learning_rate = 0.000000 (2613.3 examples/sec)
=> 2021-11-02 12:20:23.406951: step 310600, loss = 0.035299, learning_rate = 0.000000 (2609.0 examples/sec)
=> 2021-11-02 12:20:43.187943: step 310700, loss = 0.024032, learning_rate = 0.000000 (2612.0 examples/sec)
=> 2021-11-02 12:21:02.989241: step 310800, loss = 0.032911, learning_rate = 0.000000 (2609.3 examples/sec)
=> 2021-11-02 12:21:22.787120: step 310900, loss = 0.027655, learning_rate = 0.000000 (2608.8 examples/sec)
=> 2021-11-02 12:21:43.754912: step 311000, loss = 0.044280, learning_rate = 0.000000 (2621.9 examples/sec)
=> Model saved to file: ./logs/model-311000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950107, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 12:22:15.412804: step 311100, loss = 0.010880, learning_rate = 0.000000 (2621.4 examples/sec)
=> 2021-11-02 12:22:35.095531: step 311200, loss = 0.047301, learning_rate = 0.000000 (2624.2 examples/sec)
=> 2021-11-02 12:22:54.795504: step 311300, loss = 0.026179, learning_rate = 0.000000 (2621.8 examples/sec)
=> 2021-11-02 12:23:15.531622: step 311400, loss = 0.039974, learning_rate = 0.000000 (2635.3 examples/sec)
=> 2021-11-02 12:23:35.286245: step 311500, loss = 0.030442, learning_rate = 0.000000 (2614.2 examples/sec)
=> 2021-11-02 12:23:55.072312: step 311600, loss = 0.028048, learning_rate = 0.000000 (2610.2 examples/sec)
=> 2021-11-02 12:24:14.865065: step 311700, loss = 0.020022, learning_rate = 0.000000 (2609.5 examples/sec)
=> 2021-11-02 12:24:35.649082: step 311800, loss = 0.033948, learning_rate = 0.000000 (2624.1 examples/sec)
=> 2021-11-02 12:24:55.439905: step 311900, loss = 0.029529, learning_rate = 0.000000 (2609.8 examples/sec)
=> 2021-11-02 12:25:15.226400: step 312000, loss = 0.018099, learning_rate = 0.000000 (2610.1 examples/sec)
=> Model saved to file: ./logs/model-312000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951331, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 12:25:46.942128: step 312100, loss = 0.048734, learning_rate = 0.000000 (2613.5 examples/sec)
=> 2021-11-02 12:26:07.781971: step 312200, loss = 0.012129, learning_rate = 0.000000 (2628.2 examples/sec)
=> 2021-11-02 12:26:27.494255: step 312300, loss = 0.044702, learning_rate = 0.000000 (2620.3 examples/sec)
=> 2021-11-02 12:26:47.204052: step 312400, loss = 0.055092, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-02 12:27:07.007951: step 312500, loss = 0.013679, learning_rate = 0.000000 (2608.0 examples/sec)
=> 2021-11-02 12:27:27.804738: step 312600, loss = 0.023569, learning_rate = 0.000000 (2626.4 examples/sec)
=> 2021-11-02 12:27:47.580789: step 312700, loss = 0.042670, learning_rate = 0.000000 (2611.7 examples/sec)
=> 2021-11-02 12:28:07.351889: step 312800, loss = 0.019741, learning_rate = 0.000000 (2612.7 examples/sec)
=> 2021-11-02 12:28:27.135798: step 312900, loss = 0.060781, learning_rate = 0.000000 (2610.5 examples/sec)
=> 2021-11-02 12:28:47.941953: step 313000, loss = 0.039084, learning_rate = 0.000000 (2623.3 examples/sec)
=> Model saved to file: ./logs/model-313000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949495, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 12:29:19.706952: step 313100, loss = 0.041438, learning_rate = 0.000000 (2619.6 examples/sec)
=> 2021-11-02 12:29:39.470005: step 313200, loss = 0.023897, learning_rate = 0.000000 (2613.2 examples/sec)
=> 2021-11-02 12:29:59.226889: step 313300, loss = 0.039151, learning_rate = 0.000000 (2614.1 examples/sec)
=> 2021-11-02 12:30:20.003470: step 313400, loss = 0.025661, learning_rate = 0.000000 (2628.8 examples/sec)
=> 2021-11-02 12:30:39.785661: step 313500, loss = 0.050305, learning_rate = 0.000000 (2610.8 examples/sec)
=> 2021-11-02 12:30:59.565938: step 313600, loss = 0.062438, learning_rate = 0.000000 (2611.3 examples/sec)
=> 2021-11-02 12:31:19.363743: step 313700, loss = 0.050214, learning_rate = 0.000000 (2608.9 examples/sec)
=> 2021-11-02 12:31:39.162420: step 313800, loss = 0.029528, learning_rate = 0.000000 (2608.6 examples/sec)
=> 2021-11-02 12:31:59.962123: step 313900, loss = 0.059216, learning_rate = 0.000000 (2624.3 examples/sec)
=> 2021-11-02 12:32:19.746818: step 314000, loss = 0.019033, learning_rate = 0.000000 (2610.5 examples/sec)
=> Model saved to file: ./logs/model-314000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951714, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 12:32:51.590448: step 314100, loss = 0.014543, learning_rate = 0.000000 (2623.9 examples/sec)
=> 2021-11-02 12:33:11.281343: step 314200, loss = 0.018387, learning_rate = 0.000000 (2623.0 examples/sec)
=> 2021-11-02 12:33:32.007338: step 314300, loss = 0.046819, learning_rate = 0.000000 (2630.1 examples/sec)
=> 2021-11-02 12:33:51.739530: step 314400, loss = 0.031596, learning_rate = 0.000000 (2617.4 examples/sec)
=> 2021-11-02 12:34:11.510046: step 314500, loss = 0.030151, learning_rate = 0.000000 (2612.5 examples/sec)
=> 2021-11-02 12:34:31.295295: step 314600, loss = 0.038204, learning_rate = 0.000000 (2610.5 examples/sec)
=> 2021-11-02 12:34:52.079920: step 314700, loss = 0.023417, learning_rate = 0.000000 (2622.5 examples/sec)
=> 2021-11-02 12:35:11.870314: step 314800, loss = 0.013811, learning_rate = 0.000000 (2610.3 examples/sec)
=> 2021-11-02 12:35:31.668994: step 314900, loss = 0.030018, learning_rate = 0.000000 (2608.5 examples/sec)
=> 2021-11-02 12:35:51.453489: step 315000, loss = 0.023526, learning_rate = 0.000000 (2610.7 examples/sec)
=> Model saved to file: ./logs/model-315000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953704, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 12:36:24.082864: step 315100, loss = 0.024917, learning_rate = 0.000000 (2629.2 examples/sec)
=> 2021-11-02 12:36:43.805637: step 315200, loss = 0.028792, learning_rate = 0.000000 (2618.8 examples/sec)
=> 2021-11-02 12:37:03.543508: step 315300, loss = 0.072765, learning_rate = 0.000000 (2616.6 examples/sec)
=> 2021-11-02 12:37:23.290433: step 315400, loss = 0.012299, learning_rate = 0.000000 (2615.6 examples/sec)
=> 2021-11-02 12:37:43.946280: step 315500, loss = 0.013250, learning_rate = 0.000000 (2632.6 examples/sec)
=> 2021-11-02 12:38:03.686118: step 315600, loss = 0.040799, learning_rate = 0.000000 (2615.7 examples/sec)
=> 2021-11-02 12:38:23.425288: step 315700, loss = 0.022473, learning_rate = 0.000000 (2615.8 examples/sec)
=> 2021-11-02 12:38:43.196813: step 315800, loss = 0.032229, learning_rate = 0.000000 (2611.7 examples/sec)
=> 2021-11-02 12:39:03.875219: step 315900, loss = 0.012876, learning_rate = 0.000000 (2628.6 examples/sec)
=> 2021-11-02 12:39:23.641576: step 316000, loss = 0.060437, learning_rate = 0.000000 (2612.2 examples/sec)
=> Model saved to file: ./logs/model-316000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952097, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 12:39:55.198722: step 316100, loss = 0.040232, learning_rate = 0.000000 (2612.8 examples/sec)
=> 2021-11-02 12:40:14.860045: step 316200, loss = 0.030589, learning_rate = 0.000000 (2626.2 examples/sec)
=> 2021-11-02 12:40:35.531336: step 316300, loss = 0.025007, learning_rate = 0.000000 (2644.3 examples/sec)
=> 2021-11-02 12:40:55.237808: step 316400, loss = 0.015220, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-02 12:41:14.964108: step 316500, loss = 0.023944, learning_rate = 0.000000 (2617.6 examples/sec)
=> 2021-11-02 12:41:34.672860: step 316600, loss = 0.022409, learning_rate = 0.000000 (2619.7 examples/sec)
=> 2021-11-02 12:41:54.404414: step 316700, loss = 0.015416, learning_rate = 0.000000 (2617.2 examples/sec)
=> 2021-11-02 12:42:15.186646: step 316800, loss = 0.023834, learning_rate = 0.000000 (2628.2 examples/sec)
=> 2021-11-02 12:42:34.915788: step 316900, loss = 0.029187, learning_rate = 0.000000 (2617.6 examples/sec)
=> 2021-11-02 12:42:54.678350: step 317000, loss = 0.050645, learning_rate = 0.000000 (2613.2 examples/sec)
=> Model saved to file: ./logs/model-317000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950566, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 12:43:26.280316: step 317100, loss = 0.023376, learning_rate = 0.000000 (2619.7 examples/sec)
=> 2021-11-02 12:43:46.876703: step 317200, loss = 0.029956, learning_rate = 0.000000 (2637.4 examples/sec)
=> 2021-11-02 12:44:06.594048: step 317300, loss = 0.033249, learning_rate = 0.000000 (2618.8 examples/sec)
=> 2021-11-02 12:44:26.340136: step 317400, loss = 0.019433, learning_rate = 0.000000 (2615.2 examples/sec)
=> 2021-11-02 12:44:46.083876: step 317500, loss = 0.038951, learning_rate = 0.000000 (2615.2 examples/sec)
=> 2021-11-02 12:45:07.082915: step 317600, loss = 0.021223, learning_rate = 0.000000 (2624.0 examples/sec)
=> 2021-11-02 12:45:26.853743: step 317700, loss = 0.055568, learning_rate = 0.000000 (2612.4 examples/sec)
=> 2021-11-02 12:45:46.606219: step 317800, loss = 0.040920, learning_rate = 0.000000 (2614.5 examples/sec)
=> 2021-11-02 12:46:06.371900: step 317900, loss = 0.028324, learning_rate = 0.000000 (2613.2 examples/sec)
=> 2021-11-02 12:46:27.107437: step 318000, loss = 0.053747, learning_rate = 0.000000 (2626.4 examples/sec)
=> Model saved to file: ./logs/model-318000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951791, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 12:46:58.589165: step 318100, loss = 0.026713, learning_rate = 0.000000 (2628.8 examples/sec)
=> 2021-11-02 12:47:18.241741: step 318200, loss = 0.042718, learning_rate = 0.000000 (2628.0 examples/sec)
=> 2021-11-02 12:47:37.918411: step 318300, loss = 0.010983, learning_rate = 0.000000 (2624.6 examples/sec)
=> 2021-11-02 12:47:58.529370: step 318400, loss = 0.015120, learning_rate = 0.000000 (2635.4 examples/sec)
=> 2021-11-02 12:48:18.268018: step 318500, loss = 0.020296, learning_rate = 0.000000 (2615.9 examples/sec)
=> 2021-11-02 12:48:38.023716: step 318600, loss = 0.028868, learning_rate = 0.000000 (2613.6 examples/sec)
=> 2021-11-02 12:48:57.764905: step 318700, loss = 0.033748, learning_rate = 0.000000 (2615.4 examples/sec)
=> 2021-11-02 12:49:18.624387: step 318800, loss = 0.033363, learning_rate = 0.000000 (2627.5 examples/sec)
=> 2021-11-02 12:49:38.379959: step 318900, loss = 0.045935, learning_rate = 0.000000 (2613.7 examples/sec)
=> 2021-11-02 12:49:58.139825: step 319000, loss = 0.018656, learning_rate = 0.000000 (2613.0 examples/sec)
=> Model saved to file: ./logs/model-319000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952250, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 12:50:29.695103: step 319100, loss = 0.026828, learning_rate = 0.000000 (2623.0 examples/sec)
=> 2021-11-02 12:50:50.293938: step 319200, loss = 0.043865, learning_rate = 0.000000 (2637.7 examples/sec)
=> 2021-11-02 12:51:10.009917: step 319300, loss = 0.031193, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 12:51:29.726911: step 319400, loss = 0.032532, learning_rate = 0.000000 (2619.0 examples/sec)
=> 2021-11-02 12:51:49.460899: step 319500, loss = 0.035755, learning_rate = 0.000000 (2616.6 examples/sec)
=> 2021-11-02 12:52:09.205689: step 319600, loss = 0.034489, learning_rate = 0.000000 (2615.9 examples/sec)
=> 2021-11-02 12:52:29.858908: step 319700, loss = 0.021695, learning_rate = 0.000000 (2630.7 examples/sec)
=> 2021-11-02 12:52:49.642336: step 319800, loss = 0.031717, learning_rate = 0.000000 (2610.0 examples/sec)
=> 2021-11-02 12:53:09.407314: step 319900, loss = 0.026620, learning_rate = 0.000000 (2612.7 examples/sec)
=> 2021-11-02 12:53:29.176551: step 320000, loss = 0.061506, learning_rate = 0.000000 (2612.1 examples/sec)
=> Model saved to file: ./logs/model-320000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951025, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 12:54:01.555921: step 320100, loss = 0.026924, learning_rate = 0.000000 (2634.4 examples/sec)
=> 2021-11-02 12:54:21.230135: step 320200, loss = 0.037868, learning_rate = 0.000000 (2624.7 examples/sec)
=> 2021-11-02 12:54:40.943250: step 320300, loss = 0.038028, learning_rate = 0.000000 (2619.1 examples/sec)
=> 2021-11-02 12:55:00.670283: step 320400, loss = 0.033566, learning_rate = 0.000000 (2617.8 examples/sec)
=> 2021-11-02 12:55:21.358896: step 320500, loss = 0.017730, learning_rate = 0.000000 (2632.3 examples/sec)
=> 2021-11-02 12:55:41.117584: step 320600, loss = 0.020421, learning_rate = 0.000000 (2613.1 examples/sec)
=> 2021-11-02 12:56:00.892717: step 320700, loss = 0.029351, learning_rate = 0.000000 (2611.1 examples/sec)
=> 2021-11-02 12:56:20.667898: step 320800, loss = 0.011841, learning_rate = 0.000000 (2611.0 examples/sec)
=> 2021-11-02 12:56:41.317263: step 320900, loss = 0.017097, learning_rate = 0.000000 (2630.6 examples/sec)
=> 2021-11-02 12:57:01.141402: step 321000, loss = 0.015027, learning_rate = 0.000000 (2604.6 examples/sec)
=> Model saved to file: ./logs/model-321000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951638, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 12:57:32.646401: step 321100, loss = 0.012264, learning_rate = 0.000000 (2619.1 examples/sec)
=> 2021-11-02 12:57:52.366902: step 321200, loss = 0.094802, learning_rate = 0.000000 (2618.3 examples/sec)
=> 2021-11-02 12:58:13.024454: step 321300, loss = 0.047820, learning_rate = 0.000000 (2635.4 examples/sec)
=> 2021-11-02 12:58:32.747029: step 321400, loss = 0.050041, learning_rate = 0.000000 (2618.2 examples/sec)
=> 2021-11-02 12:58:52.486349: step 321500, loss = 0.019328, learning_rate = 0.000000 (2615.9 examples/sec)
=> 2021-11-02 12:59:12.241069: step 321600, loss = 0.030474, learning_rate = 0.000000 (2614.3 examples/sec)
=> 2021-11-02 12:59:32.922867: step 321700, loss = 0.042917, learning_rate = 0.000000 (2626.1 examples/sec)
=> 2021-11-02 12:59:52.692051: step 321800, loss = 0.028791, learning_rate = 0.000000 (2612.1 examples/sec)
=> 2021-11-02 13:00:12.471494: step 321900, loss = 0.049208, learning_rate = 0.000000 (2610.6 examples/sec)
=> 2021-11-02 13:00:32.241210: step 322000, loss = 0.037160, learning_rate = 0.000000 (2611.8 examples/sec)
=> Model saved to file: ./logs/model-322000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950566, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 13:01:04.798979: step 322100, loss = 0.047384, learning_rate = 0.000000 (2626.7 examples/sec)
=> 2021-11-02 13:01:24.492654: step 322200, loss = 0.029300, learning_rate = 0.000000 (2621.9 examples/sec)
=> 2021-11-02 13:01:44.216142: step 322300, loss = 0.050010, learning_rate = 0.000000 (2617.8 examples/sec)
=> 2021-11-02 13:02:03.949418: step 322400, loss = 0.023230, learning_rate = 0.000000 (2616.5 examples/sec)
=> 2021-11-02 13:02:23.699857: step 322500, loss = 0.027114, learning_rate = 0.000000 (2615.3 examples/sec)
=> 2021-11-02 13:02:44.372767: step 322600, loss = 0.028521, learning_rate = 0.000000 (2629.3 examples/sec)
=> 2021-11-02 13:03:04.121815: step 322700, loss = 0.038738, learning_rate = 0.000000 (2614.7 examples/sec)
=> 2021-11-02 13:03:23.896079: step 322800, loss = 0.015064, learning_rate = 0.000000 (2611.2 examples/sec)
=> 2021-11-02 13:03:43.667917: step 322900, loss = 0.015540, learning_rate = 0.000000 (2612.1 examples/sec)
=> 2021-11-02 13:04:04.434686: step 323000, loss = 0.053344, learning_rate = 0.000000 (2630.1 examples/sec)
=> Model saved to file: ./logs/model-323000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952785, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 13:04:35.787447: step 323100, loss = 0.034406, learning_rate = 0.000000 (2624.0 examples/sec)
=> 2021-11-02 13:04:55.445259: step 323200, loss = 0.034473, learning_rate = 0.000000 (2626.6 examples/sec)
=> 2021-11-02 13:05:15.145529: step 323300, loss = 0.032241, learning_rate = 0.000000 (2621.0 examples/sec)
=> 2021-11-02 13:05:35.817801: step 323400, loss = 0.022872, learning_rate = 0.000000 (2636.3 examples/sec)
=> 2021-11-02 13:05:55.527835: step 323500, loss = 0.019685, learning_rate = 0.000000 (2619.7 examples/sec)
=> 2021-11-02 13:06:15.261461: step 323600, loss = 0.038094, learning_rate = 0.000000 (2616.8 examples/sec)
=> 2021-11-02 13:06:35.035396: step 323700, loss = 0.034633, learning_rate = 0.000000 (2611.3 examples/sec)
=> 2021-11-02 13:06:55.889492: step 323800, loss = 0.047827, learning_rate = 0.000000 (2635.3 examples/sec)
=> 2021-11-02 13:07:15.648413: step 323900, loss = 0.057759, learning_rate = 0.000000 (2613.1 examples/sec)
=> 2021-11-02 13:07:35.405581: step 324000, loss = 0.029500, learning_rate = 0.000000 (2613.4 examples/sec)
=> Model saved to file: ./logs/model-324000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952326, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 13:08:07.066228: step 324100, loss = 0.038769, learning_rate = 0.000000 (2623.6 examples/sec)
=> 2021-11-02 13:08:27.854476: step 324200, loss = 0.026383, learning_rate = 0.000000 (2638.5 examples/sec)
=> 2021-11-02 13:08:47.568978: step 324300, loss = 0.021151, learning_rate = 0.000000 (2619.1 examples/sec)
=> 2021-11-02 13:09:07.322092: step 324400, loss = 0.042194, learning_rate = 0.000000 (2613.9 examples/sec)
=> 2021-11-02 13:09:27.088740: step 324500, loss = 0.030000, learning_rate = 0.000000 (2612.1 examples/sec)
=> 2021-11-02 13:09:47.867106: step 324600, loss = 0.013529, learning_rate = 0.000000 (2631.1 examples/sec)
=> 2021-11-02 13:10:07.678552: step 324700, loss = 0.058369, learning_rate = 0.000000 (2606.1 examples/sec)
=> 2021-11-02 13:10:27.445398: step 324800, loss = 0.041916, learning_rate = 0.000000 (2612.0 examples/sec)
=> 2021-11-02 13:10:47.208924: step 324900, loss = 0.041644, learning_rate = 0.000000 (2612.4 examples/sec)
=> 2021-11-02 13:11:07.993378: step 325000, loss = 0.014172, learning_rate = 0.000000 (2626.7 examples/sec)
=> Model saved to file: ./logs/model-325000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952173, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 13:11:39.501037: step 325100, loss = 0.021109, learning_rate = 0.000000 (2622.1 examples/sec)
=> 2021-11-02 13:11:59.186145: step 325200, loss = 0.021505, learning_rate = 0.000000 (2623.1 examples/sec)
=> 2021-11-02 13:12:18.908199: step 325300, loss = 0.026534, learning_rate = 0.000000 (2618.2 examples/sec)
=> 2021-11-02 13:12:38.649522: step 325400, loss = 0.020875, learning_rate = 0.000000 (2615.9 examples/sec)
=> 2021-11-02 13:12:59.474031: step 325500, loss = 0.035676, learning_rate = 0.000000 (2629.1 examples/sec)
=> 2021-11-02 13:13:19.236603: step 325600, loss = 0.031202, learning_rate = 0.000000 (2612.9 examples/sec)
=> 2021-11-02 13:13:39.013305: step 325700, loss = 0.032816, learning_rate = 0.000000 (2610.9 examples/sec)
=> 2021-11-02 13:13:58.786496: step 325800, loss = 0.038575, learning_rate = 0.000000 (2611.5 examples/sec)
=> 2021-11-02 13:14:19.535347: step 325900, loss = 0.028939, learning_rate = 0.000000 (2630.4 examples/sec)
=> 2021-11-02 13:14:39.323748: step 326000, loss = 0.092537, learning_rate = 0.000000 (2609.3 examples/sec)
=> Model saved to file: ./logs/model-326000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947429, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 13:15:10.670205: step 326100, loss = 0.021917, learning_rate = 0.000000 (2617.2 examples/sec)
=> 2021-11-02 13:15:30.363713: step 326200, loss = 0.017801, learning_rate = 0.000000 (2621.8 examples/sec)
=> 2021-11-02 13:15:50.980318: step 326300, loss = 0.020365, learning_rate = 0.000000 (2635.8 examples/sec)
=> 2021-11-02 13:16:10.695256: step 326400, loss = 0.059348, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 13:16:30.399866: step 326500, loss = 0.039184, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-02 13:16:50.123927: step 326600, loss = 0.024401, learning_rate = 0.000000 (2617.7 examples/sec)
=> 2021-11-02 13:17:10.780447: step 326700, loss = 0.045160, learning_rate = 0.000000 (2628.7 examples/sec)
=> 2021-11-02 13:17:30.513975: step 326800, loss = 0.025524, learning_rate = 0.000000 (2616.8 examples/sec)
=> 2021-11-02 13:17:50.213956: step 326900, loss = 0.018100, learning_rate = 0.000000 (2620.9 examples/sec)
=> 2021-11-02 13:18:09.926931: step 327000, loss = 0.050645, learning_rate = 0.000000 (2619.4 examples/sec)
=> Model saved to file: ./logs/model-327000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.947811, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 13:18:42.301199: step 327100, loss = 0.018631, learning_rate = 0.000000 (2639.2 examples/sec)
=> 2021-11-02 13:19:01.962904: step 327200, loss = 0.048110, learning_rate = 0.000000 (2626.3 examples/sec)
=> 2021-11-02 13:19:21.654092: step 327300, loss = 0.031215, learning_rate = 0.000000 (2622.3 examples/sec)
=> 2021-11-02 13:19:41.363036: step 327400, loss = 0.051177, learning_rate = 0.000000 (2619.8 examples/sec)
=> 2021-11-02 13:20:02.012322: step 327500, loss = 0.046399, learning_rate = 0.000000 (2631.7 examples/sec)
=> 2021-11-02 13:20:21.749243: step 327600, loss = 0.065170, learning_rate = 0.000000 (2616.0 examples/sec)
=> 2021-11-02 13:20:41.496850: step 327700, loss = 0.052763, learning_rate = 0.000000 (2614.7 examples/sec)
=> 2021-11-02 13:21:01.256641: step 327800, loss = 0.023695, learning_rate = 0.000000 (2613.0 examples/sec)
=> 2021-11-02 13:21:22.080329: step 327900, loss = 0.039146, learning_rate = 0.000000 (2628.1 examples/sec)
=> 2021-11-02 13:21:41.845545: step 328000, loss = 0.046328, learning_rate = 0.000000 (2612.3 examples/sec)
=> Model saved to file: ./logs/model-328000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950184, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 13:22:13.232163: step 328100, loss = 0.028651, learning_rate = 0.000000 (2620.6 examples/sec)
=> 2021-11-02 13:22:32.915544: step 328200, loss = 0.023739, learning_rate = 0.000000 (2623.1 examples/sec)
=> 2021-11-02 13:22:52.730190: step 328300, loss = 0.008116, learning_rate = 0.000000 (2605.5 examples/sec)
=> 2021-11-02 13:23:13.367406: step 328400, loss = 0.013983, learning_rate = 0.000000 (2633.7 examples/sec)
=> 2021-11-02 13:23:33.085681: step 328500, loss = 0.042134, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 13:23:52.815782: step 328600, loss = 0.040655, learning_rate = 0.000000 (2617.0 examples/sec)
=> 2021-11-02 13:24:12.571587: step 328700, loss = 0.033016, learning_rate = 0.000000 (2613.8 examples/sec)
=> 2021-11-02 13:24:33.312981: step 328800, loss = 0.024228, learning_rate = 0.000000 (2620.8 examples/sec)
=> 2021-11-02 13:24:53.074039: step 328900, loss = 0.046910, learning_rate = 0.000000 (2612.9 examples/sec)
=> 2021-11-02 13:25:12.841974: step 329000, loss = 0.042307, learning_rate = 0.000000 (2612.1 examples/sec)
=> Model saved to file: ./logs/model-329000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951714, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 13:25:44.408902: step 329100, loss = 0.048392, learning_rate = 0.000000 (2616.2 examples/sec)
=> 2021-11-02 13:26:05.208240: step 329200, loss = 0.031928, learning_rate = 0.000000 (2622.4 examples/sec)
=> 2021-11-02 13:26:24.979518: step 329300, loss = 0.020969, learning_rate = 0.000000 (2612.4 examples/sec)
=> 2021-11-02 13:26:44.735236: step 329400, loss = 0.045044, learning_rate = 0.000000 (2614.4 examples/sec)
=> 2021-11-02 13:27:04.482411: step 329500, loss = 0.032501, learning_rate = 0.000000 (2614.6 examples/sec)
=> 2021-11-02 13:27:25.619387: step 329600, loss = 0.044699, learning_rate = 0.000000 (2622.7 examples/sec)
=> 2021-11-02 13:27:45.377587: step 329700, loss = 0.024570, learning_rate = 0.000000 (2613.6 examples/sec)
=> 2021-11-02 13:28:05.135713: step 329800, loss = 0.010312, learning_rate = 0.000000 (2613.3 examples/sec)
=> 2021-11-02 13:28:24.888894: step 329900, loss = 0.035228, learning_rate = 0.000000 (2613.9 examples/sec)
=> 2021-11-02 13:28:45.703401: step 330000, loss = 0.022098, learning_rate = 0.000000 (2625.9 examples/sec)
=> Model saved to file: ./logs/model-330000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953092, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 13:29:17.082771: step 330100, loss = 0.038271, learning_rate = 0.000000 (2626.7 examples/sec)
=> 2021-11-02 13:29:36.730131: step 330200, loss = 0.035791, learning_rate = 0.000000 (2627.9 examples/sec)
=> 2021-11-02 13:29:56.391824: step 330300, loss = 0.044185, learning_rate = 0.000000 (2626.0 examples/sec)
=> 2021-11-02 13:30:17.147036: step 330400, loss = 0.027008, learning_rate = 0.000000 (2635.2 examples/sec)
=> 2021-11-02 13:30:36.879515: step 330500, loss = 0.032282, learning_rate = 0.000000 (2616.7 examples/sec)
=> 2021-11-02 13:30:56.579116: step 330600, loss = 0.026080, learning_rate = 0.000000 (2621.1 examples/sec)
=> 2021-11-02 13:31:16.308026: step 330700, loss = 0.037300, learning_rate = 0.000000 (2617.3 examples/sec)
=> 2021-11-02 13:31:36.980842: step 330800, loss = 0.042971, learning_rate = 0.000000 (2630.5 examples/sec)
=> 2021-11-02 13:31:56.713690: step 330900, loss = 0.022690, learning_rate = 0.000000 (2616.5 examples/sec)
=> 2021-11-02 13:32:16.471376: step 331000, loss = 0.017378, learning_rate = 0.000000 (2613.4 examples/sec)
=> Model saved to file: ./logs/model-331000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951331, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 13:32:48.083710: step 331100, loss = 0.029570, learning_rate = 0.000000 (2622.1 examples/sec)
=> 2021-11-02 13:33:07.736847: step 331200, loss = 0.023904, learning_rate = 0.000000 (2627.8 examples/sec)
=> 2021-11-02 13:33:28.500680: step 331300, loss = 0.039405, learning_rate = 0.000000 (2617.8 examples/sec)
=> 2021-11-02 13:33:48.228489: step 331400, loss = 0.023879, learning_rate = 0.000000 (2617.4 examples/sec)
=> 2021-11-02 13:34:07.964150: step 331500, loss = 0.020306, learning_rate = 0.000000 (2616.5 examples/sec)
=> 2021-11-02 13:34:27.698588: step 331600, loss = 0.039752, learning_rate = 0.000000 (2616.4 examples/sec)
=> 2021-11-02 13:34:48.500349: step 331700, loss = 0.027520, learning_rate = 0.000000 (2626.2 examples/sec)
=> 2021-11-02 13:35:08.251570: step 331800, loss = 0.042183, learning_rate = 0.000000 (2614.3 examples/sec)
=> 2021-11-02 13:35:28.017344: step 331900, loss = 0.035172, learning_rate = 0.000000 (2612.4 examples/sec)
=> 2021-11-02 13:35:47.834540: step 332000, loss = 0.020305, learning_rate = 0.000000 (2605.7 examples/sec)
=> Model saved to file: ./logs/model-332000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950031, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 13:36:20.388714: step 332100, loss = 0.030259, learning_rate = 0.000000 (2627.8 examples/sec)
=> 2021-11-02 13:36:40.126814: step 332200, loss = 0.017614, learning_rate = 0.000000 (2615.5 examples/sec)
=> 2021-11-02 13:36:59.969311: step 332300, loss = 0.018738, learning_rate = 0.000000 (2602.1 examples/sec)
=> 2021-11-02 13:37:19.734345: step 332400, loss = 0.030311, learning_rate = 0.000000 (2612.5 examples/sec)
=> 2021-11-02 13:37:40.438790: step 332500, loss = 0.015230, learning_rate = 0.000000 (2625.4 examples/sec)
=> 2021-11-02 13:38:00.227225: step 332600, loss = 0.018248, learning_rate = 0.000000 (2609.5 examples/sec)
=> 2021-11-02 13:38:20.002291: step 332700, loss = 0.010551, learning_rate = 0.000000 (2611.1 examples/sec)
=> 2021-11-02 13:38:39.834544: step 332800, loss = 0.038709, learning_rate = 0.000000 (2603.7 examples/sec)
=> 2021-11-02 13:39:00.619079: step 332900, loss = 0.035401, learning_rate = 0.000000 (2620.1 examples/sec)
=> 2021-11-02 13:39:20.447647: step 333000, loss = 0.016220, learning_rate = 0.000000 (2604.0 examples/sec)
=> Model saved to file: ./logs/model-333000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951102, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 13:39:51.911674: step 333100, loss = 0.026455, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 13:40:11.607401: step 333200, loss = 0.042512, learning_rate = 0.000000 (2621.8 examples/sec)
=> 2021-11-02 13:40:32.240466: step 333300, loss = 0.035208, learning_rate = 0.000000 (2635.5 examples/sec)
=> 2021-11-02 13:40:51.958419: step 333400, loss = 0.016369, learning_rate = 0.000000 (2618.6 examples/sec)
=> 2021-11-02 13:41:11.683103: step 333500, loss = 0.046368, learning_rate = 0.000000 (2617.8 examples/sec)
=> 2021-11-02 13:41:31.444786: step 333600, loss = 0.016899, learning_rate = 0.000000 (2612.9 examples/sec)
=> 2021-11-02 13:41:52.171992: step 333700, loss = 0.041798, learning_rate = 0.000000 (2624.3 examples/sec)
=> 2021-11-02 13:42:11.940596: step 333800, loss = 0.047692, learning_rate = 0.000000 (2612.2 examples/sec)
=> 2021-11-02 13:42:31.672127: step 333900, loss = 0.061547, learning_rate = 0.000000 (2616.9 examples/sec)
=> 2021-11-02 13:42:51.403357: step 334000, loss = 0.025068, learning_rate = 0.000000 (2616.9 examples/sec)
=> Model saved to file: ./logs/model-334000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952938, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 13:43:23.899500: step 334100, loss = 0.022583, learning_rate = 0.000000 (2635.5 examples/sec)
=> 2021-11-02 13:43:43.600471: step 334200, loss = 0.023613, learning_rate = 0.000000 (2620.8 examples/sec)
=> 2021-11-02 13:44:03.265584: step 334300, loss = 0.026453, learning_rate = 0.000000 (2625.8 examples/sec)
=> 2021-11-02 13:44:22.978519: step 334400, loss = 0.017583, learning_rate = 0.000000 (2619.5 examples/sec)
=> 2021-11-02 13:44:42.690355: step 334500, loss = 0.017941, learning_rate = 0.000000 (2619.4 examples/sec)
=> 2021-11-02 13:45:03.379652: step 334600, loss = 0.014170, learning_rate = 0.000000 (2629.8 examples/sec)
=> 2021-11-02 13:45:23.143172: step 334700, loss = 0.035407, learning_rate = 0.000000 (2612.7 examples/sec)
=> 2021-11-02 13:45:42.909111: step 334800, loss = 0.049540, learning_rate = 0.000000 (2612.3 examples/sec)
=> 2021-11-02 13:46:02.681110: step 334900, loss = 0.025213, learning_rate = 0.000000 (2611.5 examples/sec)
=> 2021-11-02 13:46:23.429759: step 335000, loss = 0.027859, learning_rate = 0.000000 (2618.4 examples/sec)
=> Model saved to file: ./logs/model-335000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951102, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 13:46:54.778954: step 335100, loss = 0.071045, learning_rate = 0.000000 (2615.3 examples/sec)
=> 2021-11-02 13:47:14.517668: step 335200, loss = 0.021804, learning_rate = 0.000000 (2615.9 examples/sec)
=> 2021-11-02 13:47:34.274520: step 335300, loss = 0.032882, learning_rate = 0.000000 (2613.6 examples/sec)
=> 2021-11-02 13:47:54.958289: step 335400, loss = 0.024408, learning_rate = 0.000000 (2628.2 examples/sec)
=> 2021-11-02 13:48:14.731685: step 335500, loss = 0.042737, learning_rate = 0.000000 (2611.2 examples/sec)
=> 2021-11-02 13:48:34.510587: step 335600, loss = 0.029333, learning_rate = 0.000000 (2610.6 examples/sec)
=> 2021-11-02 13:48:54.299581: step 335700, loss = 0.029498, learning_rate = 0.000000 (2609.3 examples/sec)
=> 2021-11-02 13:49:15.117114: step 335800, loss = 0.021938, learning_rate = 0.000000 (2624.6 examples/sec)
=> 2021-11-02 13:49:34.909213: step 335900, loss = 0.032452, learning_rate = 0.000000 (2608.8 examples/sec)
=> 2021-11-02 13:49:54.675980: step 336000, loss = 0.074628, learning_rate = 0.000000 (2612.0 examples/sec)
=> Model saved to file: ./logs/model-336000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949112, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 13:50:26.184430: step 336100, loss = 0.033140, learning_rate = 0.000000 (2617.1 examples/sec)
=> 2021-11-02 13:50:46.831301: step 336200, loss = 0.014692, learning_rate = 0.000000 (2630.4 examples/sec)
=> 2021-11-02 13:51:06.553811: step 336300, loss = 0.028892, learning_rate = 0.000000 (2618.1 examples/sec)
=> 2021-11-02 13:51:26.285228: step 336400, loss = 0.042816, learning_rate = 0.000000 (2617.1 examples/sec)
=> 2021-11-02 13:51:46.025089: step 336500, loss = 0.031370, learning_rate = 0.000000 (2615.7 examples/sec)
=> 2021-11-02 13:52:06.841478: step 336600, loss = 0.020606, learning_rate = 0.000000 (2623.6 examples/sec)
=> 2021-11-02 13:52:26.599123: step 336700, loss = 0.031734, learning_rate = 0.000000 (2613.4 examples/sec)
=> 2021-11-02 13:52:46.377375: step 336800, loss = 0.023868, learning_rate = 0.000000 (2610.8 examples/sec)
=> 2021-11-02 13:53:06.154214: step 336900, loss = 0.031320, learning_rate = 0.000000 (2611.0 examples/sec)
=> 2021-11-02 13:53:26.859925: step 337000, loss = 0.021197, learning_rate = 0.000000 (2623.4 examples/sec)
=> Model saved to file: ./logs/model-337000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953321, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 13:53:58.688613: step 337100, loss = 0.009710, learning_rate = 0.000000 (2597.5 examples/sec)
=> 2021-11-02 13:54:18.376254: step 337200, loss = 0.021421, learning_rate = 0.000000 (2622.9 examples/sec)
=> 2021-11-02 13:54:38.055848: step 337300, loss = 0.020613, learning_rate = 0.000000 (2623.8 examples/sec)
=> 2021-11-02 13:54:57.763942: step 337400, loss = 0.043331, learning_rate = 0.000000 (2620.1 examples/sec)
=> 2021-11-02 13:55:18.431187: step 337500, loss = 0.038445, learning_rate = 0.000000 (2629.7 examples/sec)
=> 2021-11-02 13:55:38.166494: step 337600, loss = 0.034014, learning_rate = 0.000000 (2616.2 examples/sec)
=> 2021-11-02 13:55:57.917446: step 337700, loss = 0.056474, learning_rate = 0.000000 (2614.4 examples/sec)
=> 2021-11-02 13:56:17.696279: step 337800, loss = 0.023179, learning_rate = 0.000000 (2610.6 examples/sec)
=> 2021-11-02 13:56:38.396802: step 337900, loss = 0.033162, learning_rate = 0.000000 (2626.4 examples/sec)
=> 2021-11-02 13:56:58.154792: step 338000, loss = 0.047110, learning_rate = 0.000000 (2613.5 examples/sec)
=> Model saved to file: ./logs/model-338000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951178, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 13:57:29.853460: step 338100, loss = 0.016158, learning_rate = 0.000000 (2619.9 examples/sec)
=> 2021-11-02 13:57:49.585760: step 338200, loss = 0.037902, learning_rate = 0.000000 (2616.9 examples/sec)
=> 2021-11-02 13:58:10.253922: step 338300, loss = 0.025430, learning_rate = 0.000000 (2629.7 examples/sec)
=> 2021-11-02 13:58:30.007253: step 338400, loss = 0.034017, learning_rate = 0.000000 (2614.0 examples/sec)
=> 2021-11-02 13:58:49.750715: step 338500, loss = 0.023429, learning_rate = 0.000000 (2615.2 examples/sec)
=> 2021-11-02 13:59:09.532437: step 338600, loss = 0.022039, learning_rate = 0.000000 (2610.2 examples/sec)
=> 2021-11-02 13:59:30.298369: step 338700, loss = 0.046733, learning_rate = 0.000000 (2617.6 examples/sec)
=> 2021-11-02 13:59:50.068738: step 338800, loss = 0.032126, learning_rate = 0.000000 (2611.5 examples/sec)
=> 2021-11-02 14:00:09.830121: step 338900, loss = 0.017660, learning_rate = 0.000000 (2612.9 examples/sec)
=> 2021-11-02 14:00:29.610166: step 339000, loss = 0.019455, learning_rate = 0.000000 (2610.5 examples/sec)
=> Model saved to file: ./logs/model-339000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950796, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 14:01:02.083497: step 339100, loss = 0.025171, learning_rate = 0.000000 (2631.6 examples/sec)
=> 2021-11-02 14:01:21.876731: step 339200, loss = 0.015491, learning_rate = 0.000000 (2609.0 examples/sec)
=> 2021-11-02 14:01:41.609161: step 339300, loss = 0.018376, learning_rate = 0.000000 (2616.7 examples/sec)
=> 2021-11-02 14:02:01.358051: step 339400, loss = 0.013110, learning_rate = 0.000000 (2614.6 examples/sec)
=> 2021-11-02 14:02:22.069033: step 339500, loss = 0.016511, learning_rate = 0.000000 (2625.6 examples/sec)
=> 2021-11-02 14:02:41.830072: step 339600, loss = 0.016586, learning_rate = 0.000000 (2613.0 examples/sec)
=> 2021-11-02 14:03:01.597916: step 339700, loss = 0.020198, learning_rate = 0.000000 (2612.1 examples/sec)
=> 2021-11-02 14:03:21.384832: step 339800, loss = 0.034571, learning_rate = 0.000000 (2609.5 examples/sec)
=> 2021-11-02 14:03:42.106813: step 339900, loss = 0.024574, learning_rate = 0.000000 (2627.1 examples/sec)
=> 2021-11-02 14:04:01.915052: step 340000, loss = 0.025807, learning_rate = 0.000000 (2606.8 examples/sec)
=> Model saved to file: ./logs/model-340000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953551, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 14:04:33.351593: step 340100, loss = 0.044500, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 14:04:53.023075: step 340200, loss = 0.026473, learning_rate = 0.000000 (2624.7 examples/sec)
=> 2021-11-02 14:05:12.725466: step 340300, loss = 0.055107, learning_rate = 0.000000 (2621.5 examples/sec)
=> 2021-11-02 14:05:33.407582: step 340400, loss = 0.022764, learning_rate = 0.000000 (2633.2 examples/sec)
=> 2021-11-02 14:05:53.411972: step 340500, loss = 0.090874, learning_rate = 0.000000 (2580.8 examples/sec)
=> 2021-11-02 14:06:13.169946: step 340600, loss = 0.029090, learning_rate = 0.000000 (2613.3 examples/sec)
=> 2021-11-02 14:06:32.943238: step 340700, loss = 0.067880, learning_rate = 0.000000 (2611.2 examples/sec)
=> 2021-11-02 14:06:53.646187: step 340800, loss = 0.031051, learning_rate = 0.000000 (2627.5 examples/sec)
=> 2021-11-02 14:07:13.420114: step 340900, loss = 0.013997, learning_rate = 0.000000 (2611.0 examples/sec)
=> 2021-11-02 14:07:33.201518: step 341000, loss = 0.018128, learning_rate = 0.000000 (2610.1 examples/sec)
=> Model saved to file: ./logs/model-341000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951867, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 14:08:04.827202: step 341100, loss = 0.038684, learning_rate = 0.000000 (2621.0 examples/sec)
=> 2021-11-02 14:08:25.450690: step 341200, loss = 0.048998, learning_rate = 0.000000 (2636.9 examples/sec)
=> 2021-11-02 14:08:45.149272: step 341300, loss = 0.019444, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-02 14:09:04.842888: step 341400, loss = 0.019993, learning_rate = 0.000000 (2622.0 examples/sec)
=> 2021-11-02 14:09:24.587124: step 341500, loss = 0.020881, learning_rate = 0.000000 (2615.3 examples/sec)
=> 2021-11-02 14:09:45.282388: step 341600, loss = 0.069450, learning_rate = 0.000000 (2627.4 examples/sec)
=> 2021-11-02 14:10:05.061463: step 341700, loss = 0.013699, learning_rate = 0.000000 (2610.7 examples/sec)
=> 2021-11-02 14:10:24.817240: step 341800, loss = 0.050869, learning_rate = 0.000000 (2613.6 examples/sec)
=> 2021-11-02 14:10:44.612191: step 341900, loss = 0.028556, learning_rate = 0.000000 (2608.5 examples/sec)
=> 2021-11-02 14:11:05.400239: step 342000, loss = 0.027930, learning_rate = 0.000000 (2618.4 examples/sec)
=> Model saved to file: ./logs/model-342000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952326, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 14:11:37.020981: step 342100, loss = 0.040645, learning_rate = 0.000000 (2619.1 examples/sec)
=> 2021-11-02 14:11:56.751096: step 342200, loss = 0.018563, learning_rate = 0.000000 (2617.1 examples/sec)
=> 2021-11-02 14:12:16.486760: step 342300, loss = 0.018666, learning_rate = 0.000000 (2616.5 examples/sec)
=> 2021-11-02 14:12:37.163162: step 342400, loss = 0.048568, learning_rate = 0.000000 (2629.8 examples/sec)
=> 2021-11-02 14:12:56.936866: step 342500, loss = 0.014688, learning_rate = 0.000000 (2611.2 examples/sec)
=> 2021-11-02 14:13:16.722177: step 342600, loss = 0.026716, learning_rate = 0.000000 (2609.6 examples/sec)
=> 2021-11-02 14:13:36.495958: step 342700, loss = 0.037834, learning_rate = 0.000000 (2611.1 examples/sec)
=> 2021-11-02 14:13:57.202196: step 342800, loss = 0.010273, learning_rate = 0.000000 (2628.8 examples/sec)
=> 2021-11-02 14:14:16.987304: step 342900, loss = 0.024597, learning_rate = 0.000000 (2610.1 examples/sec)
=> 2021-11-02 14:14:36.756454: step 343000, loss = 0.024987, learning_rate = 0.000000 (2611.8 examples/sec)
=> Model saved to file: ./logs/model-343000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952938, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 14:15:08.216526: step 343100, loss = 0.028523, learning_rate = 0.000000 (2616.6 examples/sec)
=> 2021-11-02 14:15:27.904172: step 343200, loss = 0.024979, learning_rate = 0.000000 (2623.5 examples/sec)
=> 2021-11-02 14:15:48.552176: step 343300, loss = 0.029575, learning_rate = 0.000000 (2635.1 examples/sec)
=> 2021-11-02 14:16:08.317190: step 343400, loss = 0.021644, learning_rate = 0.000000 (2612.6 examples/sec)
=> 2021-11-02 14:16:28.087833: step 343500, loss = 0.069128, learning_rate = 0.000000 (2611.9 examples/sec)
=> 2021-11-02 14:16:47.865739: step 343600, loss = 0.020176, learning_rate = 0.000000 (2610.8 examples/sec)
=> 2021-11-02 14:17:08.542455: step 343700, loss = 0.034243, learning_rate = 0.000000 (2628.9 examples/sec)
=> 2021-11-02 14:17:28.327694: step 343800, loss = 0.038145, learning_rate = 0.000000 (2609.9 examples/sec)
=> 2021-11-02 14:17:48.099002: step 343900, loss = 0.045661, learning_rate = 0.000000 (2611.5 examples/sec)
=> 2021-11-02 14:18:07.883335: step 344000, loss = 0.021151, learning_rate = 0.000000 (2610.0 examples/sec)
=> Model saved to file: ./logs/model-344000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953627, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 14:18:40.539691: step 344100, loss = 0.033617, learning_rate = 0.000000 (2619.8 examples/sec)
=> 2021-11-02 14:19:00.256984: step 344200, loss = 0.016173, learning_rate = 0.000000 (2618.8 examples/sec)
=> 2021-11-02 14:19:20.015331: step 344300, loss = 0.019534, learning_rate = 0.000000 (2613.6 examples/sec)
=> 2021-11-02 14:19:39.795117: step 344400, loss = 0.059083, learning_rate = 0.000000 (2610.5 examples/sec)
=> 2021-11-02 14:20:00.500410: step 344500, loss = 0.021566, learning_rate = 0.000000 (2624.8 examples/sec)
=> 2021-11-02 14:20:20.295575: step 344600, loss = 0.025214, learning_rate = 0.000000 (2608.5 examples/sec)
=> 2021-11-02 14:20:40.086575: step 344700, loss = 0.025338, learning_rate = 0.000000 (2609.1 examples/sec)
=> 2021-11-02 14:20:59.870924: step 344800, loss = 0.046428, learning_rate = 0.000000 (2610.0 examples/sec)
=> 2021-11-02 14:21:20.981726: step 344900, loss = 0.026135, learning_rate = 0.000000 (2601.3 examples/sec)
=> 2021-11-02 14:21:40.750411: step 345000, loss = 0.028537, learning_rate = 0.000000 (2612.1 examples/sec)
=> Model saved to file: ./logs/model-345000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.949265, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 14:22:12.103064: step 345100, loss = 0.060667, learning_rate = 0.000000 (2622.9 examples/sec)
=> 2021-11-02 14:22:31.832327: step 345200, loss = 0.020615, learning_rate = 0.000000 (2617.0 examples/sec)
=> 2021-11-02 14:22:52.465496: step 345300, loss = 0.024611, learning_rate = 0.000000 (2633.0 examples/sec)
=> 2021-11-02 14:23:12.216752: step 345400, loss = 0.027340, learning_rate = 0.000000 (2614.2 examples/sec)
=> 2021-11-02 14:23:31.975681: step 345500, loss = 0.044526, learning_rate = 0.000000 (2613.3 examples/sec)
=> 2021-11-02 14:23:51.753138: step 345600, loss = 0.021507, learning_rate = 0.000000 (2610.9 examples/sec)
=> 2021-11-02 14:24:12.586994: step 345700, loss = 0.012643, learning_rate = 0.000000 (2622.0 examples/sec)
=> 2021-11-02 14:24:32.371003: step 345800, loss = 0.032084, learning_rate = 0.000000 (2609.9 examples/sec)
=> 2021-11-02 14:24:52.155218: step 345900, loss = 0.033179, learning_rate = 0.000000 (2609.9 examples/sec)
=> 2021-11-02 14:25:11.958852: step 346000, loss = 0.035738, learning_rate = 0.000000 (2607.4 examples/sec)
=> Model saved to file: ./logs/model-346000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953933, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 14:25:43.387820: step 346100, loss = 0.032933, learning_rate = 0.000000 (2614.9 examples/sec)
=> 2021-11-02 14:26:04.064302: step 346200, loss = 0.037902, learning_rate = 0.000000 (2634.6 examples/sec)
=> 2021-11-02 14:26:23.795848: step 346300, loss = 0.061501, learning_rate = 0.000000 (2617.0 examples/sec)
=> 2021-11-02 14:26:43.541131: step 346400, loss = 0.017130, learning_rate = 0.000000 (2615.0 examples/sec)
=> 2021-11-02 14:27:03.302982: step 346500, loss = 0.022385, learning_rate = 0.000000 (2612.9 examples/sec)
=> 2021-11-02 14:27:24.080111: step 346600, loss = 0.069724, learning_rate = 0.000000 (2628.3 examples/sec)
=> 2021-11-02 14:27:43.843272: step 346700, loss = 0.034171, learning_rate = 0.000000 (2612.6 examples/sec)
=> 2021-11-02 14:28:03.624054: step 346800, loss = 0.011941, learning_rate = 0.000000 (2610.6 examples/sec)
=> 2021-11-02 14:28:23.420482: step 346900, loss = 0.037354, learning_rate = 0.000000 (2608.3 examples/sec)
=> 2021-11-02 14:28:44.156541: step 347000, loss = 0.031277, learning_rate = 0.000000 (2626.3 examples/sec)
=> Model saved to file: ./logs/model-347000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951944, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 14:29:15.704929: step 347100, loss = 0.013124, learning_rate = 0.000000 (2626.6 examples/sec)
=> 2021-11-02 14:29:35.372201: step 347200, loss = 0.026618, learning_rate = 0.000000 (2625.9 examples/sec)
=> 2021-11-02 14:29:55.060329: step 347300, loss = 0.014671, learning_rate = 0.000000 (2623.0 examples/sec)
=> 2021-11-02 14:30:15.760719: step 347400, loss = 0.044950, learning_rate = 0.000000 (2630.2 examples/sec)
=> 2021-11-02 14:30:35.485684: step 347500, loss = 0.025660, learning_rate = 0.000000 (2617.8 examples/sec)
=> 2021-11-02 14:30:55.240191: step 347600, loss = 0.033263, learning_rate = 0.000000 (2613.8 examples/sec)
=> 2021-11-02 14:31:15.013467: step 347700, loss = 0.014241, learning_rate = 0.000000 (2611.6 examples/sec)
=> 2021-11-02 14:31:35.718185: step 347800, loss = 0.049279, learning_rate = 0.000000 (2624.1 examples/sec)
=> 2021-11-02 14:31:55.498090: step 347900, loss = 0.014689, learning_rate = 0.000000 (2610.7 examples/sec)
=> 2021-11-02 14:32:15.272975: step 348000, loss = 0.024117, learning_rate = 0.000000 (2611.6 examples/sec)
=> Model saved to file: ./logs/model-348000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952403, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 14:32:46.854809: step 348100, loss = 0.018546, learning_rate = 0.000000 (2617.4 examples/sec)
=> 2021-11-02 14:33:07.548760: step 348200, loss = 0.040889, learning_rate = 0.000000 (2640.3 examples/sec)
=> 2021-11-02 14:33:27.255158: step 348300, loss = 0.017892, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-02 14:33:46.984057: step 348400, loss = 0.026163, learning_rate = 0.000000 (2617.4 examples/sec)
=> 2021-11-02 14:34:06.744802: step 348500, loss = 0.025417, learning_rate = 0.000000 (2612.9 examples/sec)
=> 2021-11-02 14:34:27.451611: step 348600, loss = 0.040224, learning_rate = 0.000000 (2626.1 examples/sec)
=> 2021-11-02 14:34:47.226797: step 348700, loss = 0.037605, learning_rate = 0.000000 (2611.3 examples/sec)
=> 2021-11-02 14:35:07.007385: step 348800, loss = 0.057618, learning_rate = 0.000000 (2610.5 examples/sec)
=> 2021-11-02 14:35:26.803498: step 348900, loss = 0.019307, learning_rate = 0.000000 (2608.3 examples/sec)
=> 2021-11-02 14:35:46.620129: step 349000, loss = 0.021813, learning_rate = 0.000000 (2606.4 examples/sec)
=> Model saved to file: ./logs/model-349000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952250, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 14:36:19.039048: step 349100, loss = 0.030920, learning_rate = 0.000000 (2634.9 examples/sec)
=> 2021-11-02 14:36:38.721477: step 349200, loss = 0.038733, learning_rate = 0.000000 (2623.5 examples/sec)
=> 2021-11-02 14:36:58.449940: step 349300, loss = 0.017241, learning_rate = 0.000000 (2617.3 examples/sec)
=> 2021-11-02 14:37:18.201001: step 349400, loss = 0.025168, learning_rate = 0.000000 (2614.6 examples/sec)
=> 2021-11-02 14:37:38.871727: step 349500, loss = 0.029325, learning_rate = 0.000000 (2627.8 examples/sec)
=> 2021-11-02 14:37:58.692315: step 349600, loss = 0.041636, learning_rate = 0.000000 (2605.1 examples/sec)
=> 2021-11-02 14:38:18.472268: step 349700, loss = 0.034636, learning_rate = 0.000000 (2610.4 examples/sec)
=> 2021-11-02 14:38:38.237642: step 349800, loss = 0.032456, learning_rate = 0.000000 (2612.4 examples/sec)
=> 2021-11-02 14:38:58.965776: step 349900, loss = 0.040192, learning_rate = 0.000000 (2625.4 examples/sec)
=> 2021-11-02 14:39:18.745756: step 350000, loss = 0.038360, learning_rate = 0.000000 (2610.5 examples/sec)
=> Model saved to file: ./logs/model-350000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952862, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 14:39:50.225697: step 350100, loss = 0.039147, learning_rate = 0.000000 (2619.4 examples/sec)
=> 2021-11-02 14:40:09.901331: step 350200, loss = 0.011760, learning_rate = 0.000000 (2624.5 examples/sec)
=> 2021-11-02 14:40:30.553013: step 350300, loss = 0.024879, learning_rate = 0.000000 (2640.1 examples/sec)
=> 2021-11-02 14:40:50.257473: step 350400, loss = 0.030185, learning_rate = 0.000000 (2621.3 examples/sec)
=> 2021-11-02 14:41:09.991517: step 350500, loss = 0.023805, learning_rate = 0.000000 (2617.6 examples/sec)
=> 2021-11-02 14:41:29.760432: step 350600, loss = 0.035669, learning_rate = 0.000000 (2612.8 examples/sec)
=> 2021-11-02 14:41:50.551197: step 350700, loss = 0.070541, learning_rate = 0.000000 (2625.1 examples/sec)
=> 2021-11-02 14:42:10.333488: step 350800, loss = 0.022126, learning_rate = 0.000000 (2610.8 examples/sec)
=> 2021-11-02 14:42:30.076907: step 350900, loss = 0.057645, learning_rate = 0.000000 (2616.7 examples/sec)
=> 2021-11-02 14:42:49.827982: step 351000, loss = 0.021634, learning_rate = 0.000000 (2615.2 examples/sec)
=> Model saved to file: ./logs/model-351000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954622, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 14:43:23.238290: step 351100, loss = 0.036418, learning_rate = 0.000000 (2629.7 examples/sec)
=> 2021-11-02 14:43:42.956914: step 351200, loss = 0.021760, learning_rate = 0.000000 (2619.6 examples/sec)
=> 2021-11-02 14:44:02.677009: step 351300, loss = 0.031084, learning_rate = 0.000000 (2619.2 examples/sec)
=> 2021-11-02 14:44:22.393999: step 351400, loss = 0.032977, learning_rate = 0.000000 (2619.5 examples/sec)
=> 2021-11-02 14:44:43.400588: step 351500, loss = 0.023268, learning_rate = 0.000000 (2628.8 examples/sec)
=> 2021-11-02 14:45:03.175083: step 351600, loss = 0.024457, learning_rate = 0.000000 (2612.2 examples/sec)
=> 2021-11-02 14:45:22.967108: step 351700, loss = 0.027962, learning_rate = 0.000000 (2609.6 examples/sec)
=> 2021-11-02 14:45:42.785368: step 351800, loss = 0.030101, learning_rate = 0.000000 (2606.3 examples/sec)
=> 2021-11-02 14:46:02.593671: step 351900, loss = 0.032392, learning_rate = 0.000000 (2607.8 examples/sec)
=> 2021-11-02 14:46:23.551981: step 352000, loss = 0.046080, learning_rate = 0.000000 (2604.7 examples/sec)
=> Model saved to file: ./logs/model-352000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.945669, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 14:46:55.796602: step 352100, loss = 0.041764, learning_rate = 0.000000 (2616.4 examples/sec)
=> 2021-11-02 14:47:15.498603: step 352200, loss = 0.032158, learning_rate = 0.000000 (2622.1 examples/sec)
=> 2021-11-02 14:47:35.212725: step 352300, loss = 0.017999, learning_rate = 0.000000 (2620.8 examples/sec)
=> 2021-11-02 14:47:55.990211: step 352400, loss = 0.041747, learning_rate = 0.000000 (2628.4 examples/sec)
=> 2021-11-02 14:48:15.781930: step 352500, loss = 0.016563, learning_rate = 0.000000 (2609.9 examples/sec)
=> 2021-11-02 14:48:35.563100: step 352600, loss = 0.047812, learning_rate = 0.000000 (2610.8 examples/sec)
=> 2021-11-02 14:48:55.368440: step 352700, loss = 0.017868, learning_rate = 0.000000 (2607.9 examples/sec)
=> 2021-11-02 14:49:16.296068: step 352800, loss = 0.021753, learning_rate = 0.000000 (2620.2 examples/sec)
=> 2021-11-02 14:49:36.081877: step 352900, loss = 0.018417, learning_rate = 0.000000 (2610.3 examples/sec)
=> 2021-11-02 14:49:55.852017: step 353000, loss = 0.054891, learning_rate = 0.000000 (2612.7 examples/sec)
=> Model saved to file: ./logs/model-353000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950337, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 14:50:27.802951: step 353100, loss = 0.025326, learning_rate = 0.000000 (2621.3 examples/sec)
=> 2021-11-02 14:50:48.530992: step 353200, loss = 0.044688, learning_rate = 0.000000 (2635.6 examples/sec)
=> 2021-11-02 14:51:08.197117: step 353300, loss = 0.022585, learning_rate = 0.000000 (2626.3 examples/sec)
=> 2021-11-02 14:51:27.929996: step 353400, loss = 0.018096, learning_rate = 0.000000 (2617.5 examples/sec)
=> 2021-11-02 14:51:47.639803: step 353500, loss = 0.027955, learning_rate = 0.000000 (2620.7 examples/sec)
=> 2021-11-02 14:52:08.437641: step 353600, loss = 0.030181, learning_rate = 0.000000 (2627.9 examples/sec)
=> 2021-11-02 14:52:28.234865: step 353700, loss = 0.061307, learning_rate = 0.000000 (2608.9 examples/sec)
=> 2021-11-02 14:52:48.049495: step 353800, loss = 0.026797, learning_rate = 0.000000 (2607.1 examples/sec)
=> 2021-11-02 14:53:07.866901: step 353900, loss = 0.034787, learning_rate = 0.000000 (2606.8 examples/sec)
=> 2021-11-02 14:53:28.679177: step 354000, loss = 0.034655, learning_rate = 0.000000 (2630.0 examples/sec)
=> Model saved to file: ./logs/model-354000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950719, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 14:54:00.953677: step 354100, loss = 0.016985, learning_rate = 0.000000 (2617.3 examples/sec)
=> 2021-11-02 14:54:20.661846: step 354200, loss = 0.029331, learning_rate = 0.000000 (2621.0 examples/sec)
=> 2021-11-02 14:54:40.377285: step 354300, loss = 0.027145, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 14:55:01.177346: step 354400, loss = 0.039924, learning_rate = 0.000000 (2629.4 examples/sec)
=> 2021-11-02 14:55:21.016455: step 354500, loss = 0.038075, learning_rate = 0.000000 (2603.8 examples/sec)
=> 2021-11-02 14:55:40.797700: step 354600, loss = 0.017945, learning_rate = 0.000000 (2611.2 examples/sec)
=> 2021-11-02 14:56:00.566330: step 354700, loss = 0.033265, learning_rate = 0.000000 (2612.9 examples/sec)
=> 2021-11-02 14:56:21.399687: step 354800, loss = 0.023640, learning_rate = 0.000000 (2626.5 examples/sec)
=> 2021-11-02 14:56:41.166993: step 354900, loss = 0.033756, learning_rate = 0.000000 (2613.4 examples/sec)
=> 2021-11-02 14:57:00.956398: step 355000, loss = 0.027770, learning_rate = 0.000000 (2610.1 examples/sec)
=> Model saved to file: ./logs/model-355000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.954086, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 14:57:33.380591: step 355100, loss = 0.028176, learning_rate = 0.000000 (2619.7 examples/sec)
=> 2021-11-02 14:57:53.073033: step 355200, loss = 0.032074, learning_rate = 0.000000 (2623.6 examples/sec)
=> 2021-11-02 14:58:13.858217: step 355300, loss = 0.024462, learning_rate = 0.000000 (2632.0 examples/sec)
=> 2021-11-02 14:58:33.579503: step 355400, loss = 0.043074, learning_rate = 0.000000 (2619.8 examples/sec)
=> 2021-11-02 14:58:53.330937: step 355500, loss = 0.016855, learning_rate = 0.000000 (2615.4 examples/sec)
=> 2021-11-02 14:59:13.102168: step 355600, loss = 0.014819, learning_rate = 0.000000 (2612.4 examples/sec)
=> 2021-11-02 14:59:33.975579: step 355700, loss = 0.017052, learning_rate = 0.000000 (2624.8 examples/sec)
=> 2021-11-02 14:59:53.737608: step 355800, loss = 0.031767, learning_rate = 0.000000 (2613.6 examples/sec)
=> 2021-11-02 15:00:13.471968: step 355900, loss = 0.028732, learning_rate = 0.000000 (2616.9 examples/sec)
=> 2021-11-02 15:00:33.217161: step 356000, loss = 0.036593, learning_rate = 0.000000 (2615.7 examples/sec)
=> Model saved to file: ./logs/model-356000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.950490, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 15:01:06.658377: step 356100, loss = 0.048324, learning_rate = 0.000000 (2624.5 examples/sec)
=> 2021-11-02 15:01:26.350948: step 356200, loss = 0.038160, learning_rate = 0.000000 (2623.1 examples/sec)
=> 2021-11-02 15:01:46.065325: step 356300, loss = 0.039427, learning_rate = 0.000000 (2620.4 examples/sec)
=> 2021-11-02 15:02:05.827275: step 356400, loss = 0.029237, learning_rate = 0.000000 (2613.5 examples/sec)
=> 2021-11-02 15:02:26.618513: step 356500, loss = 0.026026, learning_rate = 0.000000 (2629.1 examples/sec)
=> 2021-11-02 15:02:46.396491: step 356600, loss = 0.027432, learning_rate = 0.000000 (2611.5 examples/sec)
=> 2021-11-02 15:03:06.168201: step 356700, loss = 0.041242, learning_rate = 0.000000 (2612.5 examples/sec)
=> 2021-11-02 15:03:25.955289: step 356800, loss = 0.031205, learning_rate = 0.000000 (2610.4 examples/sec)
=> 2021-11-02 15:03:46.817515: step 356900, loss = 0.019547, learning_rate = 0.000000 (2619.3 examples/sec)
=> 2021-11-02 15:04:06.638460: step 357000, loss = 0.039354, learning_rate = 0.000000 (2605.7 examples/sec)
=> Model saved to file: ./logs/model-357000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951561, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 15:04:38.951602: step 357100, loss = 0.021537, learning_rate = 0.000000 (2618.8 examples/sec)
=> 2021-11-02 15:04:58.649255: step 357200, loss = 0.031154, learning_rate = 0.000000 (2622.1 examples/sec)
=> 2021-11-02 15:05:19.370756: step 357300, loss = 0.052460, learning_rate = 0.000000 (2638.0 examples/sec)
=> 2021-11-02 15:05:39.138096: step 357400, loss = 0.053216, learning_rate = 0.000000 (2613.4 examples/sec)
=> 2021-11-02 15:05:58.910198: step 357500, loss = 0.052832, learning_rate = 0.000000 (2612.8 examples/sec)
=> 2021-11-02 15:06:18.698081: step 357600, loss = 0.028453, learning_rate = 0.000000 (2609.8 examples/sec)
=> 2021-11-02 15:06:39.561472: step 357700, loss = 0.012267, learning_rate = 0.000000 (2624.2 examples/sec)
=> 2021-11-02 15:06:59.373538: step 357800, loss = 0.041580, learning_rate = 0.000000 (2607.6 examples/sec)
=> 2021-11-02 15:07:19.170858: step 357900, loss = 0.011011, learning_rate = 0.000000 (2609.1 examples/sec)
=> 2021-11-02 15:07:38.974815: step 358000, loss = 0.045039, learning_rate = 0.000000 (2608.1 examples/sec)
=> Model saved to file: ./logs/model-358000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.952785, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 15:08:11.192044: step 358100, loss = 0.045845, learning_rate = 0.000000 (2613.5 examples/sec)
=> 2021-11-02 15:08:31.951625: step 358200, loss = 0.011597, learning_rate = 0.000000 (2636.9 examples/sec)
=> 2021-11-02 15:08:51.656202: step 358300, loss = 0.024395, learning_rate = 0.000000 (2621.2 examples/sec)
=> 2021-11-02 15:09:11.409921: step 358400, loss = 0.022263, learning_rate = 0.000000 (2615.0 examples/sec)
=> 2021-11-02 15:09:31.184554: step 358500, loss = 0.018466, learning_rate = 0.000000 (2612.0 examples/sec)
=> 2021-11-02 15:09:51.953202: step 358600, loss = 0.019508, learning_rate = 0.000000 (2629.2 examples/sec)
=> 2021-11-02 15:10:11.692125: step 358700, loss = 0.036131, learning_rate = 0.000000 (2616.9 examples/sec)
=> 2021-11-02 15:10:31.487037: step 358800, loss = 0.036085, learning_rate = 0.000000 (2609.8 examples/sec)
=> 2021-11-02 15:10:51.234176: step 358900, loss = 0.027715, learning_rate = 0.000000 (2615.9 examples/sec)
=> 2021-11-02 15:11:12.071843: step 359000, loss = 0.035469, learning_rate = 0.000000 (2621.3 examples/sec)
=> Model saved to file: ./logs/model-359000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953551, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 15:11:44.328981: step 359100, loss = 0.027593, learning_rate = 0.000000 (2619.4 examples/sec)
=> 2021-11-02 15:12:04.005398: step 359200, loss = 0.022299, learning_rate = 0.000000 (2625.0 examples/sec)
=> 2021-11-02 15:12:23.719264: step 359300, loss = 0.014540, learning_rate = 0.000000 (2620.0 examples/sec)
=> 2021-11-02 15:12:44.502425: step 359400, loss = 0.027791, learning_rate = 0.000000 (2625.5 examples/sec)
=> 2021-11-02 15:13:04.256453: step 359500, loss = 0.033031, learning_rate = 0.000000 (2614.5 examples/sec)
=> 2021-11-02 15:13:23.999008: step 359600, loss = 0.019054, learning_rate = 0.000000 (2616.0 examples/sec)
=> 2021-11-02 15:13:43.767229: step 359700, loss = 0.020501, learning_rate = 0.000000 (2613.0 examples/sec)
=> 2021-11-02 15:14:04.641577: step 359800, loss = 0.014927, learning_rate = 0.000000 (2625.9 examples/sec)
=> 2021-11-02 15:14:24.421038: step 359900, loss = 0.029224, learning_rate = 0.000000 (2611.5 examples/sec)
=> 2021-11-02 15:14:44.214839: step 360000, loss = 0.022914, learning_rate = 0.000000 (2609.2 examples/sec)
=> Model saved to file: ./logs/model-360000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.953168, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 15:15:16.245829: step 360100, loss = 0.015485, learning_rate = 0.000000 (2614.2 examples/sec)
=> 2021-11-02 15:15:37.169043: step 360200, loss = 0.018673, learning_rate = 0.000000 (2630.6 examples/sec)
=> 2021-11-02 15:15:56.928704: step 360300, loss = 0.045070, learning_rate = 0.000000 (2614.0 examples/sec)
=> 2021-11-02 15:16:16.807998: step 360400, loss = 0.015896, learning_rate = 0.000000 (2598.0 examples/sec)
=> 2021-11-02 15:16:36.589269: step 360500, loss = 0.013321, learning_rate = 0.000000 (2611.0 examples/sec)
=> 2021-11-02 15:16:57.399381: step 360600, loss = 0.032405, learning_rate = 0.000000 (2624.0 examples/sec)
=> 2021-11-02 15:17:17.213102: step 360700, loss = 0.053937, learning_rate = 0.000000 (2607.1 examples/sec)
=> 2021-11-02 15:17:37.028790: step 360800, loss = 0.034772, learning_rate = 0.000000 (2606.5 examples/sec)
=> 2021-11-02 15:17:56.838679: step 360900, loss = 0.048492, learning_rate = 0.000000 (2607.8 examples/sec)
=> 2021-11-02 15:18:16.641757: step 361000, loss = 0.037574, learning_rate = 0.000000 (2609.6 examples/sec)
=> Model saved to file: ./logs/model-361000.pth
=> patience = 100
=> Evaluating on validation dataset...
==> accuracy = 0.951408, best accuracy 0.955005
=> patience = 99
=> 2021-11-02 15:18:49.918029: step 361100, loss = 0.014867, learning_rate = 0.000000 (2622.9 examples/sec)
=> 2021-11-02 15:19:09.653007: step 361200, loss = 0.024057, learning_rate = 0.000000 (2617.1 examples/sec)
